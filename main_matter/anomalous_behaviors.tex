\documentclass[../main.tex]{subfiles}

\begin{document}

\chapter[Anomalous Behaviors]{Anomalous Behaviors}\label{sec:anomalous}


\epigraph{``What the hell is going on with our equipment?''
``It wasn't meant to do this in the first place.''}
{\textit{Half-Life}\\\textsc{Valve}}

The decompositions shown in the last chapter work in normal conditions, but we can analyze more interesting cases such as when systems do not behave nominally.

In this chapter, we discuss briefly the causes of anomalous behaviors, how they can happen, and the primary means used in the literature to mitigate their effects.

\minitoc%

\section{Definition and types}
We define \emph{anomalous behaviors} as any non-expected (change of) behavior of a system.

There are two primary causes for a system not to perform as nominally expected: \emph{faults} and \emph{attacks}.
The main difference between these two is \emph{intention}; while faults happen unintentionally, uncoordinated and with no objective, attacks happen intentionally, usually coordinated with a malicious objective.

\begin{remark}
  A non-expected behavior can also be observed when there are modeling errors, i.e., the theoretical model used to describe the system does not correspond to the real system.
  In this case, the system did not change its behavior, but the expectation that was false.
  So, for the time being we will ignore modeling errors and assume they do not cause the non-nominal behaviors.
\end{remark}

Both faults and attacks can deviate the overall system from its nominal optimal behavior, but the most severe effect they can produce is a complete breakdown.
Some techniques can be applied to create attack/fault-tolerant systems or to robustify the systems against them.

Due to some similarities, depending on where on the system they happen, some defense techniques based on robustness used for faults may also be used for attacks~\cite{TeixeiraEtAl2015}.

In this work we will concentrate on attacks, mentioning faults eventually.
Before presenting attacks and discussing mitigation methods, let's explore the sources of the vulnerabilities.

\section{Vulnerabilities in \cps{}}

As known, \cps{} have its components in both Cyber and Physical domains.
We can divide them into: \textbf{Physical components}, which are sensors and actuators (as motors, valves, cameras, thermocouples etc.);
\textbf{Channels}, used for communication (wires, air, tubes etc); \textbf{Connectors}, which connect components by transmitting some physical quantity (wires, circuit traces, cables, water pipes, etc.);
the \textbf{Software}, which is the logic used to operate the physical components (code, \plc{} logic etc.); and the \textbf{Controller}, which is the hardware running the software (\plc{}s, micro-controllers, computers etc.).

~\\Each one of the aforementioned components represents a source of vulnerability.
\\\textbf{Physical components} can be targets of sabotage, for instance an attacker can use a cold object to disrupt thermostat readings to increase the temperature of a room. But the components may also deteriorate with time, which can eventually cause a fault.
\textbf{Channels} and \textbf{connectors} can also be targets of sabotage, as someone can interfere on the communication/transmission or intentionally interrupt it. But interruptions and corruptions can also be caused by natural accidents such solar flares (causing radio blackouts) or as trees knocking down electricity cables or sharks eating underwater cables.
\textbf{Software} can also be a source of vulnerability due to \emph{bugs}, which can interrupt the normal functioning or even let a \emph{hacker} gain total control of the system.
The \textbf{controller}, if not well dimensioned (computing capacity), can also be a vulnerability.
If it receives more requisitions than expected, the system will be overloaded.

It is worth emphasizing that in a \iot{} context, almost all sensors and actuators have embedded controllers and software, which can also be sources of vulnerabilities themselves.

\section{Security}\label{sec:security}
It can be defined as the safe/normal operation of a system even under unexpected circumstances.
We can borrow some definitions from cyber-security and extend to \cps{}.

Cyber systems are usually described in terms of data and resources.
And \emph{cyber-security} is founded on three pillars: \CIA{} of such components~\cite{Bishop2002}.

\paragraph{Confidentiality} refers to how undisclosed the data and resources are.
Sometimes parts of the system need to be secret and only accessible for a selected group.
Be it for privacy reasons, to avoid disclose personal info, or even to prevent the exposition of possible vulnerabilities of the system (a pop culture example can be the Death Star Plans on the Star Wars Saga).
\paragraph{Integrity} refers to how trustworthy the data and resources are. For data it can also divided into the integrity of the information (data integrity) and integrity of identity of the source (called authentication).

\paragraph{Availability} refers to how accessible to use the data and resources are when desired. And as exposed in~\cite{Bishop2002}, ``an unavailable system is at least as bad as no system at all''.


\section{Attacks}\label{sec:attacks}
Using the \CIA{}, It is possible~\cite{TeixeiraEtAl2015}
\todo{model 3 axis of cyber-physical attack space}

use as base
\todo{search zero dynamics attack}
https://ieeexplore.ieee.org/abstract/document/4577833
\cite{CaiEtAl2019,ZhangEtAl2021b}
Two typical attacks \cite{ZhangEtAl2021a}

\subsection{Types}\label{sec:types_of_attacks}
If we use the global vision shown in \S~\ref{sec:topology_trust} we can aggregate the components shown into only two,
\cite{PasqualettiEtAl2013}
\cite{BoemEtAl2020}

but they will always reflect on the channel.


Channel and agent

Middle-man

Deception Attack (Repeat Attack)

DoS

\cite{GuEtAl2016}

\section{Maintaining security}\label{sec:maintaining_security}
It can be achieved by two means: robustness and resilience.

Robustness can be defined as the ability to withstand perturbations without change in function~\cite{Jen2003}, while resilience
  is the ability to maintain an accepted level of operational normalcy  in  response  to  disturbances,  including  threats  of  an unexpected and malicious nature\cite{Rieger2010}

While robustness is usually passive, resilience is more adaptive, active in order to reestablish a more optimal behavior.
Some robust control approaches used in fault-tolerance can also be used for some kinds of attacks, while usually for specific kinds of attacks new resilient methods need to be created in order to mitigate the effects.
\todo{Naghavi, S. V., Safavi, A. A., & Kazerooni, M. (2014). Decentralized fault tolerant model
predictive control of discrete-time interconnected nonlinear systems. Journal of the
Franklin Institute, 351(3), 1644–1656.}
which can achieve graceful degradation

\paragraph{Trust}

\paragraph{Prevention}
~\\To prevent anomalous behaviors, we secure components that we see as a possible threat due its vulnerabilities.
\\Here we can give some examples.
Tampering of the physical components can be prevented by enclosing them by walls and doors with access control whenever possible~\cite{DingEtAl2018}, preventing the attacker to approach such components.
Faults due to deterioration are prevented usually by a periodical preventive maintenance \todo{citation??}, and substitution of deteriorated components by new ones.
Attacks and faults caused by software vulnerabilities are prevented by corrective \emph{patches} that are sent to all users of the software to correct the bugs~\todo{Citation??}.
For communication/transmission, we increase the robustness of the mean, by using better cables with insulation and braided shields for example.
To secure exchanges usually cryptography is used whenever possible/necessary.

\paragraph{Detection}
Use some system knowledge to recognize an anomalous behavior.

\paragraph{Isolation}
Use some  knowledge of the system to recognize what component is the source of the anomalous behavior

\paragraph{Mitigation}





Prevention/Protection
Detection

Isolation
Recovery

It always depend on the question «who/what do you trust/distrust?»

% no see o que se pasa
Some examples are the \emph{blockchain} (mentioned in~\ref{sec:drawbacks}), and cryptographing the signal/data we want to protect.

\subsection{Detection/Isolation}
\emph{watermarking} (where some cryptographed signal is superimposed to the signal we want to secure)~\cite{MoEtAl2015,SatchidanandanKumar2017,KshetriVoas2017,LuciaEtAl2021},
\cite{FortiEtAl2016}

\subsection{Mitigation/Recovery}
For the cases of faults, the main recovery options are disconnecting the malfunctioning components to prevent further consequences or fixing (or substituting) the components.

If disturbance is inside some probabilistic bounds \cite{AnandutaEtAl2020}


% \epigraph{\centering There are few people, however, who, if you told them a result, would be able to evolve from their own inner consciousness what the steps were which led up to that result.}
% {\textit{A Study in Scarlet}\\ \textsc{Sir Arthur Conan Doyle}}

As the hierarchical proposed in~\cite{BraunEtAl2020}, where a regulator (central supervisor) who can detect and exclude suspicious agents.

\todo{\cite{MaestreEtAl2014} Monolithical, multi independent systems}

\begin{description}
  \item[Show examples of Attacks]
  \item[False data injection/communication corruption] Maybe review attacks shown in \cite{VelardeEtAl2017} and how they can be viewed as false data injection attacks (corruption on sent values), \todo{show that since coordinator is oblivious to what happen inside each agent what matters is what it receives, no need to specify exactly the responsible part which generated attack}
\end{description}

\printbibliography%


\end{document}
