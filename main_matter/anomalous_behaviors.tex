\documentclass[../main.tex]{subfiles}

\begin{document}

\chapter[Anomalous Behaviors \& Security]{Anomalous Behaviors\\and\\ Security}\label{sec:anomalous}


\epigraph{``What the hell is going on with our equipment?''
``It wasn't meant to do this in the first place.''}
{\textit{Half-Life}\\\textsc{Valve}}

The decompositions shown in the last chapter work in normal conditions, but we can analyze more interesting cases such as when systems do not behave nominally.

In this chapter, we discuss briefly the causes of anomalous behaviors, how they can happen, and the primary means used in the literature to mitigate their effects.

\minitoc%

\section{What are anomalous behaviors?}
We define \emph{anomalous behaviors} as any non-expected (change of) behavior of a system.

There are two primary causes for a system not to perform as nominally expected: \emph{faults} and \emph{attacks}.
The main difference between these two is \emph{intention}; while faults happen unintentionally, uncoordinated and with no objective, attacks happen intentionally, usually coordinated with a malicious objective.

\begin{remark}
  A non-expected behavior can also be observed when there are modeling errors, i.e., the theoretical model used to describe the system does not correspond to the real system.
  In this case, the system did not change its behavior, but the expectation that was false.
  So, for the time being we will ignore modeling errors and assume they do not cause the non-nominal behaviors.
\end{remark}

Both faults and attacks can deviate the overall system from its nominal optimal behavior, but the most severe effect they can produce is a complete breakdown.
In \cps{}, as the systems are connected to physical components, a malfunction can provoke a great impact on the population, since some of the systems can control important
aspects of modern life, as water and energy supply.

That's why we are interested in assuring the normal operation of such systems.

\section{Security}\label{sec:security}
Security alludes to the safe and reliable operation of a system even under unexpected circumstances, such as faults and attacks.
To understand security of \cps{}, we can first borrow some definitions from cyber-security and then extend them to \cps{}.

Computer systems are usually described in terms of data and resources, and \emph{cyber-security} is ensured by three pillars: \CIA{} of such components~\cite{Bishop2005}.

\paragraph{Confidentiality} refers to how undisclosed the data and resources are.
Sometimes parts of the system need to be secret and only accessible for a selected group.
Be it for privacy reasons, to avoid disclose personal info, for instance, or even to prevent the exposition of possible vulnerabilities of the system (a pop culture example can be the Death Star Plans on the Star Wars Saga).

\paragraph{Integrity} means how trustworthy the data and resources are.
For example, a new equipment is more trustworthy than an old one. For data traffic, the integrity of the communication may be divided into the integrity of the information sent/received (data integrity) and integrity of identity of the source/recipient (called authentication).

\paragraph{Availability} relates to how accessible to use the data and resources are when desired.
For example, if one control is given to a system, it should be applied to it, and equally, if we need data from a sensor, it must be able to send it.
Furthermore, it is always good to call attention to, as exposed in~\cite{Bishop2005}, that ``an unavailable system is at least as bad as no system at all''.
\\~\\
The vulnerabilities of a system can compromise any of the three pillars, sometimes multiple at the same time. So, let us explore the sources of the vulnerabilities in \cps{}.

\section{Vulnerabilities in \cps{}}

As it is known, \cps{} have its components in both Cyber and Physical domains.
So, as in computer systems, we can divide them into data (the immaterial part) and resources (the material part). We can also divide them into more specific parts such as: \textbf{Transducers}, which are sensors and actuators (as motors, valves, cameras, antennae, thermocouples etc.);
\textbf{Channels}, used for communication (wires, air, tubes etc); \textbf{Connectors}, which connect components by transmitting some physical quantity (wires, circuit traces, cables, water pipes, etc.);
the \textbf{Software}, which is the logic used to operate the physical components (code, \plc{} logic etc.); and the \textbf{Controller}, which is the hardware running the software (\plc{}s, micro-controllers, computers etc.).

~\\Each one of the aforementioned components represents a source of vulnerability.
\\\textbf{Transducers} can be targets of sabotage, for instance an attacker can use a cold object to disrupt thermostat readings to increase the temperature of a room. But the components may also deteriorate with time, which can eventually cause a fault.
\textbf{Channels} and \textbf{connectors} can as well be targets of sabotage, as someone can interfere on the transmission to observe the traffic to gather information or intentionally interrupt it. But interruptions and corruptions might be caused by natural accidents such solar flares (causing radio blackouts) or as trees knocking down electricity cables or sharks eating underwater cables.
\textbf{Software} can also be a source of vulnerability due to \emph{bugs}, which can interrupt the normal functioning or even let a \emph{hacker} gain total control of the system.
The \textbf{controller}, if not well dimensioned (computing capacity), can also be a vulnerability.
If it receives more requisitions than expected, the system will be overloaded.

It is worth emphasizing that in a \iot{} context, almost all sensors and actuators have embedded controllers and software, which can also be sources of vulnerabilities themselves.

Attackers can discover some of those vulnerabilities and use them in their favor. Due to this adversary behavior, in this work we will concentrate on attacks, mentioning faults eventually.

\section{Attacks in \cps{}}\label{sec:attacks}

From the definition of cyber-attacks~\cite{Bishop2005} and other
definitions used in this chapter, we can define an attack as an ill-intentioned action which uses vulnerabilities of a cyber-physical system to violate its security.
The perpetrator of the action is called attacker.

In a computer context~\cite{Bishop2005}, \Citeauthor{Bishop2005} divides cyber-attacks into ``four broad classes'':
disclosure, deception, disruption and usurpation.
\textbf{Disclosure} is the unauthorized access to information (break of confidentiality).
\textbf{Deception} tries to deceit making false data pass as true (break of data integrity).
\textbf{Disruption} interrupts or prevents the system to work correctly (break of availability). And \textbf{usurpation} is the unauthorized control of the system (break of authenticity).

In a \cps{}/control context~\cite{CardenasEtAl2008}, normally only the first 3 categories are used, calling them Deception, Disclosure, and~\DoS{} instead of disruption.
Sometimes, for instance~\cite{AminEtAl2009}, authors use only deception and \DoS{} to divided attacks, probably because disclosure attacks do not affect performance. But as we will, depending on the attacker they can create sneaky attacks.

This model of categorization is usually called the \DDD{} model, and authors in \cps{} also add physical attacks. To demonstrate the \DDD{} model, the components of
\cps{} are abstracted into 4 different parts: the physical system to be controlled, the controller, the communication channels, and the information trafficking by them  (as seen in Fig.~\ref{fig:cps_abstraction}).

\begin{figure}[h]
  \centering
  \begin{tikzpicture}[
    node distance=.5cm and 2cm,
    box/.style={draw,align=center,minimum height=1.5cm,minimum width=3cm,rectangle,black},
		]

    \node[box] (plant) at (0,0) {Physical\\System};

    \node[box,below=of plant] (controller) {Controller};

    \draw[-latex,thick] (controller.west) -- ++(-1,0) node [midway,below] {${u}$} |- (plant.west) ;

    \draw[-latex,thick] (plant.east) -- ++(1,0) node [midway,above] {${y}$} |- (controller.east);
\end{tikzpicture}
\caption{General abstraction of \cps{}. (Adpated from~\cite{CardenasEtAl2008,AminEtAl2009})}\label{fig:cps_abstraction}
\end{figure}

In the diagram, $u$ corresponds to the control inputs calculated by the controller to be applied in the physical system by the actuators and $y$ corresponds to the outputs of the systems transmitted by the sensors.

Due to the networked nature of the systems, we modify the scheme to also model the communication between systems.
In Fig.~\ref{fig:networked_cps_abstraction} we represent all other systems as a single entity called network with which the system may communicate.
We also add two other signals, which represent the information shared with the network, $I_{\text{in}}$ is information received from all other systems and $I_{\text{out}}$ is the information send to all other systems.

\begin{figure}[h]
  \centering
\begin{tikzpicture}[circuit ee IEC,
    node distance=1cm and 2cm,
    box/.style={draw,align=center,minimum height=1.5cm,minimum width=3cm,rectangle,black},
		]

    \node[box] (plant) at (0,0) {Physical\\System};

    \node[box,below=of plant] (controller)  {Controller};

    \node[draw,cloud,aspect=2,cloud puffs=20,below=1.5cm of controller] (network)  {Network};

    \draw[thick] (controller.west) -- ++(-1,0) node (a) {} node [midway,below] {${u}$};
    \draw[thick] (a.center) -- (a.center |- plant.west) node (b) {};
    \draw[-latex,thick] (b.center) -- (plant.west);

    \draw[thick] (plant.east) -- ++(1,0) node (aa) {} node [midway,above] {${y}$};
    \draw[thick] (aa.center) -- (aa.center |- controller.east) node (bb) {} ;
    \draw[-latex,thick] (bb.center) -- (controller.east);

    \draw[latex-,thick] (controller.south -| network.puff 20) -- +(0,-.25) node (nin) {} ;
    \draw[thick] (nin.center) -- ($(nin.center) + (0,-1)$) node (nin2) {};
    \draw[thick] (nin2.center) -- (network.puff 20) {};
    \node at ($(nin2)+(.45,.40)$) {$\mathcal{I}_{\text{in}}$};

    \draw[latex-,thick] (network.puff 2) -- +(0,.25) node (nout) {} ;
    \draw[thick] (nout.center) -- ($(nout.center) + (0,1)$) node (nout2) {};
    \draw[thick] (nout2.center) -- ( controller.south -| network.puff 2) {};
    \node at ($(nout)+(-.45,.5)$) {$\mathcal{I}_{\text{out}}$};
  \end{tikzpicture}
  \caption{General abstraction of networked \cps{}.}\label{fig:networked_cps_abstraction}
\end{figure}

Using this general networked control system scheme, the \DDD{} model characterizes the attacks by where the attack happen.
In Fig.~\ref{fig:attacks_networked_cps} we can see multiple kinds of attacks enumerated from A1 to A9.
The attacks from A1 to A4 are deception attacks, where the attack happens in the information level.
The attacker changes the signals to a modified version (here represented by a \~{} above the variable name).
The attacks from A5 to A8 are disruption (or \DoS{}) attacks, where the attacker attacks the communication channel, momentarily or not preventing the communication between two entities.
And A9 are physical attacks, where the physical system is attacked and the attacker can change physically the behavior of the system.

\begin{figure}[h]
  \centering
  \begin{tikzpicture}[circuit ee IEC,
    node distance=1cm and 2cm,
    box/.style={draw,align=center,minimum height=1.5cm,minimum width=3cm,rectangle,black},
		]

    \node[thick,box] (plant) at (0,0) {Physical\\System};

    \node[thick,box,below=of plant] (controller)  {Controller};

    \node[thick,draw,cloud,aspect=2,cloud puffs=20,below=2.0cm of controller] (network)  {Network};

    \draw[thick] (controller.west) -- ++(-1,0) node (a) {} node [midway,below] (input) {$\tilde{u}$};
    \draw[thick] (a.center) -- (a.center |- plant.west) node (b) {};
    \draw[-latex,thick] (b.center) -- (plant.west);
    \node (switch_input) at ($(a)!0.5!(b)$) {};

    \draw[thick] (plant.east) -- ++(1,0) node (aa) {} node [midway,above] (output) {$\tilde{y}$};
    \draw[thick] (aa.center) -- (aa.center |- controller.east) node (bb) {} ;
    \draw[-latex,thick] (bb.center) -- (controller.east);
    \node (switch_output) at ($(aa)!0.5!(bb)$) {};


    \draw[latex-,thick] (controller.south -| network.puff 20) -- +(0,-.5) node (nin) {} ;
    \draw[thick] (nin.center) -- ($(nin.center) + (0,-1)$) node (nin2) {};
    \draw[thick] (nin2.center) -- (network.puff 20) {};
    \node (info_in) at ($(nin)+(.45,-.10)$) {$\mathcal{I}_{\text{in}}$};

    \draw[latex-,thick] (network.puff 2) -- +(0,.5) node (nout) {} ;
    \draw[thick] (nout.center) -- ($(nout.center) + (0,1)$) node (nout2) {};
    \draw[thick] (nout2.center) -- ( controller.south -| network.puff 2) {};
    \node (info_out) at ($(nout)+(-.45,-.0)$) {$\mathcal{I}_{\text{out}}$};

    \node[red,above right=1cm of aa,inner sep=1pt,align=center] (a1) {\scalebox{1.5}{\faUserSecret}};
    \draw[-latex,thick] (a1) -- (output) node [midway,below,sloped] {A1};


    \node[red,right=1cm of info_in,inner sep=1pt,align=center] (a2) {\scalebox{1.5}{\faUserSecret}};
    \draw[-latex,thick] (a2) -- (info_in) node [midway,below,sloped] {A2};

    \node[red,left=1cm of info_out,inner sep=1pt,align=center] (a3) {\scalebox{1.5}{\faUserSecret}};
    \draw[-latex,thick] (a3) -- (info_out) node [midway,below,sloped] {A3};


    \node[red,below left=1cm of a,inner sep=1pt,align=center] (a4) {\scalebox{1.5}{\faUserSecret}};
    \draw[-latex,thick] (a4) -- (input) node [midway,below,sloped] {A4};


    \node[red,right=.4cm of switch_output,inner sep=1pt,align=center] (a5) {\scalebox{1.5}{\faUserSecret}};
    \node[red,inner sep=1pt,align=center] at ($(switch_output) + (.3,0)$) {\rotatebox[origin=c]{180}{\faCut}};
    \node [above,sloped] at ($(a5) + (-.05,-.8)$) {A5};

    \node[red,right=.4cm of nin2,inner sep=1pt,align=center] (a6) {\scalebox{1.5}{\faUserSecret}};
    \node[red,inner sep=1pt,align=center] at ($(nin2) + (.3,0)$) {\rotatebox[origin=c]{180}{\faCut}};
    \node [above,sloped] at ($(a6) + (-.05,-.8)$) {A6};


    \node[red,left=.4cm of nout2,inner sep=1pt,align=center] (a7) {\scalebox{1.5}{\faUserSecret}};
    \node[red,inner sep=1pt,align=center] at ($(nout2) + (-.3,0)$) {\rotatebox[origin=c]{0}{\faCut}};
    \node [above,sloped] at ($(a7) + (-.05,-.8)$) {A7};

    \node[red,left=.4cm of switch_input,inner sep=1pt,align=center] (a8) {\scalebox{1.5}{\faUserSecret}};
    \node[red,inner sep=1pt,align=center] at ($(switch_input) + (-.3,0)$) {\rotatebox[origin=c]{0}{\faCut}};
    \node [above,sloped] at ($(a8) + (-.05,-.8)$) {A8};


    \node[red,above=.5cm of plant,inner sep=1pt,align=center] (a9) {\hspace{1.5pt}\scalebox{1.5}{\faUserSecret}};
    \draw[-latex,thick] (a9) -- (plant) node [midway,left] {A9};

\end{tikzpicture}
\caption{Attacks in networked \cps{}.}\label{fig:attacks_networked_cps}
\end{figure}

In~\cite{TeixeiraEtAl2015}, the authors stress that the attacks not necessarily happen purely.
For instance an attacker could record the information trafficking in the communication channel (disclosure attack) to replay it in a future time, deceiving controllers and supervisors (deception attack) generating some kind of input in the system which can be harmful for the physical system.
This attack is commonly known as \textbf{Replay attack}.
One of the classic examples of this attack in the pop culture is heist movies, such as Ocean's Eleven, where the protagonists record the video feed of surveillance cameras to deceive security guards.

In~\cite{TeixeiraEtAl2015} the authors also emphasize how the knowledge of control and physical aspects of \cps{} (sensors, actuators, model dynamics etc) and how this can be advantageous for a attacker.
So, instead of using the \DDD{} model, \citeauthor{TeixeiraEtAl2015}~\cite{TeixeiraEtAl2015} proposed an attack space based on 3 dimensions: Model Knowledge, Disruption resources and disclosure resources as seen in Fig.~\ref{fig:3_dimensions_attack}.

\todo{\cite{MoSinopoli2009}, deception attack can be subtler thant \DoS{}}

\usetikzlibrary{3d}
\usetikzlibrary{perspective}
\begin{figure}
  \centering
  \begin{tikzpicture}[3d view={105}{15},
    grid/.style={very thin,gray},
    axis/.style={-latex,thick},
    cube/.style={very thick,fill=red},
    cube hidden/.style={very thick,dashed,lightgray!70}]

    % draw the axes
    \draw[axis] (0,0,0) -- (2,0,0) node[below left]{Disruption Resources};
    \draw[axis] (0,0,0) -- (0,2,0) node (disclosure) {};
    \node[above right=5pt and -10pt] at (disclosure) {Disclosure Resources};
    \draw[axis] (0,0,0) -- (0,0,2) node (model_knowledge) {};
    \node[above] at (model_knowledge) {Model Knowledge};

  \end{tikzpicture}
  \caption{3 dimensional attack space.}\label{fig:3_dimensions_attack}
\end{figure}

We can populate the attack space with some \todo{continuar daqui}

\begin{figure}
  \centering
  \begin{tikzpicture}[3d view={105}{15},
    grid/.style={very thin,gray},
    axis/.style={-latex,thick},
    cube/.style={very thick,fill=red},
    cube hidden/.style={very thick,dashed,lightgray!70}]

    % draw the axes
    \draw[axis] (0,0,0) -- (5,0,0) node[below left]{Disruption Resources};
    \draw[axis] (0,0,0) -- (0,5,0) node (disclosure) {};
    \node[above right=5pt and -10pt] at (disclosure) {Disclosure Resources};
    \draw[axis] (0,0,0) -- (0,0,5) node (model_knowledge) {};
    \node[above] at (model_knowledge) {Model Knowledge};

    \draw[cube hidden] (2,0,0) -- (2,2,0);
    \draw[cube hidden] (0,2,0) -- (2,2,0);


    \draw[cube hidden] (0,4,4) -- (0,0,4); %% top face
    \draw[cube hidden] (0,4,4) -- (4,4,4); %% top face
    \draw[cube hidden] (4,0,4) -- (4,4,4); %% top face
    \draw[cube hidden] (4,0,4) -- (0,0,4); %% top face

    \draw[cube hidden] (4,4,0) -- (4,4,4); %%
    \draw[cube hidden] (4,4,0) -- (4,0,0);
    \draw[cube hidden] (4,4,0) -- (0,4,0);
    \draw[cube hidden] (0,4,4) -- (0,4,0);
    \draw[cube hidden] (4,0,4) -- (4,0,0);


    \draw[cube hidden] (3,0,4) -- (3,0,0);

    \draw[cube hidden] (0,4,3) -- (0,0,3); %% top face
    \draw[cube hidden] (0,4,3) -- (4,4,3); %% top face
    \draw[cube hidden] (4,0,3) -- (4,4,3); %% top face
    \draw[cube hidden] (4,0,3) -- (0,0,3); %% top face

    \draw[cube hidden] (2,0,1.5) -- (0,0,1.5); %% top face
    \draw[cube hidden] (2,0,1.5) -- (2,0,0); %% top face

    \node[fill,circle,inner sep=1.5pt] (eavesdropping) at (0,.5,0) {};
    \node[fill,circle,inner sep=1.5pt] (zero_dynamics) at (3,0,4) {};
    \node[fill,circle,inner sep=1.5pt] (false_data_injection) at (3,0,3) {};

    \node[fill,circle,inner sep=1.5pt] (dos) at (3,0,0) {};
    \node[fill,circle,inner sep=1.5pt] (covert) at (4,4,4) {};
    \node[fill,circle,inner sep=1.5pt] (soft_modif) at (4,4,3) {};
    \node[fill,circle,inner sep=1.5pt] (topology) at (2,0,1.5) {};

    \node[left=10pt] at (dos) {DoS};
    \node[left=10pt] at (topology) {Topology};
    \node[above right=5pt and -10pt] at (eavesdropping) {Eavesdropping};
    \node[above right=5pt and -30pt] at (covert) {Covert};
    \node[fill,circle,inner sep=1.5pt,label=below:Replay] at (2,2,0) {};
    \node[align=center,right=.2cm] at (soft_modif) {Software\\ Modification};
    \node[above left=5pt and -10pt] at (zero_dynamics) {Zero Dynamics};

    \node[align=center,left=10pt] at (false_data_injection) {False Data\\ Injection};

  \end{tikzpicture}
  \caption{Attacks space and some attacks. (Adpated from~\cite{TeixeiraEtAl2015})}\label{fig:3_dimensions_attack_with_attacks}
\end{figure}

But as argued in~\cite{CardenasEtAl2008}, an attacker would prefer to commit attacks A1-A4, since the attacker has less risk to be identified and not necessarily needs to by physically close to the plant, reducing also risk for injuries.


But in~\cite{TeixeiraEtAl2015}, the authors recover the \CIA{} pillars and categorizes cyber

\cite{DibajiEtAl2019} and ~ use a categorization close to the \CIA{}. It is possible
\todo{model 3 axis of cyber-physical attack space}

use as base
\cite{MaestreEtAl2018}
\cite{DibajiIshii2015,WangIshii2019,VelardeEtAl2018} based robustness of graph and ignoring extreme values.
\todo{search zero dynamics attack}

https://ieeexplore.ieee.org/abstract/document/4577833
\cite{CaiEtAl2019,ZhangEtAl2021b}
Two typical attacks \cite{ZhangEtAl2021a}

\section{Attacks in \dmpc{}}\label{sec:attacks_in_dmpc}

\subsection{Types}\label{sec:types_of_attacks}
If we use the global vision shown in \S~\ref{sec:topology_trust} we can aggregate the components shown into only two,
\cite{PasqualettiEtAl2013}
\cite{BoemEtAl2020}

but they will always reflect on the channel.


Channel and agent

Middle-man

Deception Attack (Repeat Attack)

DoS

\cite{GuEtAl2016}

\section{Maintaining security}\label{sec:maintaining_security}
It can be achieved by two means: robustness and resilience.

While it can

Robustness can be defined as the ability to withstand perturbations without change in function~\cite{Jen2003}, while resilience
  is the ability to maintain an accepted level of operational normalcy  in  response  to  disturbances,  including  threats  of  an unexpected and malicious nature\cite{Rieger2010}

While robustness is usually passive, resilience is more adaptive, active in order to reestablish a more optimal behavior.
Some robust control approaches used in fault-tolerance can also be used for some kinds of attacks, while usually for specific kinds of attacks new resilient methods need to be created in order to mitigate the effects.
\todo{Naghavi, S. V., Safavi, A. A., \& Kazerooni, M. (2014). Decentralized fault tolerant model
predictive control of discrete-time interconnected nonlinear systems. Journal of the
Franklin Institute, 351(3), 1644–1656.}
which can achieve graceful degradation


\todo{remove}
Some techniques can be applied to create attack/fault-tolerant systems or to robustify the systems against them\cite{DingEtAl2018,SatchidanandanKumar2017}

Due to some similarities, depending on where on the system they happen, some defense techniques based on robustness used for faults may also be used for attacks~\cite{TeixeiraEtAl2015}.



\section{Protecting against Attacks}\label{sec:protecting_against_attacks}
First thing is to assess the risks and see what parts of you system your trust, and what part of the system can be seem as \emph{vulnerable}, or a \emph{threat}.


\paragraph{Trust}

\paragraph{Prevention}
~\\To prevent anomalous behaviors, we secure components that we see as a possible threat due its vulnerabilities.
\\Here we can give some examples.
Tampering of the physical components can be prevented by enclosing them by walls and doors with access control and adding monitoring cameras~\cite{CardenasEtAl2008,DingEtAl2018}, preventing the attacker to approach such components.
Faults due to deterioration are prevented usually by a periodical preventive maintenance~\cite{ChenEtAl2021}, and substitution of deteriorated components by new ones.
Attacks and faults caused by software vulnerabilities may be prevented by corrective \emph{patches} that are sent to all users of the software to correct the bugs, or even by software rejuvenation~\cite{GriffioenEtAl2020}, where the system is refreshed with a trusted copy of the original, in case there is a chance it was corrupted.
For communication/transmission, we increase the robustness of the mean, by using better cables with insulation and braided shields for example.
To secure exchanges usually cryptography is used to ensure data integrity and authenticity of agents~\cite{DingEtAl2018}.

\paragraph{Detection}
Use some system knowledge to recognize an anomalous behavior.

\paragraph{Isolation}
Use some  knowledge of the system to recognize what component is the source of the anomalous behavior

\paragraph{Mitigation}





Prevention/Protection
Detection

Isolation
Recovery

It always depend on the question «who/what do you trust/distrust?»

% no see o que se pasa
Some examples are the \emph{blockchain} (mentioned in~\ref{sec:drawbacks}), and cryptographing the signal/data we want to protect.

\subsection{Detection/Isolation}
\emph{watermarking} (where some cryptographed signal is superimposed to the signal we want to secure)~\cite{MoEtAl2015,SatchidanandanKumar2017,KshetriVoas2017,LuciaEtAl2021},
\cite{FortiEtAl2016}

\subsection{Mitigation/Recovery}
For the cases of faults, the main recovery options are disconnecting the malfunctioning components to prevent further consequences or fixing (or substituting) the components.

If disturbance is inside some probabilistic bounds \cite{AnandutaEtAl2020}


% \epigraph{\centering There are few people, however, who, if you told them a result, would be able to evolve from their own inner consciousness what the steps were which led up to that result.}
% {\textit{A Study in Scarlet}\\ \textsc{Sir Arthur Conan Doyle}}

As the hierarchical proposed in~\cite{BraunEtAl2020}, where a regulator (central supervisor) who can detect and exclude suspicious agents.

\todo{\cite{MaestreEtAl2014} Monolithical, multi independent systems}

\begin{description}
  \item[Show examples of Attacks]
  \item[False data injection/communication corruption] Maybe review attacks shown in \cite{VelardeEtAl2017} and how they can be viewed as false data injection attacks (corruption on sent values), \todo{show that since coordinator is oblivious to what happen inside each agent what matters is what it receives, no need to specify exactly the responsible part which generated attack}
\end{description}



\end{document}
