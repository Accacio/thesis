\documentclass[../main.tex]{subfiles}

\begin{document}

\chapter[Anomalous Behaviors \& Security]{Anomalous Behaviors\\\&\\ Security}\label{sec:anomalous}


\epigraph{``What the hell is going on with our equipment?''
``It wasn't meant to do this in the first place.''}
{\textit{Half-Life}\\\textsc{Valve}}

The decompositions shown in the last chapter work in normal conditions, but we can analyze more interesting cases such as when systems do not behave nominally.

In this chapter, we discuss briefly the causes of anomalous behaviors, how they can happen, and the primary means used in the literature to mitigate their effects.

\minitoc%

\section{Definition and types}
We define \emph{anomalous behaviors} as any non-expected (change of) behavior of a system.

There are two primary causes for a system not to perform as nominally expected: \emph{faults} and \emph{attacks}.
The main difference between these two is \emph{intention}; while faults happen unintentionally, uncoordinated and with no objective, attacks happen intentionally, usually coordinated with a malicious objective.

\begin{remark}
  A non-expected behavior can also be observed when there are modeling errors, i.e., the theoretical model used to describe the system does not correspond to the real system.
  In this case, the system did not change its behavior, but the expectation that was false.
  So, for the time being we will ignore modeling errors and assume they do not cause the non-nominal behaviors.
\end{remark}

Both faults and attacks can deviate the overall system from its nominal optimal behavior, but the most severe effect they can produce is a complete breakdown.
In \cps{}, as the systems are connected to physical components, a malfunction can provoke a great impact on the population, since some of the systems can control important
aspects of modern life, as water and energy supply.

That's why we are interested in assuring the normal operation of such systems.

\section{Security}\label{sec:security}
Security alludes to the safe and reliable operation of a system even under unexpected circumstances, such faults and attacks.
To understand security of \cps{}, we can first borrow some definitions from cyber-security and then extend them to \cps{}.

Computer systems are usually described in terms of data and resources, and \emph{cyber-security} is ensured by three pillars: \CIA{} of such components~\cite{Bishop2005}.

\paragraph{Confidentiality} refers to how undisclosed the data and resources are.
Sometimes parts of the system need to be secret and only accessible for a selected group.
Be it for privacy reasons, to avoid disclose personal info, for instance, or even to prevent the exposition of possible vulnerabilities of the system (a pop culture example can be the Death Star Plans on the Star Wars Saga).

\paragraph{Integrity} means how trustworthy the data and resources are.
For example, a new equipment is more trustworthy than an old one. For data traffic, the integrity of the communication may be divided into the integrity of the information sent/received (data integrity) and integrity of identity of the source/recipient (called authentication).

\paragraph{Availability} relates to how accessible to use the data and resources are when desired.
For example, if one control is given to a system, it should be applied to it, and equally, if we need data from a sensor, it must be able to send it.
Furthermore, it is always good to call attention to, as exposed in~\cite{Bishop2005}, that ``an unavailable system is at least as bad as no system at all''.
\\~\\
The vulnerabilities of a system can compromise any of the three pillars, sometimes multiple at the same time. So, let us explore the sources of the vulnerabilities in \cps{}.

\section{Vulnerabilities in \cps{}}

As it is known, \cps{} have its components in both Cyber and Physical domains.
So, as in computer systems, we can divide them into data (the immaterial part) and resources (the material part). We can also divide them into more specific parts such as: \textbf{Transducers}, which are sensors and actuators (as motors, valves, cameras, antennae, thermocouples etc.);
\textbf{Channels}, used for communication (wires, air, tubes etc); \textbf{Connectors}, which connect components by transmitting some physical quantity (wires, circuit traces, cables, water pipes, etc.);
the \textbf{Software}, which is the logic used to operate the physical components (code, \plc{} logic etc.); and the \textbf{Controller}, which is the hardware running the software (\plc{}s, micro-controllers, computers etc.).

~\\Each one of the aforementioned components represents a source of vulnerability.
\\\textbf{Transducers} can be targets of sabotage, for instance an attacker can use a cold object to disrupt thermostat readings to increase the temperature of a room. But the components may also deteriorate with time, which can eventually cause a fault.
\textbf{Channels} and \textbf{connectors} can as well be targets of sabotage, as someone can interfere on the transmission to observe the traffic or intentionally interrupt it. But interruptions and corruptions might be caused by natural accidents such solar flares (causing radio blackouts) or as trees knocking down electricity cables or sharks eating underwater cables.
\textbf{Software} can also be a source of vulnerability due to \emph{bugs}, which can interrupt the normal functioning or even let a \emph{hacker} gain total control of the system.
The \textbf{controller}, if not well dimensioned (computing capacity), can also be a vulnerability.
If it receives more requisitions than expected, the system will be overloaded.

It is worth emphasizing that in a \iot{} context, almost all sensors and actuators have embedded controllers and software, which can also be sources of vulnerabilities themselves.

Attackers can discover some of those vulnerabilities and use them in their favor. Due to this adversary behavior, in this work we will concentrate on attacks, mentioning faults eventually.

\section{Attacks in \cps{}}\label{sec:attacks}

From the definition of cyber-attacks~\cite{Bishop2005} and other
definitions used in this chapter, we can define an attack as an ill-intentioned action which uses vulnerabilities of a cyber-physical system to violate its security.
The perpetrator of the action is called attacker.

In a computer context~\cite{Bishop2005}, \Citeauthor{Bishop2005} divides cyber-attacks into ``four broad classes'':
disclosure, deception, disruption and usurpation.
\textbf{Disclosure} is the unauthorized access to information.
\textbf{Deception} tries to deceit making false data pass as true.
\textbf{Disruption} interrupts or prevents the system to work correctly. And \textbf{usurpation} is the unauthorized control of the system.

In networked control systems~\cite{AminEtAl2009}, the authors divided attacks into only two \textbf{deception} and \textbf{denial of service}, which is equivalent to disruption.

While presumably those definitions may also work for \cps{}, in~\cite{TeixeiraEtAl2015} the authors emphasize the control and physical aspects of \cps{} (sensors, actuators, model dynamics etc) which can be useful for the attacker.
So to categorize aspects they proposed an attack space based on 3 dimensions: Model Knowledge, Disruption resources and disclosure resources.


But in~\cite{TeixeiraEtAl2015}, the authors recover the \CIA{} pillars and categorizes cyber

\cite{DibajiEtAl2019} and ~ use a categorization close to the \CIA{}. It is possible
\todo{model 3 axis of cyber-physical attack space}

use as base
\todo{search zero dynamics attack}
https://ieeexplore.ieee.org/abstract/document/4577833
\cite{CaiEtAl2019,ZhangEtAl2021b}
Two typical attacks \cite{ZhangEtAl2021a}

\subsection{Types}\label{sec:types_of_attacks}
If we use the global vision shown in \S~\ref{sec:topology_trust} we can aggregate the components shown into only two,
\cite{PasqualettiEtAl2013}
\cite{BoemEtAl2020}

but they will always reflect on the channel.


Channel and agent

Middle-man

Deception Attack (Repeat Attack)

DoS

\cite{GuEtAl2016}

\section{Maintaining security}\label{sec:maintaining_security}
It can be achieved by two means: robustness and resilience.

While it can

Robustness can be defined as the ability to withstand perturbations without change in function~\cite{Jen2003}, while resilience
  is the ability to maintain an accepted level of operational normalcy  in  response  to  disturbances,  including  threats  of  an unexpected and malicious nature\cite{Rieger2010}

While robustness is usually passive, resilience is more adaptive, active in order to reestablish a more optimal behavior.
Some robust control approaches used in fault-tolerance can also be used for some kinds of attacks, while usually for specific kinds of attacks new resilient methods need to be created in order to mitigate the effects.
\todo{Naghavi, S. V., Safavi, A. A., \& Kazerooni, M. (2014). Decentralized fault tolerant model
predictive control of discrete-time interconnected nonlinear systems. Journal of the
Franklin Institute, 351(3), 1644–1656.}
which can achieve graceful degradation


\todo{remove}
Some techniques can be applied to create attack/fault-tolerant systems or to robustify the systems against them\cite{DingEtAl2018,SatchidanandanKumar2017}

Due to some similarities, depending on where on the system they happen, some defense techniques based on robustness used for faults may also be used for attacks~\cite{TeixeiraEtAl2015}.



\section{Protecting against Attacks}\label{sec:protecting_against_attacks}
First thing is to assess the risks and see what parts of you system your trust, and what part of the system can be seem as \emph{vulnerable}, or a \emph{threat}.


\paragraph{Trust}

\paragraph{Prevention}
~\\To prevent anomalous behaviors, we secure components that we see as a possible threat due its vulnerabilities.
\\Here we can give some examples.
Tampering of the physical components can be prevented by enclosing them by walls and doors with access control whenever possible~\cite{DingEtAl2018}, preventing the attacker to approach such components.
Faults due to deterioration are prevented usually by a periodical preventive maintenance~\cite{ChenEtAl2021}, and substitution of deteriorated components by new ones.
Attacks and faults caused by software vulnerabilities may be prevented by corrective \emph{patches} that are sent to all users of the software to correct the bugs, or even by software rejuvenation~\cite{GriffioenEtAl2020}, where the system is refreshed with a trusted copy of the original, in case there is a chance it was corrupted.
For communication/transmission, we increase the robustness of the mean, by using better cables with insulation and braided shields for example.
To secure exchanges usually cryptography is used to ensure data integrity and authenticity of agents~\cite{DingEtAl2018}.

\paragraph{Detection}
Use some system knowledge to recognize an anomalous behavior.

\paragraph{Isolation}
Use some  knowledge of the system to recognize what component is the source of the anomalous behavior

\paragraph{Mitigation}





Prevention/Protection
Detection

Isolation
Recovery

It always depend on the question «who/what do you trust/distrust?»

% no see o que se pasa
Some examples are the \emph{blockchain} (mentioned in~\ref{sec:drawbacks}), and cryptographing the signal/data we want to protect.

\subsection{Detection/Isolation}
\emph{watermarking} (where some cryptographed signal is superimposed to the signal we want to secure)~\cite{MoEtAl2015,SatchidanandanKumar2017,KshetriVoas2017,LuciaEtAl2021},
\cite{FortiEtAl2016}

\subsection{Mitigation/Recovery}
For the cases of faults, the main recovery options are disconnecting the malfunctioning components to prevent further consequences or fixing (or substituting) the components.

If disturbance is inside some probabilistic bounds \cite{AnandutaEtAl2020}


% \epigraph{\centering There are few people, however, who, if you told them a result, would be able to evolve from their own inner consciousness what the steps were which led up to that result.}
% {\textit{A Study in Scarlet}\\ \textsc{Sir Arthur Conan Doyle}}

As the hierarchical proposed in~\cite{BraunEtAl2020}, where a regulator (central supervisor) who can detect and exclude suspicious agents.

\todo{\cite{MaestreEtAl2014} Monolithical, multi independent systems}

\begin{description}
  \item[Show examples of Attacks]
  \item[False data injection/communication corruption] Maybe review attacks shown in \cite{VelardeEtAl2017} and how they can be viewed as false data injection attacks (corruption on sent values), \todo{show that since coordinator is oblivious to what happen inside each agent what matters is what it receives, no need to specify exactly the responsible part which generated attack}
\end{description}



\end{document}
