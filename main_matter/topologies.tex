\documentclass[../main.tex]{subfiles}

\begin{document}

\chapter[Topologies, Trust and Responsivity]{Topologies,\\ Trust\\ and \\Responsivity}\label{sec:topoly_trust}
\epigraph{\centering Trust is an illusion, \\M'Lady. \\I believe only in \\mutual self-interest.}
{\textit{Jupiter Ascending}\\\textsc{The Wachowskis}}


When dividing computation into different computing units, some questions are raised:
How to distribute the computation units?
Do they communicate?
How do they influence each other?
How do they communicate?
In this chapter we try to answer these questions.

\minitoc

\section{How to distribute the computation units?}

The distribution of the computation units depends on the system we want to control and the processing power/number of computation units needed to solve.

For example, if the system is large but geographically in the same place, depending on the number of computation units or the processing needed, the units can be in the same hardware (here \GPU, multiple cores, threads and other strategies are used).
However, if the technical constraints (processing power) do not allow, multiple hardware must be used and a physical communication channel is needed to link the processing units.

If the system is geographically diffused and we want to use computing units to control groups of sub-systems, it is straightforward to distribute the computing units in multiple hardware placed strategically to geographically correspond to their respective groups.

For this work, we suppose that the large-scale system we want to control~\eqref{eq:large_scale_system_model} can be decomposed into geographically diffused sub-systems.
Each sub-system will have states $\vec{x}_{i}$ and inputs $\vec{u}_{i}$ that are a partition of the states and inputs of the original $\vec{x}$ and $\vec{u}$.

We suppose the optimization problem we want to use to control the system~\eqref{eq:qp_standard_form} is decomposable.
Not necessarily the computing units used to solve the sub-problems will correspond to each one of the sub-systems (Fig.~\ref{fig:noncorresponding_division_system_problem}).
For instance, a sub-problem may solve a problem with a subset of states of two different sub-systems to find the subset of inputs of a third and fourth sub-systems.

\begin{figure}[h] \centering
  \begin{subfigure}{.4\textwidth}
    \centering
    \def\svgwidth{.8\textwidth}
    \input{../img/noncorresponding_topology.pdf_tex}
    % \includegraphics[width=\textwidth,clip,trim=0cm 1.8cm 0 2.5cm]{../img/noncorresponding_system_problem.png}
    \caption{Non-corresponding.}\label{fig:noncorresponding_division_system_problem}
  \end{subfigure} \hfill
  \begin{subfigure}{.4\textwidth} \centering
    \def\svgwidth{.8\textwidth}
    \input{../img/corresponding_topology.pdf_tex}
    % \includegraphics[width=\textwidth,clip,trim=0cm 1.8cm 0 2.5cm]{../img/corresponding_system_problem.png}
    \caption{Corresponding.}\label{fig:corresponding_division_system_problem}
  \end{subfigure}
  \caption{Decomposition of sub-problems ($P_i$) and
    sub-systems ($S_{i}$).}
\end{figure}

In the literature, it is not unusual to assume that we can choose the computing units in order to correspond to the sub-systems of the system as in Fig.~\ref{fig:corresponding_division_system_problem}~\cite{ArauzEtAl2021}, i.e., a computing unit computes the solution of a sub-problem to find the input of the same corresponding sub-system.
So, in this work we also use this assumption.
Then, the terms sub-problems, sub-systems, agents and units will be used interchangeably.

\section{Representing communication}

To represent and better visualize the agents and how they communicate, we will use graphs. In this section we present a brief introduction on graphs.
The fundamental unit on graph theory is a vertex/node (Fig.~\ref{fig:node}), which for us will represent an agent.
\begin{figure}[h]
  \centering
  \scalebox{1.25}
  {
  \begin{tikzpicture}[node distance=1cm and .5cm,inner sep=1pt]
    \node[draw,circle] (first) at (0,0) {$v_{1}$};
  \end{tikzpicture}
  }
  \caption{A vertex/node.}\label{fig:node}
\end{figure}

The connection between nodes is represented by arcs and edges. While arcs are an ordered pair of vertices, such as ${a=(v_{1},v_{2})}$, indicating a direction, edges are an unorderd pair, not implying direction, as ${e=\{v_{1},v_{2}\}}$.
In Fig.~\ref{fig:arc_edges} we can see edges and arcs.

\begin{figure}[h]
\begin{subfigure}[t]{.45\textwidth}
  \centering
  \scalebox{1.25}{
  \begin{tikzpicture}
    \graph {
      a/$v_{1}$ ->["$a$"] b/$v_{2}$
    };
  \end{tikzpicture}
  }
  \caption{An arc.}
\end{subfigure}
\hfill
\begin{subfigure}[t]{.45\textwidth}
  \centering
    \scalebox{1.25}{
  \begin{tikzpicture}
    \graph {
      a/$v_{1}$ --["$e$"] b/$v_{2}$
    };
  \end{tikzpicture}
  }
  \caption{An edge.}
\end{subfigure}
\caption{Arcs and edges.}\label{fig:arc_edges}
\end{figure}

A directed graph $\graph{G}$ is composed of a set of vertices and a set of arcs ${\set{A}\subseteq\set{V}\times\set{V}}$, written ${\graph{G}=(\set{V},\set{A})}$.
Similarly, an undirected graph $\graph{G}$ is a tuple composed of a set of vertices $\set{V}$ and a set of edges ${\set{E}\subseteq\set{V}\times\set{V}}$, written ${\graph{G}=(\set{V},\set{E})}$.
An undirected graph can be interpreted as a directed graph where each edge $\{v_{i},v_{j}\}$ can be split into two arcs $(v_{i},v_{j})$ and $(v_{j},v_{i})$.
In Fig.~\ref{fig:directed_undirected_graphs} we can see examples of directed and undirected graphs.

\begin{figure}[h]
  \centering
  \begin{subfigure}[t]{.45\textwidth}
    \centering
    \scalebox{1.5}{
    \begin{tikzpicture}
      \graph { subgraph C_n [-!-,n=7, clockwise],
        {1,2,3,5} <- 6,
        {1,2,5} <- 3,
        3 -> 4,
        {1,7} <- 5,
        {2,4} <- 1,
        {6,7} <- 4,
        {4,3} <- 7,

      };
    \end{tikzpicture}
    }
    \caption{Directed graph.}\label{fig:graph}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.45\textwidth}
    \centering
    \scalebox{1.5}{
    \begin{tikzpicture}
      \graph { subgraph K_n [-!-,n=7,clockwise],
        {1,2,3} -- 7,
        {1,2,3} -- 6,
        {1,5,6} -- 4,
      };
    \end{tikzpicture}
      }
    \caption{Undirected graph.}\label{fig:undirected_graph}
  \end{subfigure}
    \caption{Directed and undirected graphs with 7 vertices.}\label{fig:directed_undirected_graphs}
\end{figure}

In an undirected graph two vertices are called adjacent or neighbours if there is an edge linking them.
The neighbourhood $\set{N}$ of a vertex is the set of all the vertices to which it is linked.
We can define a neighbor subgraph $\graph{N}(v)$ of $\graph{G}$ with the neighbors of $v$ and the edges connecting them. For example, taking the graph in Fig.~\ref{fig:undirected_graph}, we can overlay the neighbor subgraph of vertex $6$ in red (Fig.~\ref{fig:neighbor_subgraph}).

\definecolor{emphgraphcolor}{RGB}{232,232,232}
\colorlet{emphgraphcolor}{color-ecole}

\begin{figure}[h]
  \centering
  \scalebox{1.5}{
    \begin{tikzpicture}
      \graph[clockwise,n=7]{
        {1[emphgraphcolor,thick],2[emphgraphcolor,thick],3[emphgraphcolor,thick],4[emphgraphcolor,thick],5,6[emphgraphcolor,thick],7},
        {1,2,3} -- 7,
        {1,2,3} --[emphgraphcolor,thick] 6,
        {1,5} -- 4,
        6 --[emphgraphcolor,thick] 4,
      };
    \end{tikzpicture}
    }
  \caption[Neighbor subgraph of vertex $6$ (in red).]{Graph in Fig.~\ref{fig:undirected_graph} overlayed by neighbor subgraph of vertex $6$ (in red).}\label{fig:neighbor_subgraph}
\end{figure}

For directed graphs the notion of neighborhood can be split into in and out-neighborhoods of a vertex ($\set{N}_{\text{in}}$ and $\set{N}_{\text{out}}$), which are the sets of vertices whose arcs are inbound and outbound, respectively.
A graph that all vertices are neighbors is called a \emph{complete graph} (as in Fig.~\ref{fig:complete_graph}).

\begin{figure}[h]
    \centering
    \scalebox{1.5}{
    \begin{tikzpicture}
      \graph { subgraph K_n [--,n=6,clockwise,empty nodes,nodes={inner sep=4pt}],
      };
    \end{tikzpicture}
      }
    \caption{A complete graph with 6 vertices.}\label{fig:complete_graph}
\end{figure}

A path of length $r$ is a sequence of $r$ edges/arcs connecting two vertices. In Fig.~\ref{fig:a_path} we can see a path of length $2$ between vertices $1$ and $5$.

\begin{figure}[h]
  \centering
  \scalebox{1.5}{
    \begin{tikzpicture}
      \graph[clockwise,n=7]{
        {1,2,3,4,5,6,7},
        {1,2,3} -- 7,
        {1,2,3} -- 6,
        {1,5} --[emphgraphcolor,thick] 4,
        6 -- 4,
      };
    \end{tikzpicture}
    }
  \caption{A path between vertices $1$ and $5$ (in red).}\label{fig:a_path}
\end{figure}

A graph that for all pairs of vertices there is a path is called \emph{connected}, otherwise \emph{disconnected} or \emph{disjoint} (Fig.~\ref{fig:disjoint}).

\begin{figure}[h]
  \centering
  \scalebox{1.5}{
    \begin{tikzpicture}
      \graph[clockwise,n=7,empty nodes,nodes={inner sep=4pt}]{
        {1,2,3,4,5,6,7},
        {1,2} -- 7,
        {1,2} -- 6,
        {5} -- 4,
      };
    \end{tikzpicture}
    }
  \caption{A disjoint graph.}\label{fig:disjoint}
\end{figure}




\section{Do computing units communicate?}

As shown in Section~\ref{sec:decomposable_problems}, the only case where communication is not needed to solve the optimization problem is in the uncoupled case (\S~\ref{sec:uncoupled_problems}).
However, there are some decomposition methods for the \dmpc\ that even with coupled problems, they exploit the robustness properties of the MPC to compute the solution without communication~\cite{VahidNaghaviEtAl2014}.
For the decomposition of some optimization problems, it is shown that in certain circumstances the communication is not necessary~\cite{VoulgarisElia2022}.
\begin{remark}
  Usually in \dmpc\ literature the term «decentralized» refers to frameworks where the agents do not communicate~\cite[\S 4]{ChristofidesEtAl2013},\cite{NegenbornMaestre2014}.
  But the term can be confusing and even in this works it is sometimes ``misused''.
  So, in this work we opt for a different nomenclature, calling those kinds of frameworks as «uncoordinated control», since there is no coordination between agents nor a coordinator agent to referee. We use the term decentralized as opposed to centralized (monolithic), i.e.\ to describe structure instead of communication.
\end{remark}

The most part of the literature uses \emph{coordinated control}~\cite{NegenbornMaestre2014, ArauzEtAl2021}, in this work, analogously, we suppose the agents communicate and the communication graph is connected.

\section{How units influence each other?}

There exists multiple communication schemes. They depend on the decomposition, topology and also trust/power.
When looking at the trust/power axis, we can divide these schemes into two big groups (Fig.~\ref{fig:hierarchic_anarchic}), one where groups of agents are more important than others (\emph{hierarchy}), and another where there is not (\emph{anarchy}).

\begin{figure}[H]
\begin{subfigure}[b]{.45\textwidth}
  \centering
  \scalebox{1.5}{
  \begin{tikzpicture}[node distance=.5cm and .5cm,inner sep=0pt,every node/.style={minimum width=0.1cm}]
    \node[draw,circle,minimum width=.7cm] at (0,0) (first) {};
    \node[draw,circle,below left=of first,minimum width=.4cm] (second_l) {};
    \node[draw,circle,below right=of first,minimum width=.4cm] (second_r) {};

    \node[draw,circle,below left =0.8cm and 0.1cm  of second_l,minimum width=.2cm] (third_1) {};
    \node[draw,circle,below right=0.8cm and -0.0cm of second_l,minimum width=.2cm] (third_2) {};
    \node[draw,circle,right      =1.8cm and 0.5cm    of third_2   ,minimum width=.2cm] (third_3) {};
    \node[draw,circle,below left =0.8cm and -0.0cm of second_r,minimum width=.2cm] (third_4) {};
    \node[draw,circle,below right=0.8cm and 0.1cm  of second_r,minimum width=.2cm] (third_5) {};

    \draw[-]  (first)  -- (second_l);
    \draw[-]  (first)  -- (second_r);
    \draw[-]  (second_l) -- (third_1);
    \draw[-]  (second_l) -- (third_2);
    \draw[-]  (second_l) -- (third_3);
    \draw[-]  (second_l) -- (third_5);
    \draw[-]  (second_r) -- (third_2);
    \draw[-]  (second_r) -- (third_3);
    \draw[-]  (second_r) -- (third_4);
    \draw[-]  (second_r) -- (third_5);
  \end{tikzpicture}
  }
  \caption{Hierarchy.}\label{fig:hierarchy_topology}
\end{subfigure}
\hfill
\begin{subfigure}[b]{.45\textwidth}
  \centering
  \scalebox{1.5}{
  \begin{tikzpicture}[node distance=.5cm and .5cm,inner sep=0pt,every node/.style={minimum width=0.3cm}]
    \node[draw,circle] at (0,0) (a) {};
    \node[draw,circle] at ($(a)+(-.7,-.3)$) (b) {};
    \node[draw,circle] at ($(a)+(0.0,-0.8)$) (c) {};
    \node[draw,circle] at ($(a)+(0.8,-0.4)$) (d) {};
    \node[draw,circle] at ($(b)+(0.1,-1.0)$) (e) {};
    \node[draw,circle] at ($(e)+(1.2,-0.1)$) (f) {};
    \node[draw,circle] at ($(f)+(0.6,0.4)$) (g) {};
    \node[draw,circle] at ($(e)+(-0.8,-0.0)$) (h) {};
    \node[draw,circle] at ($(f)+(-0.5,-0.5)$) (i) {};

    \draw[-]  (a)  -- (b);
    \draw[-]  (a)  -- (c);
    \draw[-]  (a)  -- (d);
    \draw[-]  (b)  -- (c);
    \draw[-]  (c)  -- (d);
    \draw[-]  (e)  -- (b);
    \draw[-]  (e)  -- (c);
    \draw[-]  (c)  -- (f);
    \draw[-]  (d)  -- (g);
    \draw[-]  (f)  -- (g);
    \draw[-]  (e)  -- (h);
    \draw[-]  (f)  -- (i);
  \end{tikzpicture}
  }
  \caption{Anarchy}\label{fig:anarchy_topology}
\end{subfigure}
\caption[Hierarchic and anarchic topologies.]{Hierarchic and anarchic topologies. \\Bigger nodes represent more power/influence over others.}\label{fig:hierarchic_anarchic}
\end{figure}


Sometimes the hierarchical structure may be implied by the decomposition.
\\For instance, some decompositions need the agents to solve their problems one after the other until the values converge (Fig.~\ref{fig:sequential_topology})~\cite{LiuEtAl2009a}.
These schemes are called \emph{sequential}.
We can see a hierarchy among the agents, since although a convergence is reached, one group of agents solve their problems disregard the others, giving them an initial position of power, even if temporary.
\\In other decompositions, all agents solve their problems independently of others and then share results until convergence is reached, iteratively or not (Fig.~\ref{fig:parallel_topology})~\cite{LiuEtAl2010}.
These structures are called \emph{parallel}.
In such structures there is no hierarchy.


\begin{figure}[h]
\begin{subfigure}[b]{.45\textwidth}
  \centering
  \begin{tikzpicture}[node distance=1cm and .5cm]
    \node[draw,circle] (first) at (0,0) {};
    \node[draw,circle,right=of first] (second) {};
    \node[draw,circle,right=of second] (third) {};
    \node[draw,circle,opacity=0,right=of third] (fourth) {};
    \node[draw,circle,right=of fourth] (fifth) {};

    \node[] at (fourth) {...};
    \draw[-latex] (first) -- (second);
    \draw[-latex] (second) -- (third);
    \draw[-latex] (third) -- (fourth);
    \draw[-latex] (fourth) -- (fifth);
  \end{tikzpicture}
  \caption{Sequential topology.}\label{fig:sequential_topology}
\end{subfigure}
\hfill
\begin{subfigure}[b]{.45\textwidth}
  \centering
  % \includegraphics[width=\textwidth]{../img/parallel_topology.png}
  \begin{tikzpicture}[node distance=.5cm and .5cm,inner sep=0pt,minimum width=.5cm]
    \node[draw,rectangle,fill=black,minimum height=2pt,minimum width=5cm] (bar) at (0,0) {};
    % \draw[blue,fill] ($(bar)+(-2.5cm,-2pt)$) rectangle ($(bar)+(2.5cm,2pt)$);
    \node[draw,circle,below=of bar] (third) {};
    \node[draw,circle,left=of third] (second) {};
    \node[draw,circle,left=of second] (first) {};
    \node[draw,circle,opacity=0,right=of third] (fourth) {};
    \node[draw,circle,right=of fourth] (fifth) {};

    \node[] at (fourth) {...};
    \draw[latex-latex]  (first)  -- (bar.south -| first);
    \draw[latex-latex]  (second) -- (bar.south -| second);
    \draw[latex-latex]  (third)  -- (bar.south -| third);
    \draw[latex-latex]  (fifth)  -- (bar.south -| fifth);
  \end{tikzpicture}
  \caption{Parallel topology.}\label{fig:parallel_topology}
\end{subfigure}
\caption{Sequential and parallel topologies.}\label{fig:sequential_parallel_topology}
\end{figure}

And in other decompositions the hierarchical structure can be chosen.
For example, when negotiation between agents is needed, questions about trust and security can shape the presence or absence of hierarchy.
One of these questions is: Can an agent trust all other agents?

This question is common in multiple areas where communication, exchanges or consensus between a large number of agents are needed (politics, economy, and others).
If an agent distrusts the others, it can treat itself the security issues or the agent can outsource the treatment to another agent.
Additional agents can be included to serve as referees, coordinators, regulators or certifiers. It is done because it is easier to trust in/verify a single agent or small group of agents than to trust in all agents. This way the work is divided into more manageable parts.

One real life example can be the \EFT\ between a seller and client~\cite{Staskauskas1988}. A seller instead of trusting the credit (capacity of paying in future date) of each of its clients, she or he trusts in a small group of credit card brands to fulfill the \EFT{}.
Each credit card brand, in turn, trusts in a select group of credit-granting institutions, to which potentially these client are associated.
This kind of arrangement creates a hierarchical tree-like structure called \emph{polytree} in graph theory terms (Fig.~\ref{fig:polytree_topology}). Seller and clients are leafs (terminal nodes), credit card-brands are branch vertex (intermediary) and the credit-granting institutions are roots (no parent nodes). While transactions today happen in a distributed way, still we have these hierarchies.
Some other political/societal parallel views are stablished in~\cite{McNamaraEtAl2018} and~\cite{OlaruEtAl2018}.
\begin{figure}[h]
  \centering
  \scalebox{1.3}{
  \begin{tikzpicture}[every node/.style={circle,draw,minimum width=0.5cm},inner sep=0pt,node distance=1.cm and 0.5cm]
    \node[] (a) at (0,0) {};
    \node[right=of a] (b)  {};
    \node[right=of b] (c)  {};
    \node[right=of c] (d)  {};

    \node[below right=of a] (e)  {};
    \node[right      =of e] (f)  {};
    \node[right      =of f] (g)  {};

    \node[minimum width=0.2cm,below left=1.0cm and .5cm of e] (h)  {};
    \node[minimum width=0.2cm,right     =of h] (i)  {};
    \node[minimum width=0.2cm,right     =of i] (j)  {};
    \node[minimum width=0.2cm,right     =of j] (k)  {};
    \node[minimum width=0.2cm,right     =of k] (l)  {};
    \node[minimum width=0.2cm,right     =of l] (m)  {};

    \draw[-] (a) -- (e);
    \draw[-] (a) -- (g);
    \draw[-] (b) -- (e);
    \draw[-] (b) -- (f);
    \draw[-] (c) -- (e);
    \draw[-] (c) -- (f);
    \draw[-] (c) -- (g);
    \draw[-] (d) -- (g);
    \draw[-] (e) -- (h);
    \draw[-] (e) -- (i);
    \draw[-] (e) -- (j);
    \draw[-] (e) -- (l);
    \draw[-] (f) -- (i);
    \draw[-] (f) -- (j);
    \draw[-] (f) -- (k);
    \draw[-] (f) -- (l);
    \draw[-] (g) -- (m);
  \end{tikzpicture}
  }
  \caption{A polytree.}\label{fig:polytree_topology}
\end{figure}

\section{How units communicate?}
Depending on the problem and the structure, the connection of the nodes can be unidirectional or bidirectional. As said, these connections are represented by arcs and edges as shown in Fig.~\ref{fig:arc_edges}.
While edges are usually more simple to deal, arcs may need some more convoluted ways to prove that the two nodes can somehow communicate (if there is a path between them), or that the algorithm converge~\cite{GarinSchenato2010}.

Another classification of the communication is about the synchronization of the exchanges. Agents can exchange simultaneously (synchronously), or not. In general synchronous communication is the most straightforward, while asynchronous depends on the communication scheme/policy. Broadcast and gossiping~\cite{GarinSchenato2010} are examples of these communication scheme.
\\In the broadcast scheme (a unidirectional scheme), an agent transmits its information to all its out-neighbors ($\set{N}_{\text{out}}$) and each recipient agent updates its local variables.
\\Gossiping can be divided into two, asymmetric and symmetric.
In the asymmetric (unidirectional), an agent chooses one of its out-neighbors, sends its information, and the recipient updates its local variables on the arrival of the message.
On the other hand, in a symmetric case (bidirectional), after updating its variables, the recipient becomes a transmitter, sending its information to the original sender, who updates its local variables.

\todo{In this work we suppose nodes communicate bidirectionally and synchronously.}

\section{Some drawbacks and compromises}\label{sec:drawbacks}

\paragraph{Failure/Robustness}
Although the hierarchical structure can help reducing the sources of distrust, it may also reduce robustness.
Take for example the graph in Fig.~\ref{fig:polytree_topology}, if we remove the $3$ intermediary nodes, the hierarchical tree becomes disconnected.
There is a possibility that the complete system collapses since the communications will not be accomplished.
For decentralized systems with a central unit, this problem is commonly referenced as the \emph{single point of failure}, since removing the central unit collapses the communication and moves the system to a failure state.
This problem is usually deviated by the use of redundancy.
On the other hand, for non-hierarchical structures with more complex topologies than tree-like, they can be more robust.
In graph theory there is what is called f-robustness~\cite{DibajiIshii2015}, which defines how many connections we have to remove to make the graph disconnected.
This definition, as we will see can be used in favor of some decomposition techniques to ensure robustness.

\paragraph{Propagation of information}
It is known that the propagation of information depends on the connectivity of the graphs, that means, to the neighborhood of each node.
For instance, for a network with ring topology (Fig.~\ref{fig:ring_topology}) the more agents there are, more the information takes to be diffused for all nodes.
On the other hand, in a small-world topology (Fig.~\ref{fig:smallworld_topology}), where there are some hubs (in red) propagation is increased.

\begin{figure}[h]
  \begin{subfigure}[t]{.45\textwidth}
    \centering
    \scalebox{1.5}{
    \begin{tikzpicture}
      \graph { subgraph C_n [--,n=10, empty nodes,nodes={inner sep=2.5pt}, clockwise],
      };
    \end{tikzpicture}
    }
    \caption{Ring graph.}\label{fig:ring_topology}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.45\textwidth}
    \centering
    \scalebox{1.5}{
    \begin{tikzpicture}
      \graph[clockwise,n=10,empty nodes,nodes={inner sep=2.5pt}]{
        {1[emphgraphcolor,thick],2,3,4,5,6[emphgraphcolor,thick],7,8,9,10},
        {1 -- 2 -- 3 -- 4 -- 5 -- 6 -- 7 -- 8 -- 9 -- 10 -- 1},
        {1 -- {3,7,8}},
        {6 -- {9,10,4}},
      };
    \end{tikzpicture}
    }
    \caption{Small-world graph.}\label{fig:smallworld_topology}
  \end{subfigure}
  \caption{Ring and small-world graphs.}
\end{figure}

\paragraph{Energy consumption and Environment}
To overcome the problem of trust in anarchic (peer-to-peer) structures, a solution based on cryptography recently in vogue called \emph{blockchain} was proposed~\cite{Nakamoto2008}.
% The strategy targets exchange of validable data that dependend on historic data.
In this solution, all historic data (log) are shared between all agents.
Before beeing sent to all other agents (or only neighbours), new data need to be processed to generate a \emph{proof of work} (proof of a difficult computation which is easy to test) to create a block.
This block needs to be validated (data and \emph{proof of work} are valid) by at least more than half of the agents before beeing chained into the historic data, forming a chain of blocks, thus the name.
In case of multiple chains, the longest chain is always chosen, since it was in it that most \emph{proofs of work} resides. This policy is called the \emph{Longest Chain Rule}.

As each block has a different \emph{proof of work}, to create an new block with unreasonable data, an ill-intentioned agent needs to alter all the past blocks in the chain recreating all \emph{proofs of work} one by one, until the false data could be accepted.
This way, the attacker would need to have more than half of the total processing power of the network, creating the longest chain. This kind of attack is called a 51\% attack or majority attack~\cite{CilloniEtAl2020}.

The \emph{proof of work} strategy trades trust by energy.
A recent work~\cite{ColeCheng2018} estimates the energy consumption of one of the most diffused application of the \emph{blockchain}, a crypto-currency called Bitcoin.
It estimates that each transaction consumes at least $200$kWh, which is greater than the monthly electrical consumption of a small household of two people in Brazil~\cite{EPE2022}.
A more recent work~\cite{RoeckDrennen2022} makes a Life Cycle Assessment of Bitcoin mining in a power plant and concludes that its annual emissions of metric tons of CO$_2$-eq is comparable to the annual emissions of 140,000 passenger vehicles.
\\~\\
% \subsection{Conclusion}
All the points above and many others must be considered before choosing a structure.

% \todo[some??]{Some} works in the literature of \dmpc\ \cite{VelardeEtAl2017a, BoemEtAl2020, LiuEtAl2022} use an anarchic structure.
% Although some methods shown in this work could be adapted to function in analogous structures, we opt to use the hierarchical approach instead. We add coordinator(s) which referee the exchange between agents.

% \chapterEndOrnament

\end{document}
