\documentclass[../main.tex]{subfiles}

\begin{document}

\chapter[Resilient Primal Decomposition-based dMPC]{Resilient \\Primal Decomposition-based \\distributed \\Model Predictive Control}\label{sec:safe_pddmpc_ineq}
\epigraph{\centering Desperate times call for desperate measures}
{\textit{Title}\\\textsc{Author}}

In this chapter, we carry on the work from the last chapter relaxing some assumptions to make the problem to be solved more generic.
We apply the primal decomposition to the problem, and then, we compare the cases when the system presents nominal behavior and when the system is under the proposed attack model.

From the analysis, we notice how the relaxation of the assumption increases drastically the complexity of the problem.

Employing some assumptions, we take a powerful tool of our identification utility belt, and use it to create an approach to circumvent the complexity of the system, allowing us to adapt the detection and mitigation presented in the last chapter.

\minitoc

\section{Relaxing the problem}\label{sec:not-so-scarce}
We begin again with the monolithic \mpc{} equivalent problem~\eqref{eq:qp_standard_form}.
We reproduce yet another time the problem, but with a twist, now the problem also has a decomposable constraint set $\set{U}$:
\begin{equation}
  \label{eq:qp_standard_form_again_set_constraint}
  \begin{aligned}
    \begin{matrix}
      \minimize\limits_{\vec{U}[k]} &
                                                 \frac{1}{2}\norm{\vec{U}[k]}^{2}_{H} + {\vec{f}[k]}^{T}\vec{U}[k] &\\
      \mathrm{subject~ to} & \bar{\Gamma}\vec{U}[k]\preceq {\vec{U}}_{\text{max}} \\
                                    & \vec{U}[k]\in \set{U}
    \end{matrix}
  \end{aligned}.
\end{equation}
We decompose the system using the primal decomposition, and the local problems also have constraint sets, denoted $\set{U}_{i}$:
\begin{equation}
  \label{eq:DOP_local_set_constraint}
  \eqoptobji(\thetaik)[k]=
  \begin{matrix}
    \minimize\limits_{\vec{U}_{i}[k]}&\frac{1}{2}\norm{\vec{U}_{i}[k]}^{2}_{H_{i}} + {\vec{f}_{i}[k]}^{T}\vec{U}_{i}[k]\\
    \mathrm{subject~ to} & \bar{\Gamma}_{i}\vec{U}_{i}[k] \preceq \thetaik:\lambdaik\\
    & \vec{U}_{i}[k]\in \set{U}_{i}
  \end{matrix}.
\end{equation}
\begin{remark}
  As seen in~\cite{BoydEtAl2015}, if we have separable constraints sets, such as the $\set{U}_{i}$ in our problem, we can modify the local objectives $\obji$ so \begin{equation*}
    J_{i}(\optthetai)=\infty\text{, if }\vec{U}_{i}^{\star}\notin\dom{\obji}.
  \end{equation*}
  Since this change modifies the objective functions, it also modifies the corresponding gradients, and $\lambdai$ as consequence.
  So, this change guides the coordinator to choose $\thetai$ which respect $\dom{\obji}$.
\end{remark}

In this chapter, we still assume the original constraint~\eqref{eq:linear_constraint} to have at most as many rows as columns, i.e., $\card{\vec{u}_{\max}}\leq n_{u}$.
However, we relax the assumption made in \S\ref{sec:scarce-systems}.
The systems are not necesserily scarce anymore, i.e., the unconstrained solutions $\vec{U}_{\text{unc}}^{\star}[k]=-H^{-1}\vec{f}[k]$ and $\vec{U}_{i_{\text{unc}}}^{\star}[k]=-H_{i}^{-1}\vec{f}_{i}[k]$ may or may not respect the constraints.

As we will see in next section, despite the relaxation of this assumption, making the problem more generic, it causes the solution of the local problems exponentially more complex.

\todo{Nonetheless, to assure some properties we make another assumption, we assume the unconstrained solutions respect the constraint sets,\note{where to put this?? Maybe when discussing artificial scarcity}
\begin{align}
  \vec{U}_{\text{unc}}^{\star}[k]\in\set{U}\\
  \vec{U}_{i_{\text{unc}}}^{\star}[k]\in\set{U}_{i}.
\end{align}
}

\section{Impact on local problems' solution}\label{sec:impact-local-problem}
We can repeat the analysis made in the last chapter to see how the change on assumption influences the solutions of the problem.

Although now we have \qp{} problems with inequality constraints, we still can use the same method to find a analytical solution.

We similarly define a function $\inequalityfunctionname:\R^{\card\vec{U}_{i}[k]}\times \R^{\card\thetaik}$:
\begin{equation}
  \label{eq:lagrangian_inequality}
  \inequalityfunction=\bar{\Gamma}_{i}\vec{U}_i[k]-\thetaik,
\end{equation}
and use it to put the problem in standard form for inequality constraint \qp{} programs:
\begin{equation}
  \begin{matrix}
  \label{eq:local_problem_equality_standard_notation}
    \minimize\limits_{\vec{U}_{i}[k]}&\obji(\vec{U}_{i}[k],\thetaik)\\
    \mathrm{subject~ to} & \inequalityfunction\preceq 0:\lambdaik
  \end{matrix},
\end{equation}
with variables $\lambdaik$ associated to the constraints.
\begin{remark}
  Usually we make the distinction between the dual variables associated to the inequality and equality constraints by using different symbols.
  However, as in the problems we have only one kind, we use the same symbol and by context the reader can distinguish to which kind the symbol corresponds.
\end{remark}

We can again define the \emph{Lagrangian} function $\lagrangianname : \R^{\card\vec{U}_{i}[k]}\times \R^{\card\lambdaik} \times \R^{\card\thetaik} \to \R$ as
\begin{equation}
  \label{eq:lagrangian_equality}
  \lagrangian=\obji(\vec{U}_{i}[k],\thetaik)+\lambdaik^T\inequalityfunction,
\end{equation}
which embeds the inequality constraint into the objective function using $\lambdaik$, in this case the lagrangian multiplier for \emph{inequality}.
Again, since there is only one type of lagrangian multiplier, we will call it simply as the dual variable.

\begin{remark}
  The complementary slackness still holds, ${\lambdaikstar}^T\inequalityfunctionname(\vec{U}_{i}^{\star}[k],\thetaik)$ will always be zero.
  If any element of $\inequalityfunctionname(\vec{U}_{i}^{\star}[k],\thetaik)$ is greater than zero, the corresponding element on the dual variable $\lambdaikstar$ will be zero, indicating the constraint is inactive.
\end{remark}

We can define the dual function $\dualfunctionname:\R^{\card\lambdaik} \times \R^{\card\thetaik} \to \R$ also calculated by solving
\begin{equation}
  \label{eq:dual_function_equality}
  \dualfunction=\inf_{\vec{U}_{i}[k]\in\set{F}} \lagrangian,
\end{equation}
but now where $\set{F}=\dom \inequalityfunctionname=\bigcap\limits_{i=1}^{\card\vec{U}_{\max}}\set{H}_{i}$, with $\set{H}_{i}$ being the halfspaces
${\set{H}_i=\setbuild{\vec{x}}{\elem[i,\star]{{\bar{\Gamma}}}\vec{x}\leq\elem[i,\star]{\vec{U}_{\max}}}}$.
Using the first order \KKT{} optimality condition we have
\begin{equation}
\nabla_{\vec{U}_{i}[k]}\lagrangian=0
\end{equation}
yielding as well
\begin{equation}
\vec{U}_{i}[k]=-H_{i}^{-1}(-\bar{\Gamma}_{i}^{T}\lambdaik-\vec{f}_{i}[k]).
\end{equation}

Substituting it in $\lagrangian$ results
\begin{equation}
  \label{eq:dual_function_solution_lambda_theta_ineq}
\dualfunction=-\frac{1}{2}\lambdaik^{T}\linearcoefi\lambdaik-\lambdaik^{T}\bar{\Gamma}_{i}H_{i}^{-1}\vec{f}[k]-\lambdaik^{T}\thetaik,
\end{equation}
which is also concave.

Then, similarly we can find $\lambdaikstar$ by solving an optimization problem.
However, since we are using inequalities, we can only have $\lambdaik$ positive~\cite{BoydVandenberghe2004}:
\begin{equation}
  \begin{matrix}
    \lambdaikstar=\argmax\limits_{\lambdaik}\left\{
    \begin{matrix}
    \maximize\limits_{\lambdaik}&\dualfunction\\
      \mathrm{subject~ to}& \lambdaik\preceq\0
    \end{matrix}\right\}.
  \end{matrix}
\end{equation}

As we know, by complementary slackness, the value of the elements of $\lambdaik$ being $0$ (or different of $0$) will depend on the status of the corresponding constraint.
So the value of $\lambdaik$ will depend of the permutation of the status of the inequality constraint.
Depending on the form of the constraints (angle between the normals and equivalent affine term), if we have $n_{\text{ineq}}$ constraints, as each constraint can be active or inactive, we have potentially $2^{n_{\text{ineq}}}$ permutations.
\begin{remark}
  Here we say potentially because not necessarily all combinations are possible.
  In \S\ref{sec:cons-about-stat} we discuss about the number of permutations and show some cases where the number of permutations is not equal to $2^{n_{\text{ineq}}}$.
\end{remark}



\subsection{Considerations about status of constraints}\label{sec:cons-about-stat}
It is important to observe that some sets of constraints in which the permutation is not necessarily $2^{n_{\text{ineq}}}$.

For example, in some cases there is no partition where all constraints are active, i.e., the intersection of halfspaces is empty (see Fig.~\ref{fig:non_feasible}).
Problems with such constraints are infeasible, thus we ignore them in this work.

\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    \def\ang{-35}
    \def\vecmag{.25}
    \node at (0,0) {} coordinate(p1) ++(\ang:2.5) coordinate(p2) ++(\ang-90:1.5) coordinate(p3) ++(\ang-180:2.5) coordinate(p4);

    \path (p1) -- (p2) coordinate[pos=-0.2](a1l) coordinate[pos=1.2](a1r) coordinate[pos=0.8](m12);
    \draw (a1l) -- (a1r);
    \draw[-latex] (m12) -- ($ (m12)!\vecmag!90:(p1) $)node[left]{$\vec{\eta}_1$};

    \path (p3) -- (p4) coordinate[pos=-0.2](a3l) coordinate[pos=1.2](a3r) coordinate[pos=0.8](m34);
    \draw (a3l) -- (a3r);
    \draw[-latex] (m34) -- ($ (m34)!\vecmag!90:(p3) $)node[right]{$\vec{\eta}_2$};

  \end{tikzpicture}
  \caption{Set of constraints with no intersection.}\label{fig:non_feasible}
\end{figure}

In other cases, there is no combination where all constraints are inactive.
We give some different examples.
For instance, for constraints with normals $\vec{\vec{\eta}}_{i}$, if the angles of adjacent halfspaces $\vecangle{\vec{\eta}_{i}}{\vec{\eta}_{j}}$ is $180^{o}$ and the intersection is not nil (see Fig.~\ref{fig:parallel_only_one_active}), one of the constraints will always be active.
\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    \def\ang{25}
    \def\vecmag{.5}
    \node at (0,0) {} coordinate(p1) ++(\ang:2.5) coordinate(p2) ++(\ang-90:1.) coordinate(p3) ++(\ang-180:2.5) coordinate(p4);
    \path[fill=gray!60] (p1) -- (p2) -- (p3) -- (p4);
    \node at (barycentric cs:p1=1,p2=1,p3=1,p4=1) {$\mathcal{P}$};

    \path (p1) -- (p2) coordinate[pos=-0.2](a1l) coordinate[pos=1.2](a1r) coordinate[pos=0.5](m12);
    \draw (a1l) -- (a1r);
    \draw[-latex] (m12) -- ($ (m12)!\vecmag!-90:(p1) $)node[right]{$\vec{\eta}_1$};

    \path (p3) -- (p4) coordinate[pos=-0.2](a3l) coordinate[pos=1.2](a3r) coordinate[pos=0.5](m34);
    \draw (a3l) -- (a3r);
    \draw[-latex] (m34) -- ($ (m34)!\vecmag!-90:(p3) $)node[right]{$\vec{\eta}_2$};
  \end{tikzpicture}
  \caption{Two constraints with $\vecangle{\vec{\eta}_{1}}{\vec{\eta}_{2}}=180^{o}$.}\label{fig:parallel_only_one_active}
\end{figure}

Yet another example, are when the constraints form a convex polyhedron.
We present a minimal example of polyhedron in Fig.~\ref{fig:triangle_inequality}, a triangle in $\R^{2}$ formed by $3$ inequality constraints.
In this case, there will always be at least $2$ active constraints.
\begin{figure}[h]
  \centering
  \begin{tikzpicture}
    \node at (0,0) {} coordinate(p1) ++(15:2.5) coordinate(p2) ++(-45:2.5) coordinate(p3) ++ (-195:4.0) coordinate(p4);
    \path[fill=gray!60] (p1) -- (p2) -- (p3);
    \node at (barycentric cs:p1=1,p2=1,p3=1) {$\mathcal{P}$};

    \foreach \X [count=\Y] in {2,...,4}
    {
      \path (p\Y) -- (p\X) coordinate[pos=-0.2](a\Y{}l) coordinate[pos=1.2](a\Y{}r) coordinate[pos=0.5](m\Y\X);
      \draw (a\Y{}l) -- (a\Y{}r);
      \draw[-latex] (m\Y\X) -- ($ (m\Y\X)!.5!90:(p\X) $)node[right]{$\vec{\eta}_\Y$};
    }
  \end{tikzpicture}
  \caption{A $3$-sided polyhedron.}\label{fig:triangle_inequality}
\end{figure}

Since we suppose there are at most the number of constraints as dimensions, it is not possible to create polyhedrons.
\end{document}
