\documentclass[../main.tex]{subfiles}

\begin{document}
\cleartooddpage[\thispagestyle{empty}]
\phantomsection\addcontentsline{toc}{part}{Appendices}
\originalpart*{Appendices}

% \chapter{Material}
% Here follows a brief description of the material used in this thesis
% \section{Hardware}
% A portable personal computer
% \begin{description}
% \item [Processor] Intel(R) Core(TM) i7-8750H CPU @ 2.20GHz
% \item [Memory] 15GiB System memory
% \end{description}
% \section{OS}
% A GNU/Linux system based on architecture x86\_64 with
% \begin{description}
%     \item[Linux kernel] version 5.4.0-73-generic
%     \item[Ubuntu distribution] version \#82~18.04.1-Ubuntu SMP Fri Apr 16 15:10:02 UTC 2021
% \end{description}

% \section{Programming}
% The programs used in this thesis were developed in MATLAB language.

% They were executed on
% \begin{description}
% \item[MATLAB] version R2019b Update 3 (9.7.0.1261785) 64-bit (glnxa64).
% \end{description}

% All code and resulting data is available in \todo{add github link}.

% The graphs based on the saved data were generated using python scripts, also available.

% The scripts were then executed using
% \begin{description}
% \item[python] version 3.6.9
% \end{description}
% with packages:
% \begin{description}
%     \item[matplotlib] version 3.2.2
%     \item[numpy] version 1.19.0
%     \item[scipy] version 1.3.2
% \end{description}
% \section{Writing}
% This thesis was written using GNU Emacs, typeset using \gls{latex}.

% Diagrams were drawn using \gls{TikZ}.

% Hand drawings were drawn using Xournal++ and Inkscape.

\chapter{Résumé étendu en français}

\section{Contexte et Motivation}\label{sec:cont-et-motiv}

L'évolution de la computation dans les dernières deux décades est indéniable.
Dispositifs avec la même puissance des ordinateurs qui ont possibilité l'humanité à toucher le sol lunaire dans la décade de $1970$ sont aujourd'hui à la distance d'une main.

Cette évolution a proportionné l'utilisation de la commande prédictive~\cite{GarciaEtAl1989}, en anglais
connue comme \mpclong{} ou \mpcshort, en problèmes avec échelles de temps réduites, quelquefois en temps-réel~\cite{BesselmannEtAl2008}, et en utilisant dispositifs plus petits qu'une pièce~\cite{BanguraMahony2014}.

Aussi comme conséquence la \mpc{} est envisagée pour contrôler systèmes dans une myriade d'applications avec l'échelle de villes, comme les réseaux de distribution d'eau~\cite{ZhangEtAl2021}, en anglais
\wdns, et de chaleur~\cite{TaylorEtAl2021}, en anglais \dhns.
Ça présente l'insertion de la \mpc{} dans les systèmes cyber-physiques, en anglais \cps{}, où ordinateurs et machines sont étroitement couplées.

Cependant, pour quelques systèmes de grande échelles, le calcul peut encore être coûteuse, nécessitant de stratégies, comme diviser le calcul en plusieurs dispositfs, à fin de faciliter la computation.
Comme on verra cette stratégie est appelée commande prédictive distribuée, ou \dmpc{}, et cela vient en differents moutures.

Néanmoins, pas trop d'études ont été faites pour la sécurité des stratégies \dmpc{}, quand les agents ne communiquent honnêtement.
Ce travail étudie ce que se passe quand les unités ne travaillent pas ensemble.

Pour illustrer on donne un example d'un réseau \dhn{} avec 4 maisons (Fig.~\ref{fig:houses_resume}) qui n'a pas assez de puissance pour répondre aux nécessités de ses résidents, nécessitant d'un compromis.
\begin{figure}[H]
  \centering
  \begin{tikzpicture}[node distance=.5cm and .75cm,scale=1]
    \node[color=mpc_agent] (house1) at (0,0) {\scalebox{2.5}{\faHome}};
    \node[minimum height=1cm,below=of house1] (medium) {};
    \node[color=mpc_agent,right=of medium] (house2)  {\scalebox{3.5}{\faHome}};
    \node[color=mpc_agent,below=of medium] (house3)  {\scalebox{3}{\faHome}};
    \node[color=mpc_agent,left= of medium] (house4)  {\scalebox{4}{\faHome}};

    \draw[latex-,line width=1pt] (house1) -- (medium.center);
    \draw[latex-,line width=1pt] (house2) -- (medium.center);
    \draw[latex-,line width=1pt] (house3) -- (medium.center);
    \draw[latex-,line width=1pt] (house4) -- (medium.center);
    % \draw[latex-,line width=1pt] (house4) -- (medium.center) node[above,midway] {\large $\vec{u}_{i}(t)$};
    \draw[color=black,fill=mpc_coordinator,] (medium) circle [radius=.2cm];

    % \node[latex-,line width=7pt] at ($(house4) +(-1,1)$) {\large $w_{i}(t)$};
    % \node[latex-,line width=7pt] at ($(house4)$) {$\vec{x}_{i}(t)$};

  \end{tikzpicture}
  \caption{\dhn{} avec $4$ maisons.}\label{fig:houses_resume}
\end{figure}

La commande est faite utilisant \mpc{} décomposée avec un coordinateur e un agent local pour chaque maison. On voit le schéma de communication entre les entités dans la Fig.~\ref{fig:echange_controleurs_coordinateur}.
\begin{figure}[h]
  \centering
  \begin{tikzpicture}[font=\small,thick,node distance=3*0.6180cm and 0.6180cm,every node/.style=rectangle,
    mpcSmall/.style={fill=mpc_agent, minimum height=0.6180*2cm, minimum width=2cm},
    coordinator/.style={fill=mpc_coordinator, minimum height=0.6180*3cm, minimum width=6cm},
    ]

    \node[draw, mpcSmall,] (block1) {\small Maison 1};
    \node[fill=none, draw=none, right=of block1,] (mult) {\bf $\dots$};
    \node[draw, mpcSmall, fill=mpc_agent, right=of mult,] (blockM) {\small Maison M};
    \node[draw, coordinator, below=of mult,] (coordinator) {Coordinateur};

    \draw[-latex,line width=1pt] (block1.south)+(0.4,.0) -- ( coordinator.north -| {$(block1.south)+(0.4,.0)$}) node [right,midway] {$\lambdai[1]$};
    \draw[latex-,line width=1pt] (block1.south)+(-0.4,0) -- (  coordinator.north -| {$(block1.south)+(-0.4,0)$}) node [left,midway] {$\thetai[1]$};
    \draw[-latex,line width=1pt] (blockM.south)+(0.4,.0) -- ( coordinator.north -| {$(blockM.south)+(0.4,.0)$}) node [right,midway] {$\lambdai[M]$};
    \draw[latex-,line width=1pt] (blockM.south)+(-0.4,0) -- (  coordinator.north -| {$(blockM.south)+(-0.4,0)$}) node [left,midway] {$\thetai[M]$};
  \end{tikzpicture}
  \caption{Échange entre contrôleurs locaux et coordinateur.}\label{fig:echange_controleurs_coordinateur}
\end{figure}
Les allocations de ressources $\thetai$ sont proposées pour chaque maison par le coordinateur.
Le contrôleurs locaux respondent avec des indices $\lambdai$ qui indiquent leur satisfaction.
Les allocations sont mises à jour basées sur ces indices jusq'un consensus soit établi.

Dans un certain moment, un des agents, plus spécifiquement celui correspondant à la maison I, commence a modifier la valeur de $\lambdai$ envoyée.
Il l'augmente a chaque jour jusqu'à un jour la commande est arretée due à une manque de consensus entre les agents.

En utilisant des métriques comme les fonctions objectifs, dans laquelle valeures plus petites signifiquent une meilleure perfomance, on peut voir que la performance de l'agent I a amélioré à partir d'une certaine date à la fin d'octobre (Fig.~\ref{fig:change_in_j_resume}).
Par contre, la performance de toutes les autres agents a empiré.
On peut voir aussi dans l'aire hachuré quand le consensus n'est plut trouvé.
\begin{figure}[h]
  \centering
  \includegraphics[width=.8\textwidth]{../img/example_introduction/example_J_fr.pdf}
  \caption{Graphique des fonctions objectifs dans une période de 10 semaines.}\label{fig:change_in_j_resume}
\end{figure}

Cet example simple nous donne les effets d'un attaque: perte de performance et cassure du fonctionnement du système.
Le même peut arriver causé par des fautes.
Motivé par exemples réels comme les black-out de 2010 au Brési~\cite{Conti2010}, l'attaque Stuxnet au Iran en 2011~\cite{Langner2011}, et les attaques à une central électrique en Ukraine in 2016~\cite{Bindra2017} et mal-heusement beaucoup d'autres~\cite{DingEtAl2018,DibajiEtAl2019}, on veut étudier la sécurité des \cps{}.

Dans ce travail on va focaliser sur la securité des \cps{} command par \dmpc{}.

Utilisant la connaisance acquise on propose des méthodes pour sécuriser ses systèmes.

On utilise comme guide les questions suivantes:
\simplebox{
  \begin{itemize} \bfseries
    \item Peut-on detecter l'attaque?
    \item Peut-on identifier l'attaquant?
    \item Peut-ont miniser les effets du dit attaque?
  \end{itemize}
}
Cette thèse a comme objectif répondre ces questions dans un cas spécifique qui sera formalement presenté.
Pour mieux comprendre et répondre ces questions, on divise ce travail en deux parties:

\paragraph{La première partie} (\S\ref{sec:comm-pred-et} à~\ref{sec:comp-anorm}) sert comme une gentille introduction au déssin des \dmpc{}, à sa sécurité et à des attaques.
\newcommand{\tpc}{\textperiodcentered}

Pour un\tpc{}e lecteur\tpc{}ice pas familiarisé\tpc{}e, Section~\ref{sec:comm-pred-et} explique ce qui est une Commande Prédictive et les défis pour la décomposer.
Section~\ref{sec:differents-topologies} discute les topologies possibles pour fair la décomposition.
Section~\ref{sec:comp-anorm} définit comportements anormaux, donne quelques exemples, les catégorise et présente les méthodes pour les prévenir et combattre.

\paragraph{La seconde partie} (\S\ref{sec:vulnerabilites-de-la} à~\ref{sec:comm-pred-resil-1}) contient les contributions de cette thèse.

Section~\ref{sec:vulnerabilites-de-la} présente la décomposition étudié (décomposition primale). On presents ses vulnérabilités et comment elles peuvent affecter la perfomance du système.
On formalise l'example en donnant une approche plus quantitative.
Une fois les vulnérabilités et les possibles effets des attaques découverts, on divise la mitigation en parties plus gérable.
\\ Premièrement en Section~\ref{sec:comm-pred-resil}, on analyse un problème simple, pour qu'on puisse apprécier les possibles difficultés qui peuvent être rencontrées pendant le problème de mitigation.
À partir de cette analyse, on propose des mécanismes de detection et mitigation, suivis par un example académique pour illustrer leur fonctionnement.
\\Après, en Section~\ref{sec:comm-pred-resil-1}, on analyse un problème similaire mais avec un coup de théâtre. Comme on verra, une petite modification du problème inital cause une augmentation exponentiel de sa complexité.
L'analyse de ce nouvel problème résulte une stratégie similaire, mais avec modifications adéquates pour renfermer la nature exponentiel du problème.

Finallement, on conclue le travail avec Section~\ref{sec:conclusion_resume}, où on discute les résultats de l'étude, ses bénéfices et inconvénients.
La discussion ouvre des questions qui peuvent inciter des nouveau travaux.
\subsection{Contributions}
Comme un contribution mineure, on démontre l'étude de la vulnérabilité des \dmpc{} basées sur la décomposition primale, qu'au meilleur de nos connaissance n'a pas jamais été étudié.

Comme contributions majeures, deux stratégies de mitigation pour types différents de système de complexité croissante.

La première pour des systèmes lesquels les ressources ne sont pas suffisants pour répondre aux nécessités des agents locaux, on les appelle \textbf{Systèmes Dépourvus}.

La seconde, pour une classe des systèmes exponentielment plus complexes, où on assume que les demandes locales respect au moins quelques contraintes. On utilise tel hypothèse pour acquérir des informations en utilisant une méthode qu'on appelle \textbf{pénurie artificielle}.

\subsection{Publications}
Les discussion dans cette thèse a donné comme résultats les publications suivantes:
\begin{itemize}
  \item Publiés
        \begin{description}
          \item[\cite{NogueiraEtAl2021}] Conference article for the SysTol'21
          \item[\cite{NogueiraEtAl2022}] Conference article for the NecSys'22
        \end{description}
\end{itemize}

\newpage
\section{Commande Prédictive et sa décomposition}\label{sec:comm-pred-et}

La commande prédictive basée en modèle, ou commande prédictive, ou encore \mpclong{} en anglais, est une stratégie de commande en boucle fermée basée dans la solution des problèmes d'optimisation.
Ayant un modèle du système à commander et une fonction objectif, la stratégie utilise le modèle pour prévoir l'évolution de ses états et computer une séquence optimale de command qui optimise la fonction donnée.
Comme on utilise des problèmes d'optimisation, il est naturel d'ajouter des restriction en forme de contraintes d'égalité et d'inégalité.

Cette stratégie a une place spéciale dans l'industrie et est présente dans une plethora d'applications (gestion d'énérgie~\cite{AnandutaEtAl2018}, commande des quadrotors~\cite{BanguraMahony2014} et autres).

Dans ce travail, on focalise sur la \mpc{} pour des systèmes linéaires avec entrées contraintes.

\subsection{\mpc{} pour des systèmes linéaires}\label{sec:mpc-pour-des}
Comme la \mpc{} est normalement développée en utilisant un ordinateur digital et la transmission des signaux continus peuvent demander une bande passante infinite~\cite{HeEtAl2022}, naturellement on utilise un modèle de temps discret pour le système a commander:
\begin{equation}\label{eq:large_scale_system_model_resume}
  \begin{array}{rclll}
    \vec{x}[k+1]&=&f(\vec{x}[k],\vec{u}[k])&=&A\vec{x}[k]+B\vec{u}[k]\\
    \vec{y}[k]&=&C\vec{x}[k]&&
  \end{array}
\end{equation}
où $\vec{x}[k]\in\R^{n_{x}}$ est l'état du système et $\vec{u}[k]\in\R^{n_{u}}$ est l'entrée.

On suppose que les entrèes du système sont contraintes par des contraintes affines comme
\begin{equation}
  \label{eq:linear_constraint_resume}
  \Gamma\vec{u}[k]\preceq\vec{u}_{\max},
\end{equation}
avec $\Gamma$ de taille adéquate $\R^{\card{\vec{u}_{\max}}\times n_{u} }=\R^{n_{c}\times n_{u} }$.

On suppose qu'on a un objectif de commande $\vec{v}$,
qui peut être \emph{rejeter perturbations}, où ${ \vec{v}[k]=\vec{x}[k] }$, ou \emph{suivi de trajectoire}, où ${ \vec{v}[k]=\vec{w}[k]-\vec{x}[k] }$, soit $\vec{w}[k]$ la trajectoire à suivre.
On utilise comme example le suivi de trajectoire de sortie (utilisant les relations entre $\vec{x}[k]$ et $\vec{y}[k]$), mais tout les résultats de ce travail sont aussi valable pour l'autre objectif.

La \mpc{} trouve une séquence d'entrées ${\vec{U}^{\star}[k]=[\vec{u}^{\star}[0|k];\dots; \vec{u}^{\star}[\predhorz-1|k]]}$ prédite dans un horizon $\predictionSet=\{1\mathbin{:}\predhorz\}$ qui minimiser la fonction ${J:\R^{n_{x}}\times\R^{\predhorz\cdot n_{u}}\to \R}$, définie comme
\begin{equation}
  \label{eq:quadratic_objective_with_sum_resume}
  J(\vec{x}[0|k],\vec{U}[k])=\sum_{i\in\predictionSet}\left[\norm{\mpcvec{v}[ ][i][k]}^{2}_{Q} +\norm{\mpcvec{u}[ ][i-1][k]}^{2}_{R}\right].
\end{equation}
Cette fonction, quand minimisée, doit assurer l'objectif $\vec{v}[k]$ choisi en minisant l'énérgie de l'entrée.
Les matrices ${ Q\in\semidefpos }$ et ${ R\in\defpos }$ sont des poids qui représentent les coûts respectives de chaque terme de l'équation.

En mettant en form matriciel, le problème résolu par la \mpc{} est le suivant
\begin{equation}
  \small
  \begin{aligned}
    \begin{matrix}
      \minimiser\limits_{\vec{U}[k]} &\norm{\vec{V}[k]}^{2}_{\bar{Q}} + \norm{\vec{U}[k] }^{2}_{\bar{R}}&\\
      \mathrm{sous} &
      \vec{x}[i|k]=A\vec{x}[i-1|k]+B\vec{u}[i-1|k]
      &
       \forall i\in\predictionSet \\
      &\bar{\Gamma}\vec{U}[k]\preceq {\vec{U}}_{\text{max}}&

    \end{matrix}
  \end{aligned}
  \label{eq:general_qp}
  \quad,
\end{equation}
où
\begin{align}
  \label{eq:construction_Gamma_resume}
  \bar{\Gamma}&=\kron{I_{\predhorz}}{\Gamma}\\
  \label{eq:construction_Umax_resume}
  \vec{U}_{\max}&=\kron{\1_{\predhorz}}{\vec{u_{max}}}\\
  \bar{Q}&=\kron{I_{\predhorz}}{Q}\\
  \bar{R}&=\kron{I_{\predhorz}}{R}.
\end{align}

En choisissant l'approche \emph{batch}~\cite[Chapter 8.2]{BorrelliEtAl2017}, on peut récrire le problème comme
\begin{equation}
  \label{eq:quadratic_objective_compact_batch_resume}
  \begin{aligned}
    \begin{matrix}
      \minimiser\limits_{\vec{U}[k]} &
      \norm{\vec{U}[k]}^{2}_{H} + 2{\vec{f}[k]}^{T}\vec{U}[k] + c[k] &\\
      \mathrm{sous} & \bar{\Gamma}\vec{U}[k]\preceq {\vec{U}}_{\text{max}}
    \end{matrix}
  \end{aligned}
\end{equation}
où, pour le suivi de trajectoire,
\begin{align}
  \label{eq:construction_H}
H&=\norm{\mathcal{Y}^{u}}^{2}_{\bar{Q}}+\bar{R}\\
\vec{f}[k]&={\mathcal{Y}^{u}}^{T}\bar{Q}(\mathcal{Y}^{x}\vec{x}[0|k]-\vec{W}[k])\\
c[k]&=\norm{\mathcal{Y}^{x}\vec{x}[0|k]}^{2}_{\bar{Q}}-2{\vec{W}[k]}^{T}\bar{Q}{\mathcal{Y}^{x}}\vec{x}[0|k]+\norm{\vec{W}[k]}^{2}_{\bar{Q}}.
\end{align}
avec les prédictions
\begin{equation}
    \begin{matrix}
      \underbrace{
        \left[
          \begin{matrix}
            \vec{y}[1|k] \\
            \vec{y}[2|k] \\
            \vdots \\
            \vec{y}[\predhorz|k]
          \end{matrix}
        \right]
      }_{\textstyle \vec{Y}[k]} &=&
      \underbrace{
        \left[
          \begin{matrix}
            CA^{1} \\
            CA^{2} \\
            \vdots \\
            CA^{\predhorz}
          \end{matrix}
        \right]
      }_{\textstyle \mathcal{Y}^{x}}
      \vec{x}[0|k]+
      \underbrace{
        \left[
          \begin{matrix}
            CA^{0}B & 0 & \dots & 0 \\
            CA^{1}B& \ddots & \ddots & \vdots      \\
            \vdots     & \ddots   & \ddots & \vdots    \\
            CA^{\predhorz-1}B & \dots & \dots & CA^{0}B
          \end{matrix}
        \right]
      }_{\textstyle \mathcal{Y}^{u}}
      \vec{U}[k]
    \end{matrix}
    \quad.
\end{equation}

Si on divise la fonction objectiv par $2$ et on ignore le terme constant $c[k]$, on a la structure standard d'une forme de programmation quadratique, connue comme \qp{}:
\begin{equation}
  \label{eq:qp_standard_form_resume}
  \begin{aligned}
    \begin{matrix}
      \minimiser\limits_{\vec{U}[k]} &
      \frac{1}{2}\norm{\vec{U}[k]}^{2}_{H} + {\vec{f}[k]}^{T}\vec{U}[k] &\\
      \mathrm{sous} &
\bar{\Gamma}\vec{U}[k]\preceq {\vec{U}}_{\text{max}}
    \end{matrix}
  \end{aligned}.
\end{equation}
\begin{remark}\label{rem:equivalence_problems_not_same_objective_resume}
  Observe que les problèmes~\eqref{eq:qp_standard_form_resume} et~\eqref{eq:quadratic_objective_compact_batch_resume} sont equivalents (même solution), mais ils ne sont pas le même problème, alors si on doit calculer la fonction objectif~\eqref{eq:quadratic_objective_compact_batch_resume} on doit utiliser la bonne version.
\end{remark}

La communauté de la \mpc\ utilise beaucoup les \qp{}, une fois qu'existe
une grande quantité de solveurs mathematiques pour les résoudre, on peut citer comme exemples le solveur interne de MATLAB\footnote{\url{https://fr.mathworks.com/help/optim/ug/quadprog.html}}, OSQP\footnote{\url{https://osqp.org}}, MOSEK\footnote{\url{https://www.mosek.com}} et aussi ECOS\footnote{\url{https://github.com/embotech/ecos}}.

Par contre, la solution dans cette forme \textbf{monolithique} peut être intensive au niveau de calcul, dépendant des valeurs de $n_{x}$, $n_{u}$, $n_{c}$ and $\predhorz$.
Pour améliorer la solution on utilise des méthodes de décomposition.
On peut décomposer en différents échelles de temps~\cite{ChenEtAl2011}, utilisant théorie des jeux~\cite{MaestreEtAl2011} ou algorithmes génétiques associés avec des observateur d'états~\cite{XieEtAl2016}.
Mais dans ce travail on utilise des techniques de décomposition basées dans la décompostion de problèmes d'optimisation~\cite{GiselssonEtAl2013}.

\subsection{Décomposition de problèmes d'optimisation}\label{sec:decomp-de-probl}
Comme montré en~\cite{ConejoEtAl2006} et~\cite{BoydEtAl2015}, un problème d'optimisation est décomposable s'il y a plus qu'une variable de decision et on peut le diviser en au moins deux sub-problèmes.

Si les sous-problèmes ne sont pas couplés, on peut les résoudre en parallel et la solution est trouvée, sans aucune interaction entre les sous-problèmes.
Cependant, s'ils sont couplés, on doit utiliser une méthodologie pour trouver la bonne solution.

Les problèmes peuvent être couplés par variables ou par contraintes, ces variables et contraintes sont appelées compliquants.
Comme vue en~\cite{BoydEtAl2015}, une contrainte compliquant le problème peut être transformée en une variable qui complique le problème et vice versa.
Dans ce travail on utilise juste les contraintes compliquantes.

L'idée générale est de prendre un problème décomposable comme
\begin{equation}\label{eq:general_coupled_optimization_problem_resume}
  \small
  \begin{aligned}
    \begin{matrix}
      \minimiser\limits_{\text{variables de decision}}  &\text{objective}_{1}&+&\text{objective}_{2}&\\
      \mathrm{sous} & \text{constraintes}_{1},&&  \text{constraintes}_{2}\\
      &&\text{contraintes compliquantes}_{12}&
    \end{matrix}
  \end{aligned}
\end{equation}
et le récrire comme un problème équivalent avec des variables auxiliaires, comme
\begin{equation}\label{eq:general_coupled_optimization_problem_decomposed_main_problem_resume}
  \small
  \begin{aligned}
    \begin{matrix}
      \minimiser\limits_{\mathop{\operatorname{+}}\limits^{\text{variables de decision}}_{\text{variables auxiliaires}}}  &\text{objective}^{*}_{1}(\text{variables auxiliaires })+\text{objective}^{*}_{2}(\text{variables auxiliaires})&\\
    \end{matrix}
  \end{aligned}
\end{equation}
où $\text{objective}^{*}_{1}(\text{variables auxiliaires})$ et $\text{objective}^{*}_{2}(\text{variables auxiliaires})$ sont calculés en résolvant les sous-problèmes
\begin{subequations}\label{eq:general_coupled_optimization_problem_decomposed}
\begin{equation}\label{eq:general_coupled_optimization_problem_decomposed_1}
    \begin{matrix}
      \minimiser\limits_{\text{variables de decision}_{1}}  &\text{objective}_{1}&\\

      \mathrm{sous} & \text{constraints}_{1}\\
      &\text{contraintes compliquants}_{12_{1}}(\text{variables auxiliaires}_{1})
    \end{matrix}
\end{equation}
\begin{equation}\label{eq:general_coupled_optimization_problem_decomposed_2}
    \begin{matrix}
      \minimiser\limits_{\text{variables de decision}_{2}}  &\text{objective}_{2}&\\

      \mathrm{sous} & \text{constraints}_{2}\\
      &\text{contraintes compliquants}_{12_{2}}(\text{variables auxiliaires}_{2})
    \end{matrix}
\end{equation}
\end{subequations}
dont les solutions dépendent de ces variables auxiliaires ajoutées.
Pour trouver la valeure optimale des variables auxiliaires, il est nécessaire la coordination des sous-problèmes.


Le problème equivalent est appelé \emph{problème principal}, il est résolu par la coordination entre les sous-problèmes en utilisant la mise à jour des variables auxiliaires, appelées \emph{variables d'interface}.
Les méthodes de mis à jour sont basées sur un algorithme d'optimisation, comme
la bisection, plans sécants, ou d'autres méthodes qui utilisent le (sub)gradient ou des approximations.
La dernière classe est la plus utilisée, et quelques exemples sont l'iteration de Arrow-Hurwicz-Uzawa~\cite{BourdaisEtAl2012}, sub-gradient projeté~\cite{BiegelEtAl2012}, et la plus forte descente~\cite{BoydEtAl2011}.
La forme exacte depend de la topologie utilisée (discuté en \S\ref{sec:differents-topologies}).

Les sous-problemès, on les appelle \emph{problèmes locaux}.
Ils sont obtenus en utilisant des méthodes d'equivalence entre problèmes d'optimisation~\cite{BoydVandenberghe2004}, comme le problème original (primal)~\cite{PaulenEtAl2016, CamisaEtAl2022}, le dual ~\cite{MorosanEtAl2011, BourdaisEtAl2012,VelardeEtAl2018}, utilisant des opérateur comme l'opérateur proximal~\cite{Iiduka2019,OconnorVandenberghe2014}, ou d'autres stratégies.

Les \emph{problèmes locaux} ont un ensemble de contraintes formé par les contraintes derivées des contraintes décomposables du problème original, appelées \emph{contraintes locales}, et quelques autres contraintes derivées de la partie compliquante, \emph{contraintes globales d'accouplement}.
La solution de cette partie des contraintes d'accouplement dépendent des variables d'interface.

Les variables d'interface dépendent des problèmes locaux choisis.
Par example, pour des problèmes primaux, normalement les variables duales sont utilisées~\cite{Cohen1978}; pour les problèmes duals, le résidu des contraintes~\cite{BoydEtAl2015}; et pour la méthode d'alternance de direction des multiplicateurs, en anglais \ADMM, variables primales et autres multiplicateurs sont utilisés (la mise à jour de ses multiplicateurs donnent le nom de la méthode)~\cite{BoydEtAl2011}.

Ce travail se concentre à la décomposition primale et utilise le sub-gradient projeté.
Cette décomposition sera expliquée dans une section future (\S\ref{sec:vulnerabilites-de-la}).
Pour d'autres exemples on réfère~\cite{MaestreEtAl2014} ou~\cite{ConejoEtAl2006}.

\newpage
\section{Differents topologies}\label{sec:differents-topologies}
Comme dit, la forme de la décomposition dépend dans la topologie utilisé pour résoudre le problème.
Dans cette section on montre le différentes classification des topologies.

\subsection{Par distribution des unités de computation}\label{sec:par-distribution-des}

La première forme de catégoriser la topologie est par comme on distribue les unités de computation.

Ces unités peuvent être géographiquement séparés ou pas (même hardware) dépendant de l'échelle du \cps{} controllé.
Si le système a une grande échelle et peut être distribué géographiquement, naturellement on essaye de positionner le hardware stratégiquement pour correspondre aux sous-systèmes, mais pas toujours il est possible.
On peut voir dans la Fig.~\ref{fig:corresponding_noncorresponding_resume} des exemples quand les sous-problèmes correspondent ou pas aux sous-systèmes.
\begin{figure}[h] \centering
  \begin{subfigure}{.4\textwidth}
    \centering
    \def\svgwidth{.8\textwidth}
    \input{../img/noncorresponding_topology.pdf_tex}
    % \includegraphics[width=\textwidth,clip,trim=0cm 1.8cm 0 2.5cm]{../img/noncorresponding_system_problem.png}
    \caption{Non correspondant.}\label{fig:noncorresponding_division_system_problem}
  \end{subfigure} \hfill
  \begin{subfigure}{.4\textwidth} \centering
    \def\svgwidth{.8\textwidth}
    \input{../img/corresponding_topology.pdf_tex}
    % \includegraphics[width=\textwidth,clip,trim=0cm 1.8cm 0 2.5cm]{../img/corresponding_system_problem.png}
    \caption{Correspondant.}\label{fig:corresponding_division_system_problem}
  \end{subfigure}
  \caption{Décomposition du problèmes en ($P_i$) et du système en ($S_{i}$).}\label{fig:corresponding_noncorresponding_resume}
\end{figure}

Dans la littérature, c'est normal de choisir les unités de façon que ça correspond comme en Fig.~\ref{fig:corresponding_division_system_problem}~\cite{ArauzEtAl2021}, alors, dans ce travail on considère aussi que les sous-problèmes et sous-systèmes \textbf{correspondent}.
De cette façon, les termes sous-problèmes, sous-systèmes, agents et unités seront utilisés indistinctement.

\subsection{Par communication}\label{sec:par-communication}

Normalement, comme montré en \S\ref{sec:decomp-de-probl}, la communication n'est pas nécessaire si les sous-problèmes ne sont pas couplés.
Cependant, il existe des cas pour la \dmpc{} où on peut exploiter des propriétés de robustess de la \mpc{} pour computer la solution sans communication~\cite{VahidNaghaviEtAl2014}.
Pour d'autres decomposition d'optimisation il est possible montrer que dans certaines circonstances la communication n'est pas nécessaire non plus~\cite{VoulgarisElia2022}.
\begin{remark}
  Généralement, dans la littérature de la \dmpc{} le terme ``décentralisé'' se refère aux méthodes où les agents ne se communiquent~\cite[\S 4]{ChristofidesEtAl2013},\cite{NegenbornMaestre2014}.
  Mais le terme peut être confus et dans certains cas même ``mal-utilisé''.
  Donc, on opte pour une nomenclature différente, an appellant ces méthodes comme ``contrôle non coordonné'', une fois qu'il n'y a pas de coordination entre agents ni un agent coordinateur.
  On utilise le terme ``décentralisé'' comme opposé de ``centralisé'' (monolithique), i.e.\ pour décrire structure au lieu de la communication.
\end{remark}

Comme dans la majorité de la littérature où grande part des contrôles son coordonnés~\cite{NegenbornMaestre2014, ArauzEtAl2021}, dans \textbf{ce travail}, on suppose aussi que les agents se communiquent.
On considère aussi qu'il existe au moins un chemin de communication entre tous les agents (le \textbf{graphe} équivalent est \textbf{connecté}).

\subsection{Par relations de pouvoir}\label{sec:par-relations-de}
Une autre classification est par l'influence que les agents exercent les uns sur les autres.
Par example, quelques agents peuvent avoir plus de pouvoir (être plus importants) qu'autres.
Ce genre de relation est appellé hiérarchique, normalement le pouvoir est démontré par le différentes types d'actions réalisées par les agents.
Normalement les plus importants ont des rôles de médiateur, certificateur, régulateur et etc.
Pour les systèmes où il n'y a pas de différence de comportement ou d'influence entre les agents, on les appelle anarchiques.
Dans Fig.~\ref{fig:hierarchic_anarchic_resume} on voit des exemples de ces deux types de structures.
\begin{figure}[h]
\begin{subfigure}[b]{.45\textwidth}
  \centering
  \scalebox{1.5}{
  \begin{tikzpicture}[node distance=.5cm and .5cm,inner sep=0pt,every node/.style={minimum width=0.1cm}]
    \node[draw,circle,minimum width=.7cm] at (0,0) (first) {};
    \node[draw,circle,below left=of first,minimum width=.4cm] (second_l) {};
    \node[draw,circle,below right=of first,minimum width=.4cm] (second_r) {};

    \node[draw,circle,below left =0.8cm and 0.1cm  of second_l,minimum width=.2cm] (third_1) {};
    \node[draw,circle,below right=0.8cm and -0.0cm of second_l,minimum width=.2cm] (third_2) {};
    \node[draw,circle,right      =1.8cm and 0.5cm    of third_2   ,minimum width=.2cm] (third_3) {};
    \node[draw,circle,below left =0.8cm and -0.0cm of second_r,minimum width=.2cm] (third_4) {};
    \node[draw,circle,below right=0.8cm and 0.1cm  of second_r,minimum width=.2cm] (third_5) {};

    \draw[-]  (first)  -- (second_l);
    \draw[-]  (first)  -- (second_r);
    \draw[-]  (second_l) -- (third_1);
    \draw[-]  (second_l) -- (third_2);
    \draw[-]  (second_l) -- (third_3);
    \draw[-]  (second_l) -- (third_5);
    \draw[-]  (second_r) -- (third_2);
    \draw[-]  (second_r) -- (third_3);
    \draw[-]  (second_r) -- (third_4);
    \draw[-]  (second_r) -- (third_5);
  \end{tikzpicture}
  }
  \caption{Hierarchie.}\label{fig:hierarchy_topology_resume}
\end{subfigure}
\hfill
\begin{subfigure}[b]{.45\textwidth}
  \centering
  \scalebox{1.5}{
  \begin{tikzpicture}[node distance=.5cm and .5cm,inner sep=0pt,every node/.style={minimum width=0.3cm}]
    \node[draw,circle] at (0,0) (a) {};
    \node[draw,circle] at ($(a)+(-.7,-.3)$) (b) {};
    \node[draw,circle] at ($(a)+(0.0,-0.8)$) (c) {};
    \node[draw,circle] at ($(a)+(0.8,-0.4)$) (d) {};
    \node[draw,circle] at ($(b)+(0.1,-1.0)$) (e) {};
    \node[draw,circle] at ($(e)+(1.2,-0.1)$) (f) {};
    \node[draw,circle] at ($(f)+(0.6,0.4)$) (g) {};
    \node[draw,circle] at ($(e)+(-0.8,-0.0)$) (h) {};
    \node[draw,circle] at ($(f)+(-0.5,-0.5)$) (i) {};

    \draw[-]  (a)  -- (b);
    \draw[-]  (a)  -- (c);
    \draw[-]  (a)  -- (d);
    \draw[-]  (b)  -- (c);
    \draw[-]  (c)  -- (d);
    \draw[-]  (e)  -- (b);
    \draw[-]  (e)  -- (c);
    \draw[-]  (c)  -- (f);
    \draw[-]  (d)  -- (g);
    \draw[-]  (f)  -- (g);
    \draw[-]  (e)  -- (h);
    \draw[-]  (f)  -- (i);
  \end{tikzpicture}
  }
  \caption{Anarchie}\label{fig:anarchy_topology_resume}
\end{subfigure}
\caption[Topologies hierarchiques et anarchiques.]{Topologies hierarchiques et anarchiques. \\Noeuds plus grands représentent plus de pouvoir/influence sur autres.}\label{fig:hierarchic_anarchic_resume}
\end{figure}

Quelques fois la structure est impliquée par la décomposition.
Par example, il y a des décomposition où des agents résolvent leur problèmes un après l'autre jusqu'à qu'il aye une convergence
(Fig.~\ref{fig:sequential_topology_resume})~\cite{LiuEtAl2009a}.
Ces schémas sont appelés \emph{séquentiels}.
L'hierarchie est impliqué une fois que le premier agent résout son problème en ignorant les autres, lui donnant, même que juste temporairement, une position de pouvoir.

En quelques autres les agents résolvent ses problèmes indépendamment et partagent quelques résultats jusqu'à un consensus soit trouvé, itérativement ou pas (Fig.~\ref{fig:parallel_topology_resume})~\cite{LiuEtAl2010}.
Ces structure sont appelées \emph{parallèles} et il n'a pas d'hierarchie.
\begin{figure}[h]
\begin{subfigure}[b]{.45\textwidth}
  \centering
  \begin{tikzpicture}[node distance=1cm and .5cm]
    \node[draw,circle] (first) at (0,0) {};
    \node[draw,circle,right=of first] (second) {};
    \node[draw,circle,right=of second] (third) {};
    \node[draw,circle,opacity=0,right=of third] (fourth) {};
    \node[draw,circle,right=of fourth] (fifth) {};

    \node[] at (fourth) {...};
    \draw[-latex] (first) -- (second);
    \draw[-latex] (second) -- (third);
    \draw[-latex] (third) -- (fourth);
    \draw[-latex] (fourth) -- (fifth);
  \end{tikzpicture}
  \caption{Topologie séquentiel.}\label{fig:sequential_topology_resume}
\end{subfigure}
\hfill
\begin{subfigure}[b]{.45\textwidth}
  \centering
  % \includegraphics[width=\textwidth]{../img/parallel_topology.png}
  \begin{tikzpicture}[node distance=.5cm and .5cm,inner sep=0pt,minimum width=.5cm]
    \node[draw,rectangle,fill=black,minimum height=2pt,minimum width=5cm] (bar) at (0,0) {};
    % \draw[blue,fill] ($(bar)+(-2.5cm,-2pt)$) rectangle ($(bar)+(2.5cm,2pt)$);
    \node[draw,circle,below=of bar] (third) {};
    \node[draw,circle,left=of third] (second) {};
    \node[draw,circle,left=of second] (first) {};
    \node[draw,circle,opacity=0,right=of third] (fourth) {};
    \node[draw,circle,right=of fourth] (fifth) {};

    \node[] at (fourth) {...};
    \draw[latex-latex]  (first)  -- (bar.south -| first);
    \draw[latex-latex]  (second) -- (bar.south -| second);
    \draw[latex-latex]  (third)  -- (bar.south -| third);
    \draw[latex-latex]  (fifth)  -- (bar.south -| fifth);
  \end{tikzpicture}
  \caption{Topologie parallèle.}\label{fig:parallel_topology_resume}
\end{subfigure}
\caption{Topologies séquentiel et parallèle.}\label{fig:sequential_parallel_topology_resume}
\end{figure}

Dans d'autres cas, on peut choisir par l'hiérarchie ou anarchie.
Ça dépendant normalement de comment se passent les relations de confiance entre les possibles agents.
On peut choisir faire confiance à quelques agents pour l'échange des informations, ainsi comme on fait dans la vrai vie avec le système financier, agences d'inspection et régulation dans différent domaines.
En~\cite{McNamaraEtAl2018} et~\cite{OlaruEtAl2018}, on voit le parallèle entre les structures de commande et les relations politiques/sociétales.

Dans ce travail on utilise une structure hierarchique qui sera mieux décrite en
\S\ref{sec:vulnerabilites-de-la}.

\subsection{Par type de communication}\label{sec:par-type-de}

Le type de communication peut aussi être utilisé pour catégoriser les topologies,
Les agents peuvent se communiquer uni ou bi-directionnellement.
Si les agents utilisent un schéma de communication bi-directionel, il est plus simple à gérer, une fois qu'ils peuvent se communiquer directement.
Par contre si le schéma est uni-directionel il faut utiliser des autres moyens pour prouver leur comunication (s'il existe un chemin entre eux), ou pour prouver la convergence des algorithmes~\cite{GarinSchenato2010}.

Une autre classification par type de communication c'est si la communication est synchrone ou asynchrone.
En générale, les schémas synchrone sont plus simples, alors que les asynchrone dépendent de politique de communication spécifiques.
Broadcast et gossiping~\cite{GarinSchenato2010} sont des exemples de ce type de communication.
\\Pour le broadcast (uni-directionnel), un agent transmet l'information à tout ses voisins sortant ($\set{N}_{\text{sortie}}$) et chaque destinataire met à jour ses variables locales.
\\Gossiping peut être divisé en deux, asymétrique et symétrique.
La version asymétrique (uni-directionel), l'agent choisit un des ses voisins sortant, et lui envoie l'information, le destinataire met à jour ses variables locales quand le message arrive.
De l'autre côté, dans le cas symétrique (bi-directionel), après avoir mis à jour les variables, le destinataire devient transmetteur, envoyant ses informations au expéditeur original, qui aussi met à jour ses propres variables une fois que ce nouvel message arrive.

Dans ce travail on suppose que les agents se communiquent bi-directionnellement et de manière synchrone.

\newpage
\section{Comportements anormaux}\label{sec:comp-anorm}
Comportements anormaux sont n'import quel comportement ou changement de comportement inattendu d'un système.

Les deux causes principales sont \emph{défauts} et \emph{attaques}.
La différence principale entre les deux est \emph{l'intention}.
Alors que défauts se passent involontairement, non coordonés et sans objectif, attaques sont intentionnel, généralement coordonés avec un objectif malicieuse.

Comme les deux peuvent changer le comportement du système nous sommes intéressés en maintenir l'opération normale des \cps{}.


\subsection{Security}\label{sec:security_resume}
La sécurité évoque l'opération sûre d'un système.
Pour ça, on utilise comme base la définition pour la cyber-sécurité et on l'étend pour les \cps{}.

La \emph{cyber-security} a trois pilliers: confidentialité, intégrité, et disponibilité, en anglais \CIA{}~\cite{Bishop2005}.

\paragraph{Confidentialité} des données et ressources.
Parfois on a besoin de mettre en secret quelques parties du système et on veut qu'il soit acessible pour un groupe privilégié.
Ça peut être pour raisons de privacité, pour eviter la diffusion des données personnels ou pour éviter l'exposition des vulnérabilités du système (un exemple dans la culture pop sont les plans de l'étoile noire de la saga Star Wars).

\paragraph{Intégrité} des données et ressources.
Un équipement nouveau est plus digne de confiance qu'un ancient qui a probablement souffert plus des intempéries.
Dans la transmission de données l'intégrité peut être divisé dans l'intégrité de l'information (l'information reçue est la même qu'a été envoyée) et l'intégrité de l'identité du expéditeur/destinataire (authentification).

\paragraph{Disponibilité} des données et ressources quand demandés par un utilisateur.
Comme mentionné en~\cite{Bishop2005}, ``un système indisponible est au moins aussi mauvais qu'aucun système du tout''.
\\~\\
Les vulnérabilités d'un système peut compromettre n'importe lequel de ces pilliers, parfois multiples au même temps.
\subsection{Vulnérabilités des \cps{}}

Les \cps{} ont des composant des domaines physiques et cyber.
On peut les diviser en partie matériel et immatériel.
Chacune de ces parties sont des points de vulnerabilité d'un \cps{}.

Dispositifs physiques comme des transducteurs (capteur/actionneur) peuvent être cibles de sabotage. Par example un attaquant peut utiliser un objet frais pour changer la lecture des capteurs de témperature d'une salle. Mais ils peuvent aussi se détériorer avec le temps ou d'autres accidents naturelles (chute d'arbres ,glissement de terres, attaques d'animaux, ouragans etc) et causer des défauts.

Le software peut aussi être une source de vulnérabilité à cause des \emph{bogues}, qui peut interrompre le fonctionnement du système ou même permettre un \emph{hacker} de s'infiltrer et gagner accès au système.
L'ordinateur utilisé pour la commande peut être mal dimensionné (puissance de calcul insuffisante), et recevoir plus de requêtes qu'attendu, arrivant à un état de surcharge cessant de répondre.


\subsection{Attaques in \cps{}}\label{sec:attacks_resume}

Il existe plusiers modèles de catégorisation de attaques en \cps{}.
Ici on montre les deux plus connus.
Le premier modèle est basé dans la cyber-security appélé 3D ou \DDDshort par l'acronyme anglais \DDD.
\textbf{Disclosure} est tout accès non autorisé à l'information (rupture de confidentialité).
\textbf{Deception} est l'idée d'utiliser de l'information fausse pour tromper quelqu'un (rupture d'intégrité).
\textbf{Disruption} est l'interruption du fonctionnement du système (rupture de la disponibilité). Aussi on peut ajouter l'\textbf{usurpation} d'identité (rupture de la authenticité).

On définit comme un attaque n'importe laquelle action mal-intentionné qui utilise les vulnérabilités d'un \cps{} à fin de violer sa sécurité.
L'agent est appellé attaquant.

Utilisant comme base~\cite{Bishop2005},~\cite{CardenasEtAl2008},~\cite{AminEtAl2009}, et autres, on peu créer une abstraction des \cps{} dans un réseau (Fig.~\ref{fig:networked_cps_abstraction_resume}).

\begin{figure}[h]
  \centering
\begin{tikzpicture}[node distance=1cm and 2cm,
    box/.style={draw,align=center,minimum height=1.5cm,minimum width=3cm,rectangle,black},
		]

    \node[box] (plant) at (0,0) {Système\\Physique};

    \node[box,below=of plant] (controller)  {Contrôleur};

    \node[draw,cloud,aspect=2,cloud puffs=20,below=1.5cm of controller] (network)  {Réseau};

    \draw[thick] (controller.west) -- ++(-1,0) node (a) {} node [midway,below] {${u}$};
    \draw[thick] (a.center) -- (a.center |- plant.west) node (b) {};
    \draw[-latex,thick] (b.center) -- (plant.west);

    \draw[thick] (plant.east) -- ++(1,0) node (aa) {} node [midway,above] {${y}$};
    \draw[thick] (aa.center) -- (aa.center |- controller.east) node (bb) {} ;
    \draw[-latex,thick] (bb.center) -- (controller.east);

    \draw[latex-,thick,dotted] (controller.south -| network.puff 20) -- +(0,-.25) node (nin) {} ;
    \draw[thick,dotted] (nin.center) -- ($(nin.center) + (0,-1)$) node (nin2) {};
    \draw[thick,dotted] (nin2.center) -- (network.puff 20) {};
    \node at ($(nin2)+(.45,.40)$) {$\mathcal{I}_{\text{ent}}$};

    \draw[latex-,thick,dotted] (network.puff 2) -- +(0,.25) node (nout) {} ;
    \draw[thick,dotted] (nout.center) -- ($(nout.center) + (0,1)$) node (nout2) {};
    \draw[thick,dotted] (nout2.center) -- ( controller.south -| network.puff 2) {};
    \node at ($(nout)+(-.45,.5)$) {$\mathcal{I}_{\text{sort}}$};
  \end{tikzpicture}
  \caption{Abstraction Générale d'un \cps{} dans un réseau.}\label{fig:networked_cps_abstraction_resume}
\end{figure}

Dans le diagramme, $u$ correspond à la commande calculé par le contrôleur et appliquée au système physique à travers des actionneurs. $y$ correspond aux sorties des capteurs du système.
Les signaux $I_{\text{ent}}$ et $I_{\text{sort}}$ sont les informations reçu et envoyées utilisant le réseau (envoyées ou venues d'autres sous-systèmes).

Avec le modèle \DDD{}, on peut catégoriser les attaques par où dans le système ils surviennent.
Dans la Fig.~\ref{fig:attacks_networked_cps_resume} on voit différents types d'attaques énumérés de A1 à A13.
Les attaques de A1 à A4 sont des attaques du type \emph{disclosure}, qui se passent au niveau de l'information.
L'attaquant observe le trafic d'information pour une utilisation postérieure.
Ce genre d'attaque est aussi appellé \textbf{snooping} ou \textbf{eavesdropping} (furetage et écoute illicite).
A5 à A8 representent attaques du type \emph{deception}.
Aussi au niveau informationnel, mais dans ce cas le signaux sont modifiés (representés par un \~{} dans le symbole de la variable).
Les attaques A10 à A12 sont du type \emph{disruption}, quand l'attaquant attaque le canal de c communication, empêchant la communication entre deux entités.
Et finallement, A13 sont des attaques physiques, ou le système physique est attaqué directement.
Cet attaque change physiquement le comportement du système.

\begin{figure}[h]
  \centering
  \begin{tikzpicture}[node distance=1cm and 2cm,
    box/.style={draw,align=center,minimum height=1.5cm,minimum width=3cm,rectangle,black},
		]

    \node[thick,box] (plant) at (0,0) {Système\\Physique};

    \node[thick,box,below=of plant] (controller)  {Contrôleur};

    \node[thick,draw,cloud,aspect=2,cloud puffs=20,below=2.0cm of controller] (network)  {Réseau};

    \draw[thick] (controller.west) -- ++(-1,0) node (a) {} node [midway,below] (input) {$\tilde{u}$};
    \draw[thick] (a.center) -- (a.center |- plant.west) node (b) {};
    \draw[-latex,thick] (b.center) -- (plant.west);
    \node (switch_input) at ($(a)!0.5!(b)$) {};

    \draw[thick] (plant.east) -- ++(1,0) node (aa) {} node [midway,above] (output) {$\tilde{y}$};
    \draw[thick] (aa.center) -- (aa.center |- controller.east) node (bb) {} ;
    \draw[-latex,thick] (bb.center) -- (controller.east);
    \node (switch_output) at ($(aa)!0.5!(bb)$) {};


    \draw[latex-,thick,dotted] (controller.south -| network.puff 20) -- +(0,-.5) node (nin) {} ;
    \draw[thick,dotted] (nin.center) -- ($(nin.center) + (0,-1)$) node (nin2) {};
    \draw[thick,dotted] (nin2.center) -- (network.puff 20) {};
    \node (info_in) at ($(nin)+(.45,-.10)$) {$\widetilde{\mathcal{I}_{\text{ent}}}$};

    \draw[latex-,thick,dotted] (network.puff 2) -- +(0,.5) node (nout) {} ;
    \draw[thick,dotted] (nout.center) -- ($(nout.center) + (0,1)$) node (nout2) {};
    \draw[thick,dotted] (nout2.center) -- ( controller.south -| network.puff 2) {};
    \node (info_out) at ($(nout)+(-.45,-.3)$) {$\widetilde{\mathcal{I}_{\text{sort}}}$};

    \node[red,above right=1cm of aa,inner sep=1pt,align=center] (a1) {\scalebox{1.5}{\faUserSecret}};
    \draw[-latex,thick] (a1) -- (output) node [midway,above,sloped] {{\faEye} A1} node [midway,below,sloped] {{\faPencil} A5};
    % \draw[-latex,thick] ($(a1)+(0,.1)$) -- ($(output)+(0,.1)$)  node [midway,above,sloped] {A1\faEye};
    % \draw[-latex,thick] ($(a1)+(0,-.1)$) -- ($(output)+(0,-.1)$)  node [midway,below,sloped] {A1\faPencil};


    \node[red,right=1.2cm of info_in,inner sep=1pt,align=center] (a2) {\scalebox{1.5}{\faUserSecret}};
    \draw[-latex,thick] (a2) -- (info_in) node [midway,below,sloped] {{\faEye} A2} node [midway,above,sloped] {{\faPencil} A6};

    \node[red,left=1.3cm of info_out,inner sep=1pt,align=center] (a3) {\scalebox{1.5}{\faUserSecret}};
    \draw[-latex,thick] (a3) -- (info_out) node [midway,above,sloped] {A3 {\faEye}} node [midway,below,sloped] {A7 \reflectbox{\faPencil}};


    \node[red,below left=1cm of a,inner sep=1pt,align=center] (a4) {\scalebox{1.5}{\faUserSecret}};
    \draw[-latex,thick] (a4) -- (input) node [midway,above,sloped] {A4 {\faEye}} node [midway,below,sloped] {A8 \reflectbox{\faPencil}};


    \node[red,right=.4cm of switch_output,inner sep=1pt,align=center] (a5) {\scalebox{1.5}{\faUserSecret}};
    \node[inner sep=1pt,align=center] at ($(switch_output) + (.3,0)$) {\rotatebox[origin=c]{180}{\faCut}};
    \node [above,sloped] at ($(a5) + (-.05,-.8)$) {A9};

    \node[red,right=.4cm of nin2,inner sep=1pt,align=center] (a6) {\scalebox{1.5}{\faUserSecret}};
    \node[inner sep=1pt,align=center] at ($(nin2) + (.3,0)$) {\rotatebox[origin=c]{180}{\faCut}};
    \node [above,sloped] at ($(a6) + (-.05,-.8)$) {A10};


    \node[red,left=.4cm of nout2,inner sep=1pt,align=center] (a7) {\scalebox{1.5}{\faUserSecret}};
    \node[inner sep=1pt,align=center] at ($(nout2) + (-.3,0)$) {\rotatebox[origin=c]{0}{\faCut}};
    \node [above,sloped] at ($(a7) + (-.05,-.8)$) {A11};

    \node[red,left=.4cm of switch_input,inner sep=1pt,align=center] (a8) {\scalebox{1.5}{\faUserSecret}};
    \node[inner sep=1pt,align=center] at ($(switch_input) + (-.3,0)$) {\rotatebox[origin=c]{0}{\faCut}};
    \node [above,sloped] at ($(a8) + (-.05,-.8)$) {A12};


    \node[above=.5cm of plant,inner sep=1pt,align=center] (a9) {\hspace{1.5pt}\scalebox{1.5}{\reflectbox{\scalebox{.8}{\faWrench}}{\color{red}\faUserSecret}}};
    \draw[-latex,thick] (a9) -- (plant) node [midway,left] {A13};

\end{tikzpicture}
\caption{Attaques à un \cps{} dans un réseau.}\label{fig:attacks_networked_cps_resume}
\end{figure}

Un autre modèle utilisé est celui présenté par~\cite{TeixeiraEtAl2015}, où les auteurs font valeurs que les attaques ne sont pas pures, ils peuvent être mélangés.
Un attaquer peut, par exemple, enregistrers les informations (attaque \emph{disclosure}) pour utiliser les données acquises pour les renvoyées dans le futur avec intention de tromper le contrôleur (attaque \emph{deception}).
On appelle cet attaque un attaque du type \textbf{Replay}~\cite{ZhuMartinez2014}.
Pour ça les auteurs utilises troix axes pour répérer les types d'attaques, Connaissance du modèle, Perturbation de ressources et divulgation (disclosure) (Fig.~\ref{fig:3_dimensions_attack_resume}).

\begin{figure}[h]
  \centering
  \begin{tikzpicture}[3d view={105}{15},
    grid/.style={very thin,gray},
    axis/.style={-latex,thick},
    cube/.style={very thick,fill=red},
    cube hidden/.style={very thick,dashed,lightgray!70}]

    % draw the axes
    \draw[axis] (0,0,0) -- (2,0,0) node[below left]{Perturbation des ressources};
    \draw[axis] (0,0,0) -- (0,2,0) node (disclosure) {};
    \node[above right=5pt and -10pt] at (disclosure) {Divulgation};
    \draw[axis] (0,0,0) -- (0,0,2) node (model_knowledge) {};
    \node[above] at (model_knowledge) {Connaisance du modèle};

  \end{tikzpicture}
  \caption{Espace d'attaques avec 3 axes.}\label{fig:3_dimensions_attack_resume}
\end{figure}

\newpage
Pour illustrer on peut peupler le space d'attaque avec des différents types d'attaque
(Fig.~\ref{fig:3_dimensions_attack_with_attacks_resume}).

\begin{figure}[h]
  \centering
  \begin{tikzpicture}[3d view={105}{15},
    grid/.style={very thin,gray},
    axis/.style={-latex,thick},
    cube/.style={very thick,fill=red},
    cube hidden/.style={very thick,dashed,lightgray!70}]

    % draw the axes
    \draw[axis] (0,0,0) -- (5,0,0) node[below left]{Perturbation des ressources};
    \draw[axis] (0,0,0) -- (0,5,0) node (disclosure) {};
    \node[above right=5pt and -10pt] at (disclosure) {Divulgation};
    \draw[axis] (0,0,0) -- (0,0,5) node (model_knowledge) {};
    \node[above] at (model_knowledge) {Connaisance du modèle};

    \draw[cube hidden] (2,0,0) -- (2,2,0);
    \draw[cube hidden] (0,2,0) -- (2,2,0);


    \draw[cube hidden] (0,4,4) -- (0,0,4); %% top face
    \draw[cube hidden] (0,4,4) -- (4,4,4); %% top face
    \draw[cube hidden] (4,0,4) -- (4,4,4); %% top face
    \draw[cube hidden] (4,0,4) -- (0,0,4); %% top face

    \draw[cube hidden] (4,4,0) -- (4,4,4); %%
    \draw[cube hidden] (4,4,0) -- (4,0,0);
    \draw[cube hidden] (4,4,0) -- (0,4,0);
    \draw[cube hidden] (0,4,4) -- (0,4,0);
    \draw[cube hidden] (4,0,4) -- (4,0,0);


    \draw[cube hidden] (3,0,4) -- (3,0,0);

    \draw[cube hidden] (0,4,3) -- (0,0,3); %% top face
    \draw[cube hidden] (0,4,3) -- (4,4,3); %% top face
    \draw[cube hidden] (4,0,3) -- (4,4,3); %% top face
    \draw[cube hidden] (4,0,3) -- (0,0,3); %% top face

    \draw[cube hidden] (2,0,1.5) -- (0,0,1.5); %% top face
    \draw[cube hidden] (2,0,1.5) -- (2,0,0); %% top face

    \node[fill,circle,inner sep=1.5pt] (eavesdropping) at (0,.5,0) {};
    \node[fill,circle,inner sep=1.5pt] (zero_dynamics) at (3,0,4) {};
    \node[fill,circle,inner sep=1.5pt] (false_data_injection) at (3,0,3) {};

    \node[fill,circle,inner sep=1.5pt] (dos) at (3,0,0) {};
    \node[fill,circle,inner sep=1.5pt] (covert) at (4,4,4) {};
    \node[fill,circle,inner sep=1.5pt] (soft_modif) at (4,4,3) {};
    \node[fill,circle,inner sep=1.5pt] (topology) at (2,0,1.5) {};

    \node[left=10pt] at (dos) {DoS};
    \node[left=10pt] at (topology) {Topology};
    \node[above right=5pt and -10pt] at (eavesdropping) {Eavesdropping};
    \node[above right=5pt and -30pt] at (covert) {Covert};
    \node[fill,circle,inner sep=1.5pt,label=below:Replay] at (2,2,0) {};
    \node[align=center,right=.2cm] at (soft_modif) {Software\\ Modification};
    \node[above left=5pt and -10pt] at (zero_dynamics) {Zero Dynamics};

    \node[align=center,left=10pt] at (false_data_injection) {False Data\\ Injection};

  \end{tikzpicture}
  \caption{Espace d'attaques peuplé.)}\label{fig:3_dimensions_attack_with_attacks_resume}
\end{figure}

Les attaques montrés dans la figure peuvent être rétrouvés dans les travaux suivants
\begin{description}
\item[\DoS{}]~\cite{SunYang2019,ZhaoEtAl2020,YangEtAl2019}
\item[Topology]~\cite{KimTong2013,WuEtAl2016,ZhangEtAl2021b}.
\item[Software Modification]~\cite{Langner2011}.
\item[\fdi{}]~\cite{PasqualettiEtAl2013}.
\item[Covert],\cite{Smith2015,HoehnZhang2016,BarboniEtAl2020}.
\item[Zero Dynamics]~\cite{TeixeiraEtAl2012,TeixeiraEtAl2015,HoehnZhang2016}
\end{description}

La liste des attaques cités n'est pas extensive mais répresente le attaques plus étudié dans la littérature.
Autres attaques peuvent être trouvé en~\cite{TeixeiraEtAl2015,ZhangEtAl2021b} et dans autres textes cités dasn cette section.

Dans ce travail, nous nous intéressons aux attaques \fdi{}, où avec un peu de connaissance sur le système, l'attaquant modifie le trafique d'informations pour altérer son comportement pour son propre bénéfice.

\subsection{Attaques à la \dmpc{}}\label{sec:attacks_in_dmpc_resume}

Comme montré par~\cite{ArauzEtAl2021}, la sécurité des \cps{} a été étudie au cadre des \mpc{}~\cite{SunYang2019,FranzeEtAl2022}, mais la communauté de la \dmpc{} ne l'a pas étudié suffisamment.

Dans la plupart des travaux les agents coopèrent et aucune vulnérabilité est exploré.
Cependant, dans les dernières années un effort a été fait pour explorer la vulnérabilité de quelques méthodes décomposition, de manière plus perceptible la décomposition duale ~\cite{VelardeEtAl2017b,VelardeEtAl2017a,VelardeEtAl2018,AnandutaEtAl2018,AnandutaEtAl2019,AnandutaEtAl2020} et la décomposition de Jacobi-Gauß~\cite{ChanfreutEtAl2018}.

Dans ces travaux les attaques ne sont pas comme origine un agent externe.
Un (ou un groupe) des agents se comporte de manière non coopérative et essaye de piloter la décomposition de façon a déstabiliser le système ou se bénéficier.
Ces attaques peuvent être appellés \textbf{attaques inter-agents} et parfoir considéré comme \textbf{attaques interne} (comme si un agent interne avec accès suffisant prend contrôle du système).
Normalement les objectives sont accomplis utilisant des attaques du type \emph{deception}.

Les travaux présentent quatre types de attaques \fdi{}, que sont catégorisé à partir d'où l'information est modifiée.
\\L'attaque dénommé \textbf{Selfish} (égoïste) quand l'attaquant modifie sa fonction objectif (généralement la multipliant par une constante positive) pour qu'elle soit plus pénalisée, causant les autres agents d'augmenter ses effort pour équilibrer la désavantage et decroitre le coût local de l'attaquant.
\\L'attaque \textbf{Fake weights} (poids faux), l'agent non-cooperative utilise des poids faux pour sa fonction objectif locale.
L'attaque \emph{selfish} peut être considéré comme un cas spécifique de ce genre d'attaque.
\\Supposant que l'agent suit une référence, dans l'attaque \textbf{false reference} (référence fausse) l'agent malicieux utilise une valeur différente pour la référence pour calculer sa fonction objectif locale.
\\Pour l'attaque \textbf{fake constraints}, l'attaquant utilise des contraintes fausses pour résoudre le problème d'optmisation.
\\Le dernier attaque présenté est le \textbf{``liar'' agent} (agent menteur) où après la fin de la négotiation entre les agents, l'attaquant utilise un contrôle différent de ce qui été convenu.

\subsection{Sécurisant le \cps{}}\label{sec:maintaining_security_resume}
Pour sécuriser le \cps{}, il faut d'abord évalue les vulnérabilités et choisir les plus riquées à être attaquées ou à souffert un défaut.
Des méthodes existent pour diférrent types de systèmes, quelques exemples sont donnés en~\cite{Bishop2005} et~\cite{WangLu2013}.

Après on essaye de protéger les éléments plus susceptibles en utilisant des méthodes de \textbf{prévention}.

Comme exemples de protection on peut citer \emph{renfermer} composants physiques entre parois, et le portes utilisés pour les accéder doivent avoir \emph{contrôle d'accès}.
On peut aussi ajouter des \emph{dispositfs de surveillance} (cameras et des alarmes)~\cite{CardenasEtAl2008,DingEtAl2018}, persuadant l'attaquant à ne pas s'approcher des équipements.
Les défauts causés par \emph{détérioration} sont prévenu par la \emph{maintenance préventive périodique}~\cite{ChenEtAl2021}, et la substitution des composantes détériorées par des nouvelles plus neuves.

Pour chaque vulnérabilité il existe une mésure de prévention, \emph{rajeunissement de  software}~\cite{AlonsoEtAl2012,GriffioenEtAl2020}, et \emph{cryptography}~\cite{DingEtAl2018} sont d'autres méthodes utilisés.

~\\Si la prévention faille, il est nécessaire d'avoir d'autres stratégies.
Dans la littérature, ces statégies sont presque toujours accompagné de deux mots:
robustesse et résilience.
Bien que ces termes sont utilisé indistinctement, dans ce travail on donne des significations un peu différentes.

\textbf{Robustesse} peut être définie par l'habilité de tolérer des perturbation sans changer de fonction~\cite{Jen2003}.
\textbf{Résilience} est l'habilité de maintenir un niveau acceptable d'opération en réponse des perturbations, incluant les ménaces de nature inattendue et malicieuse~\cite{Rieger2010}.

On interprète les méthodes robustes comme des stratégies plus passives, pendant que les méthodes résilientes plus adaptatifs, actifs de façon à rétablir un comportement plus optimal.

Alors, on divise les méthodes en deux catégories: méthodes actives et passives.

\subsection{Stratégies Passives}\label{sec:protecting_against_attacks_resume}
Les méthodes passives sont normalement basées sur le contrôle robuste, où la loi de commande implémentée ne change pas quand en présence des fautes ni d'attaques.

La plupart des méthodes robustes sont utilisé pour la commande tolérante aux défauts, en anglais \ftc{}, par contre, à cause de quelques similarités, ces méthodes sont aussi utilisées contre des attaques~\cite{TeixeiraEtAl2015,DingEtAl2018,ArauzEtAl2021}.

Un exemple c'est pour attaques \fdi{} qui changes une variable et alors utilisant une méthode robuste~\cite{VahidNaghaviEtAl2014} on peut contrôller le système malgré la déviation.

Un autre exemple est pour le réseau de distribution, on utilise un index de sécurité appelé N-1 statique, qui indique quant stable le réseau se comporte quand un des composants présent un défaut (ou est disconnecté)~\cite{QianEtAl2022}.
\citeauthor{VelardeEtAl2018} en~\cite{VelardeEtAl2018} utilisent une solution similaire basée sur la robustesse f des graphes\footnote{Le Graphe maintient la connectivité même si un nombre $f$ d'agents est déconnecté}~\cite{DibajiIshii2015,WangIshii2019} pour créer une \dmpc{} robuste basée sur la décomposition duale.
Pendant la négotiation, les valeurs extrêmes (les f plus petites et plus grandes) sont ignorées.

Encore une autre stratégie est presentée en~\cite{VelardeEtAl2017a,MaestreEtAl2021}, où des scénarios historiques (des trajectoires de la \mpc{}) sont connus avec des probabilités d'occurrence associées sont enregistrées et utilisées pour résoudre le problème avec le calcul des agents, qui peut être peu fiable à cause des attaques.

\subsection{Stratégies Actives}\label{sec:protecting_against_attacks_resume}
Les méthodes actives sont normalement bi-modales.
Un mode pour quand il n'y a pas d'attaque et un autre pour quand le système change de comportement.

À fin d'identifier les comportements anormaux, on a besoin premièrement d'une information de comportement normal du système, par exemple la dynamique de quelques variables, des bornes ou n'importe quel autre information utile.
Avec cette connaisance, on peut superviser les composants menacés et créer des moniteurs.
Cette partie est appellée la phase de \textbf{Détection}, ou l'attaque peut être dectecté à partir des dits moniteurs et détecteurs.
Dans quelques cas la phase est associé d'un pas d'isolation, ou l'agent qui se comporte mal est identifié.

Quand l'attaque est détecté, la loi de commande change pour qu'on puisse mitiger les effets du comportement anormal.
Cette phase est appelée \textbf{Mitigation} ou \textbf{Récupération}.

\subsection{Détection}

La détection peut être catégorisée dans différentes façons.
Si un signal additionnel doit être ajouté, on l'appéle \textbf{détection active} sinon \textbf{détection passive}.

Une autre division est s'elle est basée en événements (\textbf{event-triggered}) ou pas.

On donne~\cite{SunYang2019,HuEtAl2021,SunEtAl2022} comme exemples basés en méthodes du type  \emph{event-triggered}.

Autre catégorisation c'est par l'utilisation de connaisance analytique du système ou par l'utilisation de méthodes d'apprentissage.

Exemples de méthodes actives est le \emph{watermarking} (filigrane) où on surimpose un signal (pseudo) aléatoire d'authentification au signal monitoré~\cite{MoSinopoli2009,MoEtAl2015,SatchidanandanKumar2017,KshetriVoas2017,LuciaEtAl2021}.
Ce méthode est connu pour protèger contre les attaques du type replay, une fois que la semence du signal aléatoire sert comme un générateur unique d'horodatage.

Un exemple passive et analytique sont les the observateurs utilisées en~\cite{HoehnZhang2016} ou les résidus de la dynamique des états~\cite{TeixeiraEtAl2015,BoemEtAl2020}, qui peuvent être associés à un test d'hypothèse~\cite{MoSinopoli2009} (détecteurs $\chi^{2}$), ou encore la détection à partir de la détection d'appartenance à quelques ensembles~\cite{FortiEtAl2016,MaestreEtAl2018}.
D'autres exemples de décteurs sont trouvés en~\cite{PasqualettiEtAl2012,PasqualettiEtAl2013,ZhangEtAl2021a,ArauzEtAl2021}.

Pour les méthodes d'apprentissage, on peut citer~\cite{AnandutaEtAl2018,AnandutaEtAl2019,AnandutaEtAl2020} qui utilises une approche bayésiènne pour apprendre quelques bornes et détecter agents suspects.
Un autre exemple et l'utilisation des réseaux neuronaux/apprentissage profonde
pour créer des détecteurs.
En~\cite{HussainEtAl2021}, les auteurs entraînent un réseau neuronal convolutionnel pour détecter 91\% des attaques \dDoS{} d'un certain genre.

En~\cite{BraunEtAl2020,BraunEtAl2020a}, les auteurs utilisent un problème d'optimisation pour identifier quel partie du système été attaquée.

Encore une autre méthode est d'utiliser le contrôle des coalitions~\cite{ChanfreutEtAl2021} qui peut potentiellement regrouper les agents sains et détecter changements de topologie.

\begin{remark}\label{rem:bounds_and_error_resume}
Comme indiqué en~\cite{ArauzEtAl2021} il est important d'observer que le choix de la borne de détection influencie les faux positifs associés.
\end{remark}

\subsection{Mitigation/Récupération}
La phase de récupération consiste en contrôle de dégâts, modifiant le systme de façon à rétablir le comportement normal.

L'option principale de récupération est la substitution immédiate des composants en mauvais fonctionnement (ou attaqués) par leur redondance (s'il y a une) à fin de prévenir répercussions plus profondes.
Après on peut réparer le composant pour le réutiliser (si possible).

Quand une substition immédiate n'est pas possible, la loi de commande est changée.
Le composant est déconnecté et on utilise des stratégies robustes, qui peuvent mitiger les effets du comportement anormal.
Ces stratégies font le système se comporterr pas forcément de la manière originale, mais d'une manière sub-optimale satisfaisante, jusque la normalité soit restaureée.

Des exemples peuvent être~\cite{MaestreEtAl2018} dans le quel une \mpc{} robuste  utilisant la robustesse \emph{tube-based} est utilisé contre les perturbations dans une zone de sûreté.
Similairement à~\cite{VelardeEtAl2018}, en~\cite{AnandutaEtAl2018,AnandutaEtAl2019,AnandutaEtAl2020} les auteurs basent leur solution dans la robustesse f-local des graphes, où les agents suspects sont ignorés pendant la négotiation de la \dmpc{}.

Une autre option est d'utiliser les stratégies adaptatives qui essayaient d'estimer variables, ou ensembles et les utiliser pour compenser les perturbations causées par les comportement anormaux~\cite{YangEtAl2022,LuEtAl2020}.

\newpage
\section{Comparaison avec état de l'art}\label{sec:comp-avec-etat}
Ce travail utlise~\cite{VelardeEtAl2017b,ChanfreutEtAl2018} comm inspiration pour démontrer les vulnérabilités du méthode de décomposition primale, qui n'ont jamais été présentées.

Comme les autres travaux adjacents, nous nous intéressons par des attaques entre agents du type \textbf{\fdi{}}.
Le modèle exact est présenté dans la prochaîne section.

En~\cite{VelardeEtAl2017b,VelardeEtAl2018}, les auteurs présentent des méthodes robustes baséees sur la théorie des graphes, où l'attaquant n'est pas detecté par soi, mais agents suspects sont déconnectés ou ignorés.
En~\cite{VelardeEtAl2017a,MaestreEtAl2021}, une autre méthode robuste est utilisée, mais cette fois là avec une approche basée sur des scénarios, où séquences suspectes reçoivent poids différents.

Nous optons, par contre, comme dans~\cite{AnandutaEtAl2018,AnandutaEtAl2019,AnandutaEtAl2020}, par une méthode
\textbf{active} et \textbf{résiliente}.
La stratégie est plus détailée dans les prochaines sections, mais pour la détection, on utilise une méthode \textbf{active}, où nous ajoutons des données pour détecter l'attaquant..
On utilise une méthode hybride de connaissance analytiques de la décomposition et aussi des méthodes d'apprentissage pour créer le dit détecteur.
Pour la récupération, on utilise les mêmes connaissances analytiques utilisées pour la détection à fin de réconstruire quelques variables et compenser les perturbations causées par l'attaque.

Comme la liste de travaux adjacents à ce travail est curte, on peut les compiler et comparer dans un tableau.
Le Tab.~\ref{tab:compare_works_resume} compare les travaux avec les méthodes présentées dans cette thèse.

\begin{landscape}
  \vspace*{\fill}
\begin{table}[H]
  \centering
  \begin{tabular}[h]{lccccc}
    \toprule
     & Décomposition & Présente vulnérabilités?  & Résiliente/Robuste & Détection & Mitigation\\
    \midrule
    \parbox{20pt}{\cite{VelardeEtAl2017a}\\ \cite{MaestreEtAl2021}} & Duale & Oui & Robuste (Scénario) & NA & NA\\\\
    \parbox{20pt}{\cite{VelardeEtAl2017b} \\ \cite{VelardeEtAl2018}} & Duale & Oui & Robuste (f-robustesse) & NA & NA\\\\
    \cite{ChanfreutEtAl2018} & Jacobi-Gauß & Oui & -- & -- & --\\\\
    \parbox{40pt}{\cite{AnandutaEtAl2018}\\\cite{AnandutaEtAl2019}\\\cite{AnandutaEtAl2020}} & Duale & Oui & Résiliente& Analyt./Apprent. & Déconnexion (Robustesse)\\\\
    Notre & Primale & Oui & Résiliente & Active Analyt./Apprent. & Reconstruction de données\\
    \bottomrule
  \end{tabular}
  \caption[Comparaison entre travaux adjacents]{Comparaison entre travaux adjacents. NA signifie non applicable.}\label{tab:compare_works_resume}
\end{table}
  \vspace*{\fill}
\end{landscape}

\newpage
\section{Vulnérabilités de la decomposition primale}\label{sec:vulnerabilites-de-la}

\subsection{La \dmpc{} baséee sur la décomposition primale}\label{sec:decomposition_PD_resume}

On prend le problème de la \mpc{} en sa forme monolitique présentée en ~\eqref{eq:qp_standard_form_resume}, et on le divise en $M$ parties de même taille, qui correspondent à une sousdivision du système initial~\eqref{eq:large_scale_system_model_resume}.
La dynamique des sous-systèmes est décrite par des matrices d'état $(A_{i},B_{i},C_{i})$, et sous états $\vec{x}_{i}[k]$, références $\vec{w}_{i}[k]$ et entrées $\vec{u}_{i}[k]$.

On donne un index dans l'ensemble $\set{M}=\{1\mathbin{:}M\}$ pour chaque sous-système et on récrit~\eqref{eq:qp_standard_form_resume} comme
\begin{equation}
  \label{eq:qp_standard_form_decomposable_resume}
  \begin{aligned}
    \begin{matrix}
      \minimiser\limits_{\vec{U}_{1}[k],\dots, \vec{U}_{M}[k]} &
      \sum\limits_{i\in\set{M}}\left[\frac{1}{2}\norm{\vec{U}_{i}[k]}^{2}_{H_{i}} + {\vec{f}_{i}[k]}^{T}\vec{U}_{i}[k]\right]&\\
      \mathrm{sous} & \sum\limits_{i\in\set{M}}\left[\bar{\Gamma}_{i}\vec{U}_{i}[k]\right] \preceq {\vec{U}}_{\text{max}}
    \end{matrix}
  \end{aligned},
\end{equation}
avec des versions locales $\vec{U}_{i}[k]=\left[\vec{u}_{i}[0|k]; \dots; \vec{u}_{i}[\predhorz-1|k]\right]$, $\bar{\Gamma}_{i}$, $H_{i}$ et $\vec{f}_{i}[k]$ des variables presentées en~\S\ref{sec:mpc-pour-des}.

Pour la décomposition primale, on divise~\eqref{eq:qp_standard_form_decomposable_resume} en un problème principal~\eqref{eq:DOP_main_resume} et $M$ problèmes locaux~\eqref{eq:DOP_local_resume} basés sur le problème original (primal)~\eqref{eq:qp_standard_form_decomposable_resume} et utilisant des variables d'interface $\thetaik,\forall i\in\set{M}$:
\begin{subequations}
  \begin{equation}
        \eqoptobji(\thetaik)[k]=
        \begin{matrix}
          \minimiser\limits_{\vec{U}_{i}[k]}&\frac{1}{2}\norm{\vec{U}_{i}[k]}^{2}_{H_{i}} + {\vec{f}_{i}[k]}^{T}\vec{U}_{i}[k]\\
          \mathrm{sous} & \bar{\Gamma}_{i}\vec{U}_{i}[k] \preceq \thetaik:\lambdaik
      \end{matrix}
    \label{eq:DOP_local_resume}
  \end{equation}

  \begin{equation}
    \begin{aligned}
      \eqoptobj[k]=
      \begin{matrix}
        \minimiser\limits_{\mpcvec{\theta}[i][k], \dots, \mpcvec{\theta}[M][k]} &\sum\limits_{i\in\set{M}} J^{\star}_i(\thetaik)\\
        \mathrm{sous} &
          \begin{aligned}
            \quad \sum_{i\in\set{M}}\thetaik\preceq\vec{U}_{\max}\\
          \end{aligned}
      \end{matrix}
    \end{aligned},
    \label{eq:DOP_main_resume}
  \end{equation}
\end{subequations}
où $\lambdaik,\forall i\in\set{M}$ sont des variables duales des problèmes, i.e. les multiplicateurs de Lagrange associés aux contraintes~\cite{BoydVandenberghe2004}.

Le problème~\eqref{eq:DOP_main_resume} est résolu par mises à jour de $\theta_{i}$ jusqu'à une convergence.
La méthode iterative choisie est le sous-gradient projeté, dans laquelle on utilise $\lambdaik$ comme sous-gradient~\cite{BoydVandenberghe2004,BoydEtAl2015}.
La loi de mise à jour est donné par
\begin{equation}
  \label{eq:projectedSubgradient_lambda_resume}
  \vec{\theta}[k]\pplusone=\Proj^{\set{S}}(\vec{\theta}[k]\p+\rho\p\vec{\lambda}[k]\p).
\end{equation}
où
$p$ est un pas d'itération,
$\rho^{(p)}$ est la largeur du pas d'itération\footnote{choisie comme montré en~\cite{ConejoEtAl2006}},
$\vec{\theta}[k]=[\vec{\theta}_{1}[k];\dots;\vec{\theta}_{M}[k]]$,
$\vec{\lambda}[k]=[\vec{\lambda}_{1}[k];\dots;\vec{\lambda}_{M}[k]]$.
La projection est faite sur l'ensemble ${\set{S} = \setbuild{\vec{\theta}[k]}{I_{c}^{M}\vec{\theta}[k]\preceq \vec{U}_{\max}}}$\footnote{${c=\card{\lambdaik}=\card{\thetaik}=\card{\vec{U}_{\max}}=n_{c}\predhorz}$, et
${I_{c}^{M}=\kron{\1_{M}\T}{I_{c}}}$}.

Comme chaque problème~\eqref{eq:DOP_local_resume} peut être résolu en parallèle, une unité de computation est attribuée pour résoudre chaque un des sous-problèmes.
Pour la mise à jour~\eqref{eq:projectedSubgradient_lambda_resume}, les agents ont besoin des $\lambdaik$ des autres agents pour mettre à jour leur propre $\thetaik$.
On pourrait créer une solution anarchique comme celle en~\cite{VelardeEtAl2018}, où l'information $\lambdaik$ circulerait entre les agents et chaque agent mettrait à jour son $\thetaik$.
Cependant, nous avons décidé d'utiliser une structure plus privative.
On a opté pour une solution \textbf{hierarchique}, où un agent agrège les $\lambdaik$ et coordonne les mises à jour des $\thetaik$, on appelle cet agent le \emph{coordinateur}.
De cette façon, chaque agent a accès juste à ses propres valeurs de $\lambdaik$ et $\thetaik$.

On illustre la structure de  communication en Fig.~\ref{fig:dmpc_communication_resume}.
On peut voir la structure hierarchique vu en \S\ref{sec:differents-topologies}.
L'Algorithm~\ref{alg:primal_decomposition_based_dmpc} resume la \dmpc{} basée sur la décomposition primale
\begin{algorithm2e}[h]
  \DontPrintSemicolon%
  \coordinitfr{
    Initialiser $k$, $p$, $p_{\max}$ et $\epsilon$\;
  }
  \Tq{$k\geq 0$}{
    Initialiser ${\thetaik}^{(p)},$ $\forall i\in\set{M}$, tel que ${\vec{\theta}[k]}^{(p)}\in\set{S}$\;
    Coordinateur envoie $\thetaik^{(p)}$ pour tous les agents\;
    \exchangefr{
      \Repeter{$\left[\norm{{\vec{\theta}[k]}^{(p)}-{\vec{\theta}[k]}^{(p-1)}}\leq\epsilon\right]\lor \left[p\geq p_{\max}\right]$}{
        Agents résolvent sous-problèmes~\eqref{eq:DOP_local_resume} et envoient ${\vec{\lambda}_{i}[k]}^{(p)}$ au coordinateur\;
        Coordinateut met à jour les $\vec{\theta}[k]$ utilisant~\eqref{eq:projectedSubgradient_lambda_resume} et les renvoie\;
        $p\gets p+1$\;
      }
    }
    Agents appliquent la dernière commande $\vec{u}_{i}^{\star}[0|k]$ en son sous-système respectif\;
    $k\gets k+1$\;
  }
  \caption{La \dmpc{} basée sur la décomposition primale.}\label{alg:primal_decomposition_based_dmpc_resume}
\end{algorithm2e}

\begin{figure}[H]
  \centering
  \begin{tikzpicture}[font=\small,thick,node distance=3*0.6180cm and 0.6180cm,every node/.style=rectangle,
    mpcSmall/.style={fill=mpc_agent, minimum height=0.6180*2cm, minimum width=2cm},
    coordinator/.style={fill=mpc_coordinator, minimum height=0.6180*3cm, minimum width=6cm},
    ]

    \node[draw, mpcSmall,] (block1) {\small Agent 1};
    \node[fill=none, draw=none, right=of block1,] (mult) {\bf $\dots$};
    \node[draw, mpcSmall, fill=mpc_agent, right=of mult,] (blockM) {\small Agent M};
    \node[draw, coordinator, below=of mult,] (coordinator) {Coordinateur};

    \draw[-latex,line width=1pt] (block1.south)+(0.4,.0) -- ( coordinator.north -| {$(block1.south)+(0.4,.0)$}) node [right,midway] {$\lambda_{1}$};
    \draw[latex-,line width=1pt] (block1.south)+(-0.4,0) -- (  coordinator.north -| {$(block1.south)+(-0.4,0)$}) node [left,midway] {$\theta_{1}$};
    \draw[-latex,line width=1pt] (blockM.south)+(0.4,.0) -- ( coordinator.north -| {$(blockM.south)+(0.4,.0)$}) node [right,midway] {$\lambda_{M}$};
    \draw[latex-,line width=1pt] (blockM.south)+(-0.4,0) -- (  coordinator.north -| {$(blockM.south)+(-0.4,0)$}) node [left,midway] {$\theta_{M}$};
  \end{tikzpicture}
  \caption{Échange entre agents et coordinateur pendant une \dmpc{} basée sur la décomposition primale.}\label{fig:dmpc_communication_resume}
\end{figure}

Si on donne un example, on peut voir la dynamique des $\thetai$ et $\lambdai$ en Fig.~\ref{fig:example_variables_resume}.
\begin{figure}[h]
  \centering
  \begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\textwidth]{../img/example_primal_decomposition/example_theta.pdf}
    \caption{Évolution de $\thetai$.}\label{fig:example_theta_resume}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{../img/example_primal_decomposition/example_lambda.pdf}
    \caption{Évolution de $\lambdai$.}\label{fig:example_lambda_resume}
  \end{subfigure}
    \caption{Évolution des variables pendant procès itératif.}\label{fig:example_variables_resume}
\end{figure}

Les valeurs de $\thetai$ représentent une allocation de l'entréé maximale donnée aux agents par le coordinateur, et $\lambdai$ est une mésure de insatisfaction de chaque agent à la valeur allouée.
Le rôle du coordinateur est de négocier les allocations jusqu'à que tous les agenst soient également insatisfaits.
Le procès itératif est appellé la \textbf{phase de négociation}.

À cause de ce procès d'allocations itératives, autres noms sont donés à la décomposition, comme \textbf{allocation des ressources} ou \textbf{décomposition par quantités}.

\subsection{Attack of interest}\label{sec:attack-interest_resume}

Comme les $\lambdai$ sont les sous-gradients des problème locaux~\eqref{eq:DOP_local_resume}, il est possible de voir qu'ils portent de l'information du problème, i.e.\ il y a d'une certaine façon l'information de la $5$-tuple $(H_{i},\vec{f}_{i}[k],\bar{\Gamma}_{i},\thetaik)$, qu'on appelle l'information locale complète $\set{I}_{i}$.
Alors, les attaques en~\cite{VelardeEtAl2018} (montrés en \S\ref{sec:attacks_in_dmpc_resume}) vont réfléchir en modifications du $\lambdai$.

Pour cette raison, nous nous intéressons en attaques du type \fdi{} entre agents qui modifient leur propre $\lambdai$.

On suppose qu'avant chaque négociation, l'attaquant décide une fonction ${\gamma:\R^{c}\times\R\to \R^{c}}$, pour modifier $\lambdai$ avant de l'envoyer au coordinateur.
Pour faciliter l'analyse on suppose la fonction est linéaire comme
\begin{equation}
  \label{eq:linear_attack_resume}
  \lambdaicheat[k]=\gamma(\lambdaik,k)=\Tik\lambdaik.
\end{equation}

On appelle $\Tik$ la matrice de triche.

Cet attaque peut être interprété comme un cas générale du attaque dit selfish ~\cite{VelardeEtAl2018},
où la constante positive qui multiplie la fonction objectif locale est traduite par une matrice de triche diagonale
\begin{equation}
  \label{eq:selfish_attack}
  \Tik=\tau_{i}[k] I_{c}.
\end{equation}

On illustre avec un example d'un système avec $3$ sous agents.
On fait que l'agent $3$ attaque le système avec~\eqref{eq:linear_attack_resume}.
On simule pour scénarios différents.
Pour chaque scénario, agent $3$ utilise un coefficient de triche $\tau_{3}[k]$ distinct.

En Fig.~\ref{fig:example_vary_tau_objective_resume} et~\ref{fig:example_vary_tau_objective_detail_resume}, on accumule les fonctions objectif locales ${\Jiacc=\sum\limits_{k\in\set{K}}\optobji(\optthetai[k])[k]}$
et aussi l'objectif total ${\Jacc=\sum\limits_{i\in\set{M}}J_{i}^{\text{acc}}}$ pour chaque valeur différent de $\tau_{3}$.

Observe (Fig.~\ref{fig:example_vary_tau_objective_detail_resume}) que $\Jacc$ a sa valeur la plus petite quen $\tau_{3}=1$, i.e., quand il n'y a pas de triche.
Quand $\tau_{3}$ augmente, les fonctions objectif de l'attaquant ($\Jiacc[3]$) décroît au même moment que celles des autres augmentent.
L'opposé se passe pour des valeurs de $\tau_{3}$ entre $0$ et $1$.
Dans ce cas l'attaquant détériore sa propre performance, ce qui ne justifie pas tel attaque, sauf dans un scénario de détournement.

\begin{figure}[h]
  \centering
  \begin{subfigure}{0.50\textwidth}
    \includegraphics[width=\textwidth]{../img/example_primal_decomposition/example_vary_tau_J.pdf}
    \caption{}\label{fig:example_vary_tau_objective_resume}
  \end{subfigure}
  \begin{subfigure}{0.3\textwidth}
    \includegraphics[width=\textwidth]{../img/example_primal_decomposition/example_vary_tau_J_detail.pdf}
    \caption{(detail)}\label{fig:example_vary_tau_objective_detail_resume}
  \end{subfigure}
  \caption{Accumulate objective functions for different values of $\tau_{3}$.}\label{fig:example_vary_tau_objective_both_resume}
\end{figure}

Un autre fait peut être vu dans la zone hachurée en rouge de la Fig.~\ref{fig:example_vary_tau_objective_resume}.
Les fonctions objectif trouvent l'équilibre mais recommencent à augmenter.
Cela est causé par un effondrement de la négociation et les agents n'entrent plus en consensus.
On présente la négociation de $\lambdai$ pour $4$ valeurs différentes de $\tau_{3}$ (Figs.~\ref{fig:example_vary_tau_lambda_resume}).

\begin{figure}[h]
  \centering
  \begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\textwidth]{../img/example_primal_decomposition/example_vary_tau_lambda_tau_1.0.pdf}
    \caption{$\tau_{3}=1$.}\label{fig:example_vary_tau_lambda_tau_1}
  \end{subfigure}
  \begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\textwidth]{../img/example_primal_decomposition/example_vary_tau_lambda_tau_5.0.pdf}
    \caption{$\tau_{3}=5$.}\label{fig:example_vary_tau_lambda_tau_5}
  \end{subfigure}
  \\~\\
  \begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\textwidth]{../img/example_primal_decomposition/example_vary_tau_lambda_tau_20.0.pdf}
    \caption{$\tau_{3}=20$.}\label{fig:example_vary_tau_lambda_tau_20}
  \end{subfigure}
  \begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\textwidth]{../img/example_primal_decomposition/example_vary_tau_lambda_tau_40.0.pdf}
    \caption{$\tau_{3}=40$.}\label{fig:example_vary_tau_lambda_tau_40}
  \end{subfigure}
    \caption{Evolution of $\lambdai$ during negotiation for $k=5$ with different values of $\tau_{3}$.}\label{fig:example_vary_tau_lambda_resume}
\end{figure}
Comme on voit, quand $\tau_{3}$ augmente, la négociation présente un comportement oscillatoire atténué.
L'attenuation diminue si $\tau_{3}$ augmente, jusqu'à la négociation oscille et aucun consensus soit achévé, cassant la \dmpc{} et peut être aussi le système.

\newpage
\section{Commande Prédictive résiliente pour systèmes dépourvus}\label{sec:comm-pred-resil}

\subsection{Systèmes dépourvus sous attaque}\label{sec:syst-depo-sous}

Différemment de~\cite{VelardeEtAl2018,MaestreEtAl2021}, notre solution pour la \dmpc{} sécurisée est résiliente basée sur la détection active utilisant des méthodes d'apprentissage et des connaissances analytiques du problème.  which propose robust solutions, we propose a resilient \dmpc{} based on a hybrid of analytical/learning active detection method.
Alors, on commence par analyser le système sous attaque.

\subsection{Systèmes dépourvus}\label{sec:deprived-systems_resume}
Premièrement, on rappelle le problème équivalent de la \mpc{} en forme monolitique~\eqref{eq:qp_standard_form_resume}, reproduit ici par convenience,
\begin{equation}
  \label{eq:qp_standard_form_again_resume}
  \tag{\ref*{eq:qp_standard_form_resume}}
  \begin{aligned}
    \begin{matrix}
      \minimiser\limits_{\vec{U}[k]} &
                                                 \frac{1}{2}\norm{\vec{U}[k]}^{2}_{H} + {\vec{f}[k]}^{T}\vec{U}[k] &\\
      \mathrm{sous} &
                             \bar{\Gamma}\vec{U}[k]\preceq {\vec{U}}_{\text{max}}
    \end{matrix}
  \end{aligned},
\end{equation}
et on rappelle les problèmes locaux~\eqref{eq:DOP_local_resume} de la décomposition primale,

\begin{equation}
  \label{eq:DOP_local_reprise_resume}
  \tag{\ref*{eq:DOP_local_resume}}
  \eqoptobji(\thetaik)[k]=
  \begin{matrix}
    \minimiser\limits_{\vec{U}_{i}[k]}&\frac{1}{2}\norm{\vec{U}_{i}[k]}^{2}_{H_{i}} + {\vec{f}_{i}[k]}^{T}\vec{U}_{i}[k]\\
    \mathrm{sous} & \bar{\Gamma}_{i}\vec{U}_{i}[k] \preceq \thetaik:\lambdaik
  \end{matrix}.
\end{equation}

Les versions sans contraintes de ces problèmes sont
\begin{align}
  \label{eq:qp_standard_form_unconstrained_resume}
  \begin{aligned}
    \begin{matrix}
      \minimiser\limits_{\vec{U}[k]} &
                                                 \frac{1}{2}\norm{\vec{U}[k]}^{2}_{H} + {\vec{f}[k]}^{T}\vec{U}[k] &\\
    \end{matrix},
  \end{aligned}\\
  \label{eq:DOP_local_unconstrained_resume}
  \begin{aligned}
    \begin{matrix}
    \minimiser\limits_{\vec{U}_{i}[k]}&\frac{1}{2}\norm{\vec{U}_{i}[k]}^{2}_{H_{i}} + {\vec{f}_{i}[k]}^{T}\vec{U}_{i}[k]\\
    \end{matrix},
  \end{aligned}
\end{align}
et ses solutions sont analytiques~\cite{BoydVandenberghe2004}
\begin{align}
  \label{eq:qp_standard_form_unconstrained_solution_resume}
  \optuncU=-H^{-1}\vec{f}[k],\\
  \label{eq:DOP_local_unconstrained_solution_resume}
  \optuncUik=-H_{i}^{-1}\vec{f}_{i}[k].
\end{align}

On appelle un système dépourvu quand la solution sans contrainte $\optuncU$ se situe dehors les frontières du polytope formé par les constraintes pour tout $k$, i.e.,
\begin{equation}
\bar{\Gamma}\optuncU\succ {\vec{U}}_{\text{max}}, \forall k.
\end{equation}

De plus, dans cette section, nous supposons que pour tous les sous-systèmes, leur solutions sans contraintes $\optuncUik$ ne respectent pas les contraintes
\begin{equation}
\bar{\Gamma}_{i}\optuncUik\succ \thetaik, \forall i\in\set{M}, \forall k,
\end{equation}
i.e., même si tous les ressources sont allouées pour un seul sous-système, il n'est pas capable d'achever ses besoin.

Ces hypothèses signifient que la solution optimal de chaque problème nécessiterait beaucoup plus de ressources que le disponible ($\vec{U}_{\max}$).
Alors, les solutions de ces \qp{} sont trouvées par la projection pondérée\footnote{Un problème \qp{} peut être vu comme une projection pondérée, dans laquelle la mésure de l'ensemble est pondérée par $H$ et le point original est décalé utilisant $\vec{f}_i[k]$} des solutions sans contraintes sur le polytope.
Normalement, le résultat se donne au périmètre du polytope.

Alors, avec quelques mises en garde\footnote{Par example, si on suppose que les contraintes forment un cone, il est facilement prouvé géométriquement que le point projeté est l'apex du cone.}, la solution peut être la même que pour un problème avec des contraintes d'égalité
\begin{equation}
  \label{eq:qp_standard_form_equality}
  \begin{aligned}
    \begin{matrix}
      \minimiser\limits_{\vec{U}[k]} &
                                                 \frac{1}{2}\norm{\vec{U}[k]}^{2}_{H} + {\vec{f}[k]}^{T}\vec{U}[k] &\\
      \mathrm{sous} &
                             \bar{\Gamma}\vec{U}[k]= {\vec{U}}_{\text{max}}
    \end{matrix}
  \end{aligned}.
\end{equation}

Si on utilise la décomposition primale on a
\begin{equation}
  \label{eq:example_local_problem_reprise_resume}
   \eqoptobji(\thetaik)[k]= \begin{matrix}
    \minimize\limits_{\vec{U}_{i}[k]}&\frac{1}{2}\norm{\vec{U}_{i}[k]}^{2}_{H_{i}} + {\vec{f}_{i}[k]}^{T}\vec{U}_{i}[k]\\
    \mathrm{subject~ to} & \bar{\Gamma}_{i}\vec{U}_{i}[k] = \thetaik:\lambdaik
  \end{matrix}
\end{equation}
comme problèmes locaux et pour la mise à jour on développe la projection pour une intersection de hyperplans résultant
\begin{equation}
  \label{eq:example_projectedSubgradient_lambda_reprise_resume}
 \thetai\pplusone=\thetai\p+\rho\p\left(\lambdai\p-\frac{1}{M}\sum_{j=1}^{M}\vec{\lambda}_j\p\right),\forall i\in\set{M}.
\end{equation}

Ces équations seront utilisées pour une brève analyse du système sous attaque.
\begin{remark}
  On utilise des systèmes dépourvus, car quand en manque de ressources, les agents doivent faire le compromis.
  Ça instigue la compétition entre eux et éventuellement des comportements égoïstes.
  Si ses besoins étaient achévés, il n'aurait pas de motivation pour une triche, tous les agents seraient satisfaits.
\end{remark}

\subsection{Analysises des problèmes locaux}\label{sec:analysis-local-problems_resume}
Comme les problèmes~\eqref{eq:example_local_problem_reprise_resume} sont des \qp{} avec des contraintes d'égalité, on peut trouver une solution analytique~\cite{BoydVandenberghe2004}.

En se basant sur la dualité Lagrangienne on est capable de trouver aussi une solution analytique pour $\lambdaik$.
En calculant le Lagrangien et quelques gradients pour achever les conditions d'optimalité de \KKT{} on a
\begin{equation}
  \label{eq:lambda_function_theta_resume}
  \lambdaik=-\Plin\thetaik-\sik,
\end{equation}
où $\Plin={(\linearcoefi)}^{-1}$ et $\sik=\Plin\bar{\Gamma}_{i}H_{i}^{-1}\vec{f}_{i}[k]$.

Comme attendu, $\lambdaik$ depend de $\thetaik$.
De plus, à cause de la forme quadratique, la solution est affine.

\begin{remark}
  On peut remarquer, comme dit avant la solution intègre les information de la fonction objectif (présence de $H_{i}$ et $\vec{f}_{i}[k]$), et aussi des constraintes (présence de $\bar{\Gamma}_{i}$ et $\thetaik$).
\end{remark}

\subsection{Analyse de la négociation}\label{sec:analysis-negotiation_resume}
Utilisant~\eqref{eq:example_projectedSubgradient_lambda_reprise_resume} et~\eqref{eq:lambda_function_theta_resume}, on peut observer les dynamiques de $\thetai$ et $\lambdai$ pendant la négociation.
Cette analyse donne des idées pour une méthode future de détection et mitigation.

\subsubsection{Dynamique de $\lambdai$}
Si on substitue~\eqref{eq:example_projectedSubgradient_lambda_reprise_resume} en~\eqref{eq:lambda_function_theta_resume}, on a pour chaque sous-système
\begin{equation}
  \label{eq:lambda_dynamics}
\lambdai\pplusone=-\Plin\left(\thetai\p+\rho\p\left(\lambdai\p-\frac{1}{M}\sum_{j=1}^{M}\vec{\lambda}_j\p\right)\right)-\sik.
\end{equation}

En forme matricielle on a la dynamique complète
\begin{equation}
  \label{eq:negotiation_equation_substituting_organizing_matrix_lambda_resume}
  \vec{\lambda}\pplusone=\mathcal{A}_{\lambda}\vec{\lambda}\p,
\end{equation}
où
\begin{equation}
\mathcal{A}_{\lambda}=\left[
\begin{matrix}
I-\frac{M-1}{M}\rho\p \Plin[1] & \frac{1}{M}\rho\p \Plin[1]&\dots&\frac{1}{M}\rho\p \Plin[1]\\
\frac{1}{M}\rho\p \Plin[2]&I-\frac{M-1}{M}\rho\p \Plin[2]&\dots&\frac{1}{M}\rho\p \Plin[2]\\
\vdots&\vdots&\ddots&\vdots\\
\frac{1}{M}\rho\p \Plin[M]&\frac{1}{M}\rho\p \Plin[M]&\dots&I-\frac{M-1}{M}\rho\p \Plin[M]\\
\end{matrix}
\right].
\end{equation}

On voit que c'est un système à temps discret, en anglais \dt{}, homogène.
Le système varie avec le temps, à cause de $\rho$, mais on peut le choisir de façon qu'il disparaisse quand $p\to\infty$.
Alors, on peu utiliser le critère de Lyapunov~\cite[\S8.6]{Hespanha2009}, i.e., les valeurs propres de $\mathcal{A}_{\lambda}$ doivent être dans le cercle unitaire pour que le système soit stable.
Pour des systèmes petits, on peut utiliser le critère de Jury~\cite{Jury1962} pour vérifier ça.

Analisant $\mathcal{A}_{\lambda}$ encore, on voit que la somme des ses colonnes est égale a un\footnote{$I+\frac{M-1}{M}\rho\p \Plin+\sum\limits_{j=1}^{M-1}\frac{1}{M}\rho\p \Plin=I$},
signifiant que $1$ est une valeur propre par la droite $\mathcal{A}_{\lambda}$:
\begin{equation*}
  \mathcal{A}_{\lambda}\1=\1
\end{equation*}
Alors, si on suppose que les autres valeurs propres sont dedans le cercle unitaire, le système converge à un état $\1c$, i.e., où tous les $\lambdaik$ sont égaux~\cite{GarinSchenato2010,XiaoEtAl2007}.
Par contre, la somme des lignes n'est pas égal, alors la somme des états n'est pa constante, où comme dit dans la communauté des algorithmes de consensus, la masse n'est pas conservée.
De cette façon, on ne pourrait pas utiliser des stratégies de consensus moyen, sauf si tous les systèmes avaient le même $\Plin$, ce qui rendrait le problème extrêmement pas intéressent (la solution serait de diviser les ressources également entre les sous-systèmes).

Si le système est sous attaque, on utilise le modèle~\eqref{eq:linear_attack_resume},
\begin{equation}
  \label{eq:linear_attack_reprise_resume}
  \tag{\ref*{eq:linear_attack_resume}}
  \lambdaicheat[k]=\Tik\lambdaik.
\end{equation}
Comme n'importe quel agent peut être l'attaquant, on suppose tous les agents attaquent simultanément le système résultant en:
\begin{equation}
  \label{eq:negotiation_equation_substituting_organizing_under_attack_resume}
  \tilde{\vec{\lambda}}\pplusone=\tilde{\mathcal{A}}_{\lambda}\tilde{\vec{\lambda}}\p,
\end{equation}
où
\begin{equation}
\tilde{\mathcal{A}}_{\lambda}=\left[
\begin{matrix}
I-\frac{M-1}{M}\rho\p \Tik[1]\Plin[1] & \frac{1}{M}\rho\p \Tik[1]\Plin[1]&\dots&\frac{1}{M}\rho\p \Tik[1]\Plin[1]\\
\frac{1}{M}\rho\p \Tik[2]\Plin[2]&I-\frac{M-1}{M}\rho\p \Tik[2]\Plin[2]&\dots&\frac{1}{M}\rho\p \Tik[2]\Plin[2]\\
\vdots&\vdots&\ddots&\vdots\\
\frac{1}{M}\rho\p \Tik[M]\Plin[M]&\frac{1}{M}\rho\p \Tik[M]\Plin[M]&\dots&I-\frac{M-1}{M}\rho\p \Tik[M]\Plin[M]\\
\end{matrix}
\right],
\end{equation}

Comme on a montré en \S\ref{sec:attack-interest_resume}, les matrices de triche $\Tik$ peuvent change les valeurs propres de la matrice, éventuellement faisant le système osciller et ne pas converger aux valeurs optimales.

\subsubsection{Dynamique de $\thetai$}
Similairement, si on fait le contraire et substitue~\eqref{eq:lambda_function_theta_resume} en~\eqref{eq:example_projectedSubgradient_lambda_reprise_resume},
ça résulte en
\begin{equation}
  \label{eq:negotiation_equation_substituting_resume}
 \thetai\pplusone=\thetai\p+\rho\p\left((-\Plin\thetai\p-\sik)-\frac{1}{M}\sum_{j\in\set{M}}(-\Plin[j]\vec{\theta}_{j}\p-\vec{s}_{j}[k])\right),\forall i\in\set{M}.
\end{equation}
ou en forme matricielle
\begin{equation}
  \label{eq:negotiation_equation_substituting_organizing_matrix_theta_resume}
  \vec{\theta}\pplusone=\mathcal{A}_{\theta}\vec{\theta}\p+\mathcal{\vec{B}}_{\theta}[k],
\end{equation}
où
\begin{equation}
\mathcal{A}_{\theta}=\left[
\begin{matrix}
I-\frac{M-1}{M}\rho\p \Plin[1] & \frac{1}{M}\rho\p \Plin[2]&\dots&\frac{1}{M}\rho\p \Plin[M]\\
\frac{1}{M}\rho\p \Plin[1]&I-\frac{M-1}{M}\rho\p \Plin[2]&\dots&\frac{1}{M}\rho\p \Plin[M]\\
\vdots&\vdots&\ddots&\vdots\\
\frac{1}{M}\rho\p \Plin[1]&\frac{1}{M}\rho\p \Plin[2]&\dots&I-\frac{M-1}{M}\rho\p \Plin[M]\\
\end{matrix}
\right]
\end{equation}
\begin{equation}
\mathcal{\vec{B}}_{\theta}[k]=\left[
\begin{matrix}
-\frac{M-1}{M}\rho\p \vec{s}_{1}[k]+\frac{1}{M}\rho\p \vec{s}_{2}[k]\dots-\frac{1}{M}\rho\p \vec{s}_{M}[k]\\
\frac{1}{M}\rho\p \vec{s}_{1}[k]-\frac{M-1}{M}\rho\p \vec{s}_{2}[k] \dots-\frac{1}{M}\rho\p \vec{s}_{M}[k]\\
\vdots\\
\frac{1}{M}\rho\p \vec{s}_{1}[k]+\frac{1}{M}\rho\p \vec{s}_{2}[k]\dots-\frac{M-1}{M}\rho\p \vec{s}_{M}[k]\\
\end{matrix}
\right],
\end{equation}
qui aussi est un système \dt{}, mais avec une entrée forcée ($\mathcal{\vec{B}}_{\theta}$).

On peut analyser la stabilité de $\mathcal{A}_{\theta}$ exactement comme fait avec $\mathcal{A}_{\lambda}$, c'est-à-dire, les valeurs propres doivent être dans le cercle unitaire.

On analyse aussi la somme de ses lignes et colonnes.
La somme des colonnes est égal à $1$.
Alors, $1$ est une de ces valeurs propres par la gauche:
\begin{equation}
  \label{eq:1}
  \1^{T}\mathcal{A}_{\theta}=\1^{T}
\end{equation}
Comme esperé, le système conserve la masse, i.e., les $\theta_{i}$ respectent la contrainte d'égalité globale.
De cette façon, la dépendence linéaire entre les $\theta_{i}$ est explicite.
Si on analyse les colonnes, on voit que la somme n'est pas $1$.
Alors, comme nous avons constaté, le système converge mais pas nécessairement à un état où tous les $\theta_{i}$ sont égaux.
Cela serait le cas où les $\Plin$ sont égaux.

Comme on voit, les valeurs propres dependent just de $\Plin$ et $\rho\p$.
Comme les $\Plin$ sont des paramètres du système, le designer ne peut que choisir l'évolution de $\rho\p$.

Une fois le $\rho\p$ choisi, la matrice $\mathcal{A}_{\theta}$ évolue toujours de la même manière.
Alors, s'il y a un changement de cette évolution, ça veut dire que le système présente un comportement anormale.

Comme on peut observer, une perturbation en $\Plin$ (changement de la fonction objectif ou contraintes) change les valeurs de $\mathcal{A}_{\theta}$, et par conséquence sa dynamique.
Ce changement peut déstabiliser le système si les valeurs propres sont décalées dehors le cercle unitaire, comme déjà montré en \S\ref{sec:attack-interest_resume}.
Par contre, les perturbations en $\sik$ (modification de la function objectif, contraintes ou état/référence) peuvent change l'état en régime permanent (changement en $\mathcal{\vec{B}}_{\theta}[k]$).

Si on suppose que le système est sous attaque et tous les agents sont suspects on a la dynamique
\begin{equation}
  \label{eq:negotiation_equation_substituting_organizing_tilde_resume}
  \vec{\theta}\pplusone=\tilde{\mathcal{A}}_{\theta}[k]\vec{\theta}\p+\tilde{\mathcal{\vec{B}}}_{\theta}[k]
\end{equation}
où
\begin{equation}
\tilde{\mathcal{A}_{\theta}}[k]=\left[
\begin{matrix}
I-\frac{M-1}{M}\rho\p \Tik[1]\Plin[1] & \frac{1}{M}\rho\p \Tik[2]\Plin[2]&\dots&\frac{1}{M}\rho\p \Tik[M]\Plin[M]\\
\frac{1}{M}\rho\p \Tik[1]\Plin[1]&I-\frac{M-1}{M}\rho\p \Tik[2]\Plin[2]&\dots&\frac{1}{M}\rho\p \Tik[M]\Plin[M]\\
\vdots&\vdots&\ddots&\vdots\\
\frac{1}{M}\rho\p \Tik[1]\Plin[1]&\frac{1}{M}\rho\p \Tik[2]\Plin[2]&\dots&I-\frac{M-1}{M}\rho\p \Tik[M]\Plin[M]\\
\end{matrix}
\right]
\end{equation}
\begin{equation}
\tilde{\mathcal{\vec{B}}}_{\theta}[k]=\left[
\begin{matrix}
-\frac{M-1}{M}\rho\p \Tik[1]\vec{s}_{1}[k]+\frac{1}{M}\rho\p \Tik[2]\vec{s}_{2}[k]\dots-\frac{1}{M}\rho\p \Tik[M]\vec{s}_{M}[k]\\
\frac{1}{M}\rho\p \Tik[1]\vec{s}_{1}[k]-\frac{M-1}{M}\rho\p \Tik[2]\vec{s}_{2}[k] \dots-\frac{1}{M}\rho\p \Tik[M]\vec{s}_{M}[k]\\
\vdots\\
\frac{1}{M}\rho\p \Tik[1]\vec{s}_{1}[k]+\frac{1}{M}\rho\p \Tik[2]\vec{s}_{2}[k]\dots-\frac{M-1}{M}\rho\p \Tik[M]\vec{s}_{M}[k]\\
\end{matrix}
\right]
\end{equation}

Comme dans le cas avec $\mathcal{A}_{\theta}$, en ajustant les $\Tik$, un attaquant peut changer les valeurs propres de $\mathcal{A}_{\lambda}$.
Les matrices de triche $\Tik$ peuvent être aussi ajusté pour pousser la négociation à un nouveau point, mais comme on voit, ça modifie aussi la dynamique do système.
Alors, les ataquants doivent faire le compromis entre leur gourmandise et de ne pas casser la négociation, ce qu'est pire pour tous les agents, incluant les attaquants.

Quelqu'un peut remarquer qu'on pourrait créer un détecteur de comportement anormale en supervisant la matrice $\mathcal{A}_{\theta}$.
Une fois qu'il y a un changement d'une de ses valeurs propres, un comportement anormale est détecté.

Malheureusement, cette méthode nous donne que la détection, mais pas forcément quel agent à causé l'anomalie, ce que serait utile pour un algorithm de mitigation.
D'ailleurs, pour estimer les éléments de $\mathcal{A}_{\theta}$, il nous serait nécessaire estimer $M^{2}{(c)}^{2}$ éléments\footnote{$M^{2}$ blocs de taille ${c}$}.
Exploitant la structure connue de la matrice et des blocs, on pourrait réduire le total au moins $2M{(\frac{c+{c}^{2}}{2})}$ éléments\footnote{($M$ diagonal + $M$ hors diagonal) blocs symmetriques de taille ${c}$ (seulement triangle supérieur)}.

En suite on verra un mécanisme capable de pas seulement détecter les attaques, mais aussi de identifier l'attaquant, et ça en utilisant la moitié des éléments cités.

\subsection{Détection}\label{sec:detection-mechanism_resume}

Utilisant~\eqref{eq:linear_attack_reprise_resume} on peut récrire~\eqref{eq:lambda_function_theta} comme
\begin{equation}
  \label{eq:lambda_function_theta_tilde}
\lambdaicheat[k]=-\Plintilde\thetaik-\tilde{\vec{s}}_{i}[k],
\end{equation}
où $\Plintilde=\Tik\Plin$ et $\tilde{\vec{s}}_{i}[k]=\Tik\sik$.

Une fois que $\Plin$ doit est constant, n'importe quel chagement entre deux négociations est une conséquence d'un comportement anormal, dans ce cas causé par $\Tik$.

Utilisant la relation entre $\thetaik$ et $\lambdaik$, on peut superviser les échanges entre coordinateur et agents, estimant $\Plintildeestimate$ et $\siktildeestimate$ tels que
\begin{equation}
  \lambdaicheat[k]=-\Plintilde\thetaik-\tilde{\vec{s}}_{i}[k],
\end{equation}

Si on a accès à la valeur nominale de $\Plin$\footnote{Donnée ou estimée à partir de données historiques fiables.}, notée $\Plinnominal$, on peut créer une loi de détection pour chaque agent $i$.
En choisissant une borne arbitraire $\epsilon_{\Plin}$, on peut définir l'erreur
\begin{equation}
  E_{i}[k] =\norm{\Plintildeestimate-\Plinnominal}_{F},
\end{equation}
et la fonction de détection $d_{i}$:
\begin{equation}
  d_{i}=\indicator{E_{i}[k]\geq\epsilon_{\Plin}},
\end{equation}
qui détecte un attaque quand la borne est surpassée, i.e., $d_{i}=1$.
\todo{remarque}
\begin{remark}
  Comme montré en Remarque~\ref{rem:bounds_and_error_resume}, le choix de $\epsilon_{\Plin}$ peut influencer le taux de faux positifs.
  La borne doit être supérieure à l'erreur d'estimation pour un scénario sans attaque.
  La propagation des érreurs n'est pas dans le cadre d'étude de cette thèse.
\end{remark}

\begin{remark}
  Si l'estimation ne converge pas, ça veut dire que les rélations ne sont plus linéaires, et alors on pourrait comme ça détecter un comportement anormal.
\end{remark}

Une brève discussion pour l'estimation de $\Plintildeestimate$ suit.

\subsection{Estimation}\label{sec:about-estimation_resume}
On choisie la méthode des moindres carrés récursive, en anglais \RLS{}~\cite{AstroemWittenmark1989}, pour estimer les paramètres.

Dans le \RLS{}, pour estimer un paramètre $\rlsparam$, on utilise un modèle de régression avec entrées et sorties ($\rlssysinput$ et $\rlssysoutput$) qui nous possibilitent de calculer un résidu $\epsilon$.
Ce résidue, allié à un gain $\rlsgain$, est utilisé pour mettre à jour les estimations de $\rlsparam$.
Comme la valeur exacte n'est pas connue on utilise une initialisation et un terme d'oubli $\rlsforget$ pour mettre à jour le gain $\rlsgain$, et naturellement comme dit le nome, oubliant les événements du passé.

On transforme~\eqref{eq:lambda_function_theta_tilde} pour utiliser un modèle comme  
\begin{equation}
  \rlssysinput\rlsparam=\rlssysoutput,
\end{equation}
où on vectorise $\Plintildeestimate$ and $\siktildeestimate$ en $\rlsparam$ et change la structure de $\thetai$ pour créer $\rlssysinput$ et $\rlssysoutput$
\begin{equation}
  \rlsparam=\left[
    \begin{matrix}
      \vectorize{\Plintildeestimate}\\
      \siktildeestimate\\
    \end{matrix}
  \right],
\end{equation}
\begin{equation}
  \rlssysinput=\left[
    \begin{matrix}
      \kron{I_{c}}{\thetai\T}&I_{c}\\
    \end{matrix}
  \right].
\end{equation}

Si on veut utiliser le structure symétrique de $\Plintildeestimate$ and on peut estimer juste le triangle supérieur, en réduisant le total d'éléments à ${\frac{c^{2}+3c}{2}}$.


On restructure $\rlsparam$
\begin{equation}
  \rlsparam=\left[
    \begin{matrix}
      \elem[1,1:c]{\Plintildeestimate}\T\\
      \elem[2,2:c]{\Plintildeestimate}\T\\
      \vdots\\
      \elem[c,c]{\Plintildeestimate}\T\\
      \siktildeestimate\\
    \end{matrix}
  \right].
\end{equation}

Cependant, pour $\rlssysinput$, on utilise un algorithme de construction (Algorithme~\ref{alg:struct_symmetric_resume}):
\begin{equation}
  \rlssysinput=\left[
    \begin{matrix}
      \text{\structDataSym}(\thetai) &  I_{c}
    \end{matrix}
  \right].
\end{equation}

\begin{algorithm2e}[h]
  \DontPrintSemicolon%
  \Fn{\structDataSym($\vec{x}$)}{
    $s\gets\card\vec{x}$\;
    \eSi{$s==1$}{
      $Y\gets \vec{x}$\;
    }
    {
      $Y\gets \left[\begin{smallmatrix}
                  \left[\begin{smallmatrix}
                          \vec{x}\T \\
                          \left[\begin{matrix}
                                  \0_{s-1}& \elem[1]{\vec{x}}I_{s-1}
                                \end{matrix} \right]
                        \end{smallmatrix} \right]
                  & \begin{smallmatrix}
                      \0_{\frac{s^{2}-s}{2}}\T \\
                      \text{\structDataSym}(\elem[2:s]{\vec{x}})
                    \end{smallmatrix}
                \end{smallmatrix}\right]$\;
            }
          }
          \caption{Restructuration de forme symétrique.}\label{alg:struct_symmetric_resume}
        \end{algorithm2e}
Pour mieux comprendre on donne un example.
Si $\thetai$ a ${c=3}$ éléments, en appliquant \structDataSym, ça résulte en
\begin{equation}
  \text{\structDataSym}(\theta_i)=
  \left[
  \begin{matrix}
     \elem[1]{\theta_{i}}  &   \elem[2]{\theta_{i}}   &  \elem[3]{\theta_{i}} &    0  &   0  &   0 \\
     0  &   \elem[1]{\theta_{i}}   &  0 &    \elem[2]{\theta_{i}}  &   \elem[3]{\theta_{i}}  &   0 \\
     0  &   0   &  \elem[1]{\theta_{i}} &    0  &   \elem[2]{\theta_{i}}  &   \elem[3]{\theta_{i}}
  \end{matrix}
  \right].
\end{equation}

\begin{remark}
  On ne nécessite pas de $\sik$ pour la estimation, on l'estime quand même car on l'utilisera pour la mitigation.
\end{remark}

On décrit en Algorithme~\ref{alg:update_rls_resume} comme calculer une estimation de $\rlsparam$.

\begin{algorithm2e}[h]
  \DontPrintSemicolon%
  \Entree{Pas $h$, Oubli $\rlsforget$, Estimation $\rlsparam\h$, Gain $\rlsgain\h$, Entrée $\thetai\h$, Sortie $\rlssysoutput\h$}
  \Sortie{Nouvelle estimation $\rlsparam\hplusone$, Nouveau Gain $\rlsgain\hplusone$ }
  $\rlssysinput\gets\left[\text{\structDataSym}(\thetai\h),I_{c}\right]$\;
  Calculate residual $\rlsresidual$: $\rlsresidual\gets \rlssysoutput-\rlssysinput\rlsparam$\;
  Update gain $\rlsgain$: $\rlsgain\hplusone\gets \rlsforget^{-1}\rlsgain\h-\rlsforget^{-2}\rlsgain\h\rlssysinput\T{(I_{c}+\rlsforget^{-1}\rlssysinput\rlsgain\h\rlssysinput\T)}^{-1}\rlssysinput\rlsgain\h$\;
  Calculate new estimate $\rlsparam$: $\rlsparam\hplusone\gets\rlsparam\h+\rlsgain\hplusone\rlssysinput\T\rlsresidual$\;
  \caption{Update of \RLS{} to estimate $\Plintildeestimate$ and $\siktildeestimate$ simultaneously.}\label{alg:update_rls_resume}
\end{algorithm2e}

On pourrait essayer d'utiliser l'estimation pendant la négociation, mais l'agorithme ne marcherait pas.
Le fait que $\lambdai$ dépend de $\thetai$ et vice-versa fait que la négociation se comporte comme un système \dt{} (comme vu en~\S\ref{sec:analysis-negotiation_resume}).
Cette dépendance diminue l'excitation de l'algorithme et comme vu en~\cite{AstroemWittenmark1989}, ça fait que la solution devienne pas unique, une des matrices devienne singulière.
Une façon d'augmenter artificiellement l'excitation est de déconecter les $\thetai$ de la négociation et utiliser un autre type d'entrée.

On a opté d'utiliser un bruit comme entrée une foi que comme vu en~\cite[\S3.4]{AstroemWittenmark1989}, le signal aléatoire a excitation persistent de n'importe quel ordre.

\subsection{Technique de détection Complete }\label{sec:compl-detect-algor_resume}
La détection peut être décrite enfin par l'Algorithme~\ref{alg:detection_rls_resume}.

\begin{algorithm2e}[h]
  \DontPrintSemicolon%
  \Entree{$\Plinnominal$ Nominal, $h_{\max}$, Borne $\epsilon_{\rlsparam}$, Borne $\epsilon_{\Plin}$, }
  \Sortie{Détection $d_{i}$, Estimations de $\Plintildeestimate$ et $\siktildeestimate$}
  $h\gets0$\;
  Initialise $\rlsparam\p$\;
  \Repeter{$\norm{\rlsparam\hplusone-\rlsparam\h}\leq\epsilon_{\rlsparam}$}
  {
    Coordinateur envoie $\thetai\h$ aléatoire à agent $i$ \;
    Sous-système résout~\eqref{eq:DOP_local_resume}, et envoie  $\lambdaikstar(\thetai\p)$ en retour\;
    Coordinateur met à jour l'estimation de $\rlsparam$ avec Algorithme~\ref{alg:update_rls}\;
    \Si{$\ \left[h\geq h_{\max}\right]$}{
      Coordinateut fixe $d_{i}$: $d_{i}\gets 1$\;
      break\;
    }
    $h\gets h+1$\;
  }
  Reconstruit $\Plintildeestimate$ et $\siktildeestimate$ à partir de $\rlsparam$\;
  $E_{i}[k]\gets\norm{\Plintildeestimate-\Plinnominal}_{F}$\;
  Coordinateur calcule $d_{i}$: $d_{i}\gets d_{i}\lor \indicator{E_{i}[k]\geq\epsilon_{\Plin}}$\;

  \caption{Algorithme de détection dans un pas $k$ (en parallèle si possible).}\label{alg:detection_rls_resume}
\end{algorithm2e}

Une fois les attaquants identifiés, on a besoin de la mitigation pour réduire les effets.

\newpage
\subsection{Mitigation}\label{sec:mitigation_resume}
Pour la mitigation on a quelques possibilités d'objectifs.
On donne un petit exemple.

\subsubsection{Exemple Qualitatif}\label{sec:qualitative-example_resume}

Imaginons un système simple de deux sous-systèmes \ltidt{} d'une dimension, contraints par l'entrée, controllés par la \dmpc{} presentée dans ce travail, problèmes du type \qp{} et toute autre condition imposé dans cette section.
On utilise un horizon de prédiction $\predhorz=1$ and contraintes locales $\vec{u}_{i}\geq\0$ pour faciliter la visualisation.

Si on trace les courbes de niveaux du système (Fig.~\ref{fig:original_minimum_resume}), on voit le minimum sans contraintes projeté (projection pondérée) sur le hyperplan.
La projection résulte la solution sous contraintes (point bleu).
\begin{figure}[h]
  \centering
  \includegraphics[width=7cm]{../img/resilient_eq/original-minimum.pdf}
  \caption{Minimum Original.}\label{fig:original_minimum_resume}
\end{figure}

Une fois qu'un agent attaque le système~\eqref{eq:linear_attack_reprise_resume}, les courbes sont déformées (Fig.~\ref{fig:minimum_after_attack_resume}).
Cette distortion change la projection, resultant en une nouvelle solution (en vert).
\begin{figure}[h]
  \centering
  \includegraphics[width=7cm]{../img/resilient_eq/new-minimum-selfish.pdf}
  \caption{Minimum après attaque.}\label{fig:minimum_after_attack_resume}
\end{figure}

Si l'attaquant est détecté, une option est de mitiger la dérive par substituant le $\lambdaicheat$ réçu par $\0$.
Cela peut être interpreté comme un coordinateur punissant l'attaquant, en supposant que l'attaquant est satisfait $\lambdai=\0$, indépendamment de l'allocation faite.
Cette négligence vers l'attaquant résulte en lui recevant moins et moins de ressources.
À la limite, ça serait comme si l'attaquant ne faisait plus part de la négociation, en étant débranché, comme en~\cite{VelardeEtAl2018,MaestreEtAl2021}.

Si on le fait (Fig.~\ref{fig:minimum_ignoring_attacker}) on voit les nouvelles courbes et la nouvelle solution (en orange).
\begin{figure}[h]
  \centering
  \includegraphics[width=7cm]{../img/resilient_eq/ignoreX.png}
  \caption{Nouveau optimal quand négligent l'attaquant.}\label{fig:minimum_ignoring_attacker_resume}
\end{figure}

Même si l'idée de punir l'attaquant semble attirante, comme nous controllons un \cps{} ça peut affecter la qualité de service, en anglais \QoS{}, et par conséquence les personnes.

Une solution serait d'allouer des ressources suffisantes pour un niveau minimal de \QoS{}, mais ça peut être un peu difficile à cause de sa subjectivité.

Nous proposons une autre solution, essayer de récuperer le comportement normal, tant que quelques hypothèses soient garanties.
Cela permet de passer des courbes du système attaqué (Fig.~\ref{fig:minimum_after_attack_resume}) à des autres, comme montré en Fig.~\ref{fig:minimum_recovered_resume}, où le nouveau minimum s'encontre dans une voisinage acceptable de l'original.

\begin{figure}[h]
  \centering
  \includegraphics[width=7cm]{../img/resilient_eq/correctX.png}
  \caption{Valeur optimale après récuperer comportement original.}\label{fig:minimum_recovered_resume}
\end{figure}

\subsubsection{Récuperant comportement nominal}\label{sec:recov-nomin-behav_resume}
Comme vu, si $\lambdai=\0$, ça veut dire que l'allocation de l'agent lui satisfait.
Alors, on n'espère pas que l'attaquant va tricher pour dire qu'il est satisfait quand il n'y est pas.

De cette façon, on assume que
\begin{equation}
  \left[\lambdaicheat=\0 \right] \iff \left[\lambdai=\0 \right],
\end{equation}
qui signifie que
\begin{equation}
  \label{eq:T_is_invertible}
  \lambdaicheat=\Tik\lambdai=\0\text{, if and only if }\lambdai=\0,
\end{equation}
impliquant que $\Tik$ est \textbf{inversible}.

En observant~\eqref{eq:lambda_function_theta_tilde_resume}, on suppose aussi que le choix de $\Tik$ ne change pas le structure de $\Plin$, i.e., $\Plintilde$ est aussi symétrique.

Si on a l'estimation $\Plintildeestimate$ et la valeur nominale $\Plinnominal$, avec ces hypothèses on peut estimer l'inverse de $\Tik$:
\begin{equation}
  \label{eq:estimate_T_inverse}
{\Tikinvestimate=\Plinnominal{\Plintildeestimate}^{-1}}.
\end{equation}

Et avec cette estimation on peut reconstruire $\lambdai$:
\begin{equation}
  \label{eq:lambdareconstruction}
  \lambdaireconstructed=-\Plinnominal\thetai-\Tikinvestimate\siktildeestimate
\end{equation}

Alors, on peut moduler la négociation en choisissant la version de $\lambdai$ qu'on veut, i.e.,
\begin{equation}
  \lambdaimodified=
          \begin{cases}
            \lambdaicheat, &\text{if } d_{i}=0\\
            \lambdaireconstructed, &\text{if }d_{i}=1\\
        \end{cases}
\end{equation}

\begin{remark}
  Observe que si l'estimation ne converge pas on ne peut pas réconstruire $\lambdaik$.
  Une solution serait ignorer l'attaquant comme montré.
  Par contre, on ignore les cas où l'estimation ne converge pas.
\end{remark}

\subsection{La dMPC résiliente pour systèmes dépourvus}\label{sec:complete-safe-dmpc_resume}
En mettant ensemble les méthodes de détection et mitigation présentées, on peut finalement avoir notre \dmpc{} résiliente basée sur la décomposition primale pour systèmes dépourvus, ou en anglais \rpdmpcss{}.
On peut observer que les mécanismes présentés peuvent être vus comme un superviseur ajouté pour chaque agent (Fig.~\ref{fig:dmpc_communication_safe_eq_resume}).
Algorithme~\ref{alg:rpdbdmpcss} systematize la méthode.

\begin{figure}[H]
  \centering
  \begin{tikzpicture}[font=\small,thick,node distance=3*0.6180cm and 0.6180cm,every node/.style=rectangle,
    mpcSmall/.style={fill=mpc_agent, minimum height=0.6180*2cm, minimum width=2cm},
    coordinator/.style={fill=mpc_coordinator, minimum height=0.6180*3.5cm, minimum width=6.5cm},
    supervisor/.style={fill=mpc_green, minimum height=0.6180*3*0.3cm, minimum width=2cm},
    ]

    \node[draw, mpcSmall,] (block1) {\small Agent 1};
    \node[fill=none, draw=none, right=of block1,] (mult) {\bf $\dots$};
    \node[draw, mpcSmall, fill=mpc_agent, right=of mult,] (blockM) {\small Agent M};
    \node[draw, coordinator, below=of mult,] (coordinator) {Coordinateur};

    \node[draw, supervisor,anchor=north west] at (coordinator.north west) {\small Superviseur 1};
    \node[draw, supervisor,anchor=north east] at (coordinator.north east) {\small Superviseur M};

    \draw[-latex,line width=1pt] (block1.south)+(0.4,.0) -- ( coordinator.north -| {$(block1.south)+(0.4,.0)$}) node [right,midway] {$\lambda_{1}$};
    \draw[latex-,line width=1pt] (block1.south)+(-0.4,0) -- (  coordinator.north -| {$(block1.south)+(-0.4,0)$}) node [left,midway] {$\theta_{1}$};
    \draw[-latex,line width=1pt] (blockM.south)+(0.4,.0) -- ( coordinator.north -| {$(blockM.south)+(0.4,.0)$}) node [right,midway] {$\lambda_{M}$};
    \draw[latex-,line width=1pt] (blockM.south)+(-0.4,0) -- (  coordinator.north -| {$(blockM.south)+(-0.4,0)$}) node [left,midway] {$\theta_{M}$};
  \end{tikzpicture}
  \caption{Échange entre agents et coordinateur dans la \rpdmpcss{}.}\label{fig:dmpc_communication_safe_eq_resume}
\end{figure}

\begin{algorithm2e}[h]
  \DontPrintSemicolon
  \detectPhasefr{
    Coordinateur compute $d_{i}$ et estimations de $\Plintildeestimate$ avec Algorithme~\ref{alg:detection_rls_resume}\;
  }
  \negotPhasefr{
    $p\gets 0$\;
    Coordinateur initialise $\vec{\theta}^{(p)}$ et les envoie aux sous-systèmes\;
    \Repeter{$\left[\norm{{\vec{\theta}[k]}^{(p)}-{\vec{\theta}[k]}^{(p-1)}}\leq\epsilon\right]\lor \left[p\geq p_{\max}\right]$}{
      Sous-systèmes résout~\eqref{eq:DOP_local_resume}, et envoient $\vec{\lambda}^{\star}_{i}(\vec{\theta}\p)$\;

      Coordinateur m-à-j les allocations~\eqref{eq:example_projectedSubgradient_lambda_reprise_resume} avec versions adéquates de $\vec{\lambda}_{i}$:\;
      \quad$\vec{\lambda}_{i}^{\star}(\vec{\theta}\p)$, si $d_{i}=0$ et $\lambdaireconstructed$, si ${d_{i}=1}$~\eqref{eq:lambdareconstruction}\;
      $p\gets p+1$
    }
    Agents appliquent la dernière commande $\vec{u}_{i}^{\star}[0|k]$ calculée\;
    $k\gets k+1$\;
  }
  \caption{La \dmpc{} Résiliente basée sur la décomposition primale pour systèmes dépourvus.}\label{alg:rpdbdmpcss_resume}
\end{algorithm2e}

\subsection{Expériment Numérique}\label{sec:numerical-experiment_resume}

\subsubsection{Étude de cas}\label{sec:case-study}

Notre étude de cas est un simple \dhn{} composé par ${M=4}$ petites maisons (appelées I, II, II and IV).
Chacune a un état $\vec{x}_{i}$, et une référence de temperature différente $\vec{w}_{i}(t)$ (besoins diveses).
Les maisons sont equipées de convecteurs, et la puissance total de chauffage de chaque maison est l'entrée $\vec{u}_{i}(t)$.
Comme il n'y a pas de dispositifs pour rafraîchir l'ambient, les entrées sont positives, i.e., $\vec{u}_{i}[k]\succeq\0$.
En Fig.~\ref{fig:houses} les maisons consomment la puissance d'un fournisseur.

\begin{figure}[h]
  \centering
  \begin{tikzpicture}[node distance=.5cm and .75cm,scale=1]
    \node[color=mpc_agent] (house1) at (0,0) {\scalebox{2.5}{\faHome}};
    \node[minimum height=1cm,below=of house1] (medium) {};
    \node[color=mpc_agent,right=of medium] (house2)  {\scalebox{3.5}{\faHome}};
    \node[color=mpc_agent,below=of medium] (house3)  {\scalebox{3}{\faHome}};
    \node[color=mpc_agent,left=3cm of medium] (house4)  {\scalebox{7}{\faHome}};

    \draw[latex-,line width=1pt] (house1) -- (medium.center);
    \draw[latex-,line width=1pt] (house2) -- (medium.center);
    \draw[latex-,line width=1pt] (house3) -- (medium.center);
    \draw[latex-,line width=1pt] (house4) -- (medium.center) node[above,midway] {\large $\vec{u}_{i}(t)$};
    \draw[color=black,fill=mpc_coordinator,] (medium) circle [radius=.2cm];

    \node[latex-,line width=7pt] at ($(house4) +(-1,1)$) {\large $w_{i}(t)$};
    \node[latex-,line width=7pt] at ($(house4)$) {$\vec{x}_{i}(t)$};

  \end{tikzpicture}
  \caption{District avec 4 maisons.}\label{fig:houses_resume}
\end{figure}

On modèle des maisons utilisant des modèles 3R-2C monozone ave des fenêtres~\cite{GoudaEtAl2002} (Fig.~\ref{fig:3R2C_model_resume}).
Les paramètres sont décrits sur Tab.~\ref{tab:modelParamMeaning_resume} et~\ref{tab:modelParam_resume}.

\begin{figure}[h]
  \centering
  \begin{circuitikz}[european]
    \draw (0,0) node[tlground]{} to[isource, l=$P^{\text{heat}}$] ++(0,2) to[short, -*] ++(1.5,0) coordinate (a);

    \draw (a) node[above]{$T^{\text{in}}$}  to[C=$C^{\text{air}}$] ++(0,-2) node[tlground]{};
    \draw (0,-3) node[tlground]{} to[isource, l=$I^{\text{sol}}$] ++(0,2)
    to[short, -*] ++(1.5,0) coordinate (b);
    \draw (b) to[C=$C^{\text{walls}}$] ++(0,-2) node[tlground]{};

    \draw (a) -- ++(2,0) coordinate (c) -- ++(0,-.5) to[R=$R^{\text{iw/ia}}$] ++(0,-2) -- ++(0,-.5) coordinate (d);

    \draw (b) node[above]{$T^{\text{walls}}$} to[short,-*] (d);

    \draw (c) --  ++(2.5,0) -- ++(0,-.5) to[R=$R^{\text{oa/ia}}$] ++(0,-2) -- ++(0,-.5) coordinate (e);

    \draw (d) to[R=$R^{\text{ow/oa}}$] (e) to[battery,l=$T^{\text{out}}$] ++(0,-2) node[tlground]{};
  \end{circuitikz}
  \caption{Modèle thermique 3R-2C d'une maison.}\label{fig:3R2C_model_resume}
\end{figure}

\begin{table}[h]
  \centering
  \caption{Paramètres du Modèle}\label{tab:modelParamMeaning_resume}
  \begin{tabular}[b]{cl}
    \toprule
    Symbole&Signification\\
    \midrule
    $C^{\text{air}}_{i}$  &Capacité termique de l'air intérieur\\
    $C^{\text{walls}}_{i}$ &Capacité termique des parois externes\\
    $R^{\text{iw/ia}}_{i}$ &Resist.\ entre l'air et parois internes\\
    $R^{\text{ow/oa}}_{i}$ &Resist.\ entre l'air et parois externes\\
    $R^{\text{oa/ia}}_{i}$ &Resist.\ entre l'air intérieur et extérieur (à travers des fenêtres)\\
    $P^{\text{heat}}$ &Puissance de chauffage des convecteurs\\
    $I^{\text{sol}}$ &Puissance irradiée par le Soleil\\
    $T^{\text{in}}$ &Temperature moyenne de l'air à l'intérieur\\
    $T^{\text{walls}}$ &Temperature moyenne des parois internes\\
    \bottomrule
  \end{tabular}
\end{table}

\begin{table}[h]
  \centering
  \caption{
    Paramètres pour chaque maison}\label{tab:modelParam_resume}
  \begin{tabular}[t]{cccccc} \toprule
    Élément& I & II & III & IV &Unit\\
    \midrule
    \input{../data/resilient_eq/thermic_params.tex}\\
    \bottomrule
  \end{tabular}
\end{table}


Le circuit peut être traduit par le modèle d'espace d'état
  \begin{equation}
  \begin{matrix}
    \label{eq:systems_cont_resume}
    \dot{\vec{x}}_{i}(t)  &=&{A_{c}}_{i}\vec{x}_{i}(t) &+& {B_{c}}_{i}\vec{u}_{i}(t)+{D_{c}}_{i}\vec{d}_{i}(t)\\
    \vec{y}_{i}(t)        &=&{C_{c}}_{i}\vec{x}_{i}(t) &&
  \end{matrix},
\end{equation}
où

\begin{equation}
  \label{eq:4_resume}
  \begin{matrix}
    A_{\mathrm{c}_{i}}=\left[
    \begin{matrix}
      -\frac{1}{C^{\text{walls}}_{i}R^{\text{oa/ia}}_{i}}-\frac{1}{C^{\text{walls}}_{i}R^{\text{iw/ia}}_{i}}& \frac{1}{C^{\text{walls}}_{i}R^{\text{iw/ia}}_{i}}\\
      \frac{1}{C^{\text{air}}_{i}R^{\text{iw/ia}}_{i}} &-\frac{1}{C^{\text{air}}_{i}R^{\text{ow/oa}}o_{i}}-\frac{1}{C^{\text{air}}_{i}R^{\text{iw/ia}}_{i}}
    \end{matrix}\right]
                                                         &
      B_{\mathrm{c}_{i}}=\left[\begin{matrix}  \frac{1}{C^{\text{air}}_{i}}\\ 0\end{matrix}\right]\T
  \\\\
    D_{\mathrm{c}_{i}}=\left[
    \begin{matrix}
      0& \frac{1}{C^{\text{air}}_{i}R^{\text{ow/oa}}_{i}}\\
      \frac{1}{C^{\text{air}}_{i}} &\frac{1}{C^{\text{air}}_{i}R^{\text{ow/oa}}}
    \end{matrix}\right]&C_{\mathrm{c}_{i}}=\left[\begin{matrix}1 & 0\end{matrix}\right]

\end{matrix}
\end{equation}

avec
${\vec{x}_{i}(t)=\left[T^{\text{in}}_{i}(t)\ T^{\text{walls}}_{i}(t)\right]\T}$,
${\vec{u}_{i}(t)=P^{\text{heat}}_{i}}$,
${\vec{d}_{i}(t)=\left[I^{\text{sol}}(t)\ T^{\text{out}}(t)\right]\T}$.

Les entrées $\vec{u}_{i}(t)$ sont contraintes par une puissance de chauffage maximale disponibilisée par le founisseur, i.e.,
\begin{equation}
\sum\limits_{i\in\set{M}}\left[\vec{u}_{i}(t)\right]\preceq \vec{u}_{\max}
\end{equation}
où
$\vec{u}_{\max}=40\mathrm{kW}.$

\begin{remark}
  On ignore les perturbation causées par le soleil et la temperature à l'éxterieur, i.e., $\vec{d}_{i}(t)=\0$.
\end{remark}

Comme on utilise la \mpc{}, on discretise le système avec un bloqueur d'ordre zéro et $T_{s}=0.25\mathrm{h}$ comme pas d'échantillonnage, resultant en les $3$-tuples $(A_{i},B_{i},C_{i})$.

\subsubsection{Appliquant le \rpdmpcss{}}
D'abord, on suppose que le système est dépourvu, c'est à dire, ayant des états initiaux $\vec{x}_{i}[0]$, les références $\vec{w}_{i}[k]$ ne peuvent pas être achevées.

On utilise par exemple, les états
\input{../data/resilient_eq/initial_states.tex},
et références
\input{../data/resilient_eq/references.tex}.
Utilisant les gains
$Q_{i}=10I$,
et
$R_{i}=   I_{2}$,
et en choisissant de contrôler le système avec un horizon de prédiction
$\predhorz=4$,
on structure le problème de la \dmpc{} et le décompose avec la décomposition primale, avec des problèmes locaux
\begin{equation}
  \label{eq:houses_deprived_local_problem_resume}
  \begin{matrix}
    \minimize\limits_{\vec{U}_{i}[k]}&\obji=\frac{1}{2}\norm{\vec{U}_{i}[k]}^{2}_{H_{i}} + {\vec{f}_{i}[k]}^{T}\vec{U}_{i}[k]\\
    \mathrm{subject~ to} & \bar{\Gamma}_{i}\vec{U}_{i}[k] = \thetaik:\lambdaik\\
                                     &\vec{U}_{i}[k]\succeq\0
  \end{matrix}
\end{equation}

et équations de mise à jour~\eqref{eq:example_projectedSubgradient_lambda_reprise_resume}.

\subsubsection{Résultats}\label{sec:results_resume}
On teste l'algorithme avec une simulation dans une période de
$5$
heures, i.e.,
${k\in\{0,5/T_{s}\}}$,
dans quelques scénarios différents:
\begin{enumerate}
  \item Comportement Nominal (dénoté N)
  \item Agent I attaque le système commandé par \dmpc{} standard (dénoté S)\label{it:case_selfish_resume}
  \item Agent I attaque le système commandé par \rpdmpcss{} (dénoté C)\label{it:case_selfish_recovered_resume}
  % \todo{\item Agents I and IV attack system controlled by standard \dmpc{} (denoted as MS)\label{it:case_selfish_multiple}\note{only if a have time to simulate}}
  % \todo{\item Agents I and IV attack system controlled by \rpdmpcss{} (denoted as MC)\label{it:case_selfish_multiple_recovered}\note{only if a have time to simulate}}
\end{enumerate}

L'attaque choisi pour les scénarios~\ref{it:case_selfish_resume} et~\ref{it:case_selfish_recovered_resume},
sont
\begin{align}
  T_{I}=&\begin{cases}
          \left[\input{../data/resilient_eq/triche_matrix_I}\right],&\text{if }k> 5\\
          I_{c},&\text{otherwise}
        \end{cases}
  % T_{IV}=\begin{cases}
  %         \todo{4I_{c}\text{, if }k< 6}\\
  %         I_{c}\text{, otherwise}
  %       \end{cases}
.
\end{align}

Dans Fig.~\ref{fig:response_houseI_3Scenarios_resume}, on compare la temperature de la maison I ($\vec{y}_{I}[k]$) avec sa référence $\vec{w}_{I}[k]$, et après la variable de détection ${E_{I}(k)}$ avec sa borne $\epsilon_{P}=10^{-4}$.

\begin{figure}[h]
  \centering
  \includegraphics[width=.7\textwidth]{../img/resilient_eq/ErrorWX_command_normErrH.pdf}
\caption{Temperature de la maison I et la variable $E_{I}(k)$ pour les 3 scénarios.}\label{fig:response_houseI_3Scenarios_resume}
\end{figure}
Comme attendu, les variables de détection repose sous la borne $\epsilon_{P}=10^{-4}$ quand on est dans le scénario nominal.
Par contre, pour les scénarios S et C, où l'agent attaque le système, la variable dépasse la borne, indiquant la triche.
En scénario S, on observe l'erreur de suivi ${w_{I}-y_{I}}$ se réduire quand l'attaque est activé, suggérant que l'attaquant pousse la négocitation pour recevoir plus de ressources.
D'ailleurs, les autres agents reçoivent moins de ressources, et leur erreur de suivi augmente (Fig.~\ref{fig:response_housesII_to_IV_3Scenarios_resume}).

\begin{figure}[h]
  \centering
 \includegraphics[width=.7\textwidth,trim=0 .3cm 0 .2cm,clip]{../img/resilient_eq/ErrorWX_command_normErrH_all_houses.pdf}
  \caption{Temperature de l'air dans toutes les maisons pour les 3 scénarios.}\label{fig:response_housesII_to_IV_3Scenarios_resume}
\end{figure}

Quand la \rpdmpcss{} est activée en scénario C, les temperatures récupèrent un comportement proche du nominal, comme on voit dans Fig.~\ref{fig:response_houseI_3Scenarios_resume} et~\ref{fig:response_housesII_to_IV_3Scenarios_resume}.

% \todo{
%   Similarly, we can show the method works for cases where multiple agents attack the system (Fig.~\ref{fig:response_houses_N_M}),
% \begin{figure}[h]
%   \centering
%   \includegraphics[width=7cm]{AirTempAndDecisionVariable.pdf}
% \caption{Temperature of all houses, and respective references for scenarios N,MS and MC. \todo{remake figure}}\label{fig:response_houses_N_M}
% \end{figure}
% }

On peut aussi comparer les fonctions objectif locales et global $\Jiacc$ et $\Jacc$ dans Tab.~\ref{tab:eq_costsGlobalLocal_resume}.
Comme attendue, la fonction decroît pour l'attaqueur si la \dmpc{} n'est pas sécurisée. Cependant une fois que la \rpdmpcss{} est activé les objectifs reviennent à une valeur proche de l'originale.

\begin{table}[h]
  \centering
  \caption{Fonctions objectif $J_{i}$ (\% erreur)}\label{tab:eq_costsGlobalLocal_resume}
  \begin{tabular}[t]{cccc}
    \toprule
    Agent  & Scénario N& Scénario S & Scénario C\\
    \midrule
    \input{../data/resilient_eq/table_costs_all_houses_error.tex}\\
    \bottomrule
  \end{tabular}
\end{table}

\newpage
\section{Commande Prédictive résiliente sur pénurie artificielle}\label{sec:comm-pred-resil-1}

\newpage
\section{Conclusion}\label{sec:conclusion_resume}
\end{document}
